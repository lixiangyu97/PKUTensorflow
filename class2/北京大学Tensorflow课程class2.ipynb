{
 "cells": [
  {
   "cell_type": "raw",
   "id": "ebbbcd96",
   "metadata": {},
   "source": [
    "预备知识：先讲几个函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ec9965a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc995983",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.constant([1, 2, 3, 1, 1])\n",
    "b = tf.constant([0, 1, 3, 4, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38efd52c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5,), dtype=bool, numpy=array([ True,  True, False, False, False])>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.greater(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22660f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = tf.where(tf.greater(a, b),a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec28d413",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5,), dtype=int32, numpy=array([1, 2, 3, 4, 5])>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8bdc66c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "532ce960",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdm = np.random.RandomState(seed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e6fd7e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomState(MT19937) at 0x2A3362B6340"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "639cefac",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = rdm.rand()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "69b6979a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.417022004702574"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f7fdfacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = rdm.rand(2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4bd521dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.20324493e-01, 1.14374817e-04, 3.02332573e-01],\n",
       "       [1.46755891e-01, 9.23385948e-02, 1.86260211e-01]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "raw",
   "id": "569c907a",
   "metadata": {},
   "source": [
    "垂直叠加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2e9487a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1, 2, 3])\n",
    "b = np.array([4, 5, 6])\n",
    "c = np.vstack((a, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4e7d29de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3],\n",
       "       [4, 5, 6]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2317ef81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成等间隔数值点\n",
    "x, y = np.mgrid[1:3:1, 2:4:0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2268e7ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., 1.],\n",
       "       [2., 2., 2., 2.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "42549619",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2. , 2.5, 3. , 3.5],\n",
       "       [2. , 2.5, 3. , 3.5]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a6997ded",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 2., 2., 2., 2.])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7b2f5797",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2. , 2.5, 3. , 3.5, 2. , 2.5, 3. , 3.5])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fccc7083",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将x, y拉直，并合并配对为二维张量，生成二维坐标点\n",
    "grid = np.c_[x.ravel(), y.ravel()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bc966705",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1. , 2. ],\n",
       "       [1. , 2.5],\n",
       "       [1. , 3. ],\n",
       "       [1. , 3.5],\n",
       "       [2. , 2. ],\n",
       "       [2. , 2.5],\n",
       "       [2. , 3. ],\n",
       "       [2. , 3.5]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid "
   ]
  },
  {
   "cell_type": "raw",
   "id": "d17aedcc",
   "metadata": {},
   "source": [
    "神经网络复杂度"
   ]
  },
  {
   "cell_type": "raw",
   "id": "466c74fc",
   "metadata": {},
   "source": [
    "统计神经网络的层时候，输入层不算在内。（因为他们不参与计算）\n",
    "层数 = 隐藏层的层数n+输出层  \n",
    "除输入层外：每一个神经元，都有一个偏置b"
   ]
  },
  {
   "cell_type": "raw",
   "id": "445f6c95",
   "metadata": {},
   "source": [
    "参数：W矩阵，b偏置向量\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6c4022a5",
   "metadata": {},
   "source": [
    "可以先使用较大的学习率，较优解之后减小学习率。\n",
    "可使用衰减公式"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7d8d4688",
   "metadata": {},
   "source": [
    "激活函数\n",
    "sigmod函数:对输入值进行归一化\n",
    "Tanh tf.math.tanh(x)\n",
    "\n",
    "Relu 函数：分段函数\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "05134d8b",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 0 training steps,w1 is \n",
      "[[-0.8096241]\n",
      " [ 1.4855157]] \n",
      "\n",
      "After 500 training steps,w1 is \n",
      "[[-0.21934733]\n",
      " [ 1.6984866 ]] \n",
      "\n",
      "After 1000 training steps,w1 is \n",
      "[[0.0893971]\n",
      " [1.673225 ]] \n",
      "\n",
      "After 1500 training steps,w1 is \n",
      "[[0.28368822]\n",
      " [1.5853055 ]] \n",
      "\n",
      "After 2000 training steps,w1 is \n",
      "[[0.423243 ]\n",
      " [1.4906037]] \n",
      "\n",
      "After 2500 training steps,w1 is \n",
      "[[0.531055 ]\n",
      " [1.4053345]] \n",
      "\n",
      "After 3000 training steps,w1 is \n",
      "[[0.61725086]\n",
      " [1.332841  ]] \n",
      "\n",
      "After 3500 training steps,w1 is \n",
      "[[0.687201 ]\n",
      " [1.2725208]] \n",
      "\n",
      "After 4000 training steps,w1 is \n",
      "[[0.7443262]\n",
      " [1.2227542]] \n",
      "\n",
      "After 4500 training steps,w1 is \n",
      "[[0.7910986]\n",
      " [1.1818361]] \n",
      "\n",
      "After 5000 training steps,w1 is \n",
      "[[0.82943517]\n",
      " [1.1482395 ]] \n",
      "\n",
      "After 5500 training steps,w1 is \n",
      "[[0.860872 ]\n",
      " [1.1206709]] \n",
      "\n",
      "After 6000 training steps,w1 is \n",
      "[[0.88665503]\n",
      " [1.098054  ]] \n",
      "\n",
      "After 6500 training steps,w1 is \n",
      "[[0.90780276]\n",
      " [1.0795006 ]] \n",
      "\n",
      "After 7000 training steps,w1 is \n",
      "[[0.92514884]\n",
      " [1.0642821 ]] \n",
      "\n",
      "After 7500 training steps,w1 is \n",
      "[[0.93937725]\n",
      " [1.0517985 ]] \n",
      "\n",
      "After 8000 training steps,w1 is \n",
      "[[0.951048]\n",
      " [1.041559]] \n",
      "\n",
      "After 8500 training steps,w1 is \n",
      "[[0.96062106]\n",
      " [1.0331597 ]] \n",
      "\n",
      "After 9000 training steps,w1 is \n",
      "[[0.9684733]\n",
      " [1.0262702]] \n",
      "\n",
      "After 9500 training steps,w1 is \n",
      "[[0.97491425]\n",
      " [1.0206193 ]] \n",
      "\n",
      "After 10000 training steps,w1 is \n",
      "[[0.9801975]\n",
      " [1.0159837]] \n",
      "\n",
      "After 10500 training steps,w1 is \n",
      "[[0.9845312]\n",
      " [1.0121814]] \n",
      "\n",
      "After 11000 training steps,w1 is \n",
      "[[0.9880858]\n",
      " [1.0090628]] \n",
      "\n",
      "After 11500 training steps,w1 is \n",
      "[[0.99100184]\n",
      " [1.0065047 ]] \n",
      "\n",
      "After 12000 training steps,w1 is \n",
      "[[0.9933934]\n",
      " [1.0044063]] \n",
      "\n",
      "After 12500 training steps,w1 is \n",
      "[[0.9953551]\n",
      " [1.0026854]] \n",
      "\n",
      "After 13000 training steps,w1 is \n",
      "[[0.99696386]\n",
      " [1.0012728 ]] \n",
      "\n",
      "After 13500 training steps,w1 is \n",
      "[[0.9982835]\n",
      " [1.0001147]] \n",
      "\n",
      "After 14000 training steps,w1 is \n",
      "[[0.9993659]\n",
      " [0.999166 ]] \n",
      "\n",
      "After 14500 training steps,w1 is \n",
      "[[1.0002553 ]\n",
      " [0.99838644]] \n",
      "\n",
      "Final w1 is:  [[1.0009792]\n",
      " [0.9977485]]\n"
     ]
    }
   ],
   "source": [
    "SEED = 23455\n",
    "\n",
    "rdm = np.random.RandomState(seed=SEED)  # 生成[0,1)之间的随机数\n",
    "x = rdm.rand(32, 2)\n",
    "y_ = [[x1 + x2 + (rdm.rand() / 10.0 - 0.05)] for (x1, x2) in x]  # 生成噪声[0,1)/10=[0,0.1); [0,0.1)-0.05=[-0.05,0.05)\n",
    "x = tf.cast(x, dtype=tf.float32)\n",
    "\n",
    "w1 = tf.Variable(tf.random.normal([2, 1], stddev=1, seed=1))\n",
    "\n",
    "epoch = 15000\n",
    "lr = 0.002\n",
    "\n",
    "for epoch in range(epoch):\n",
    "    with tf.GradientTape() as tape:\n",
    "        y = tf.matmul(x, w1)\n",
    "        loss_mse = tf.reduce_mean(tf.square(y_ - y))\n",
    "\n",
    "    grads = tape.gradient(loss_mse, w1)\n",
    "    w1.assign_sub(lr * grads)\n",
    "\n",
    "    if epoch % 500 == 0:\n",
    "        print(\"After %d training steps,w1 is \" % (epoch))\n",
    "        print(w1.numpy(), \"\\n\")\n",
    "print(\"Final w1 is: \", w1.numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3a02aed7",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 0 training steps,w1 is \n",
      "[[2.8786578]\n",
      " [3.2517848]] \n",
      "\n",
      "After 500 training steps,w1 is \n",
      "[[1.1460369]\n",
      " [1.0672572]] \n",
      "\n",
      "After 1000 training steps,w1 is \n",
      "[[1.1364173]\n",
      " [1.0985414]] \n",
      "\n",
      "After 1500 training steps,w1 is \n",
      "[[1.1267972]\n",
      " [1.1298251]] \n",
      "\n",
      "After 2000 training steps,w1 is \n",
      "[[1.1758107]\n",
      " [1.1724023]] \n",
      "\n",
      "After 2500 training steps,w1 is \n",
      "[[1.1453722]\n",
      " [1.0272155]] \n",
      "\n",
      "After 3000 training steps,w1 is \n",
      "[[1.1357522]\n",
      " [1.0584993]] \n",
      "\n",
      "After 3500 training steps,w1 is \n",
      "[[1.1261321]\n",
      " [1.0897831]] \n",
      "\n",
      "After 4000 training steps,w1 is \n",
      "[[1.1751455]\n",
      " [1.1323601]] \n",
      "\n",
      "After 4500 training steps,w1 is \n",
      "[[1.1655253]\n",
      " [1.1636437]] \n",
      "\n",
      "After 5000 training steps,w1 is \n",
      "[[1.1350871]\n",
      " [1.0184573]] \n",
      "\n",
      "After 5500 training steps,w1 is \n",
      "[[1.1254673]\n",
      " [1.0497413]] \n",
      "\n",
      "After 6000 training steps,w1 is \n",
      "[[1.1158477]\n",
      " [1.0810255]] \n",
      "\n",
      "After 6500 training steps,w1 is \n",
      "[[1.1062276]\n",
      " [1.1123092]] \n",
      "\n",
      "After 7000 training steps,w1 is \n",
      "[[1.1552413]\n",
      " [1.1548865]] \n",
      "\n",
      "After 7500 training steps,w1 is \n",
      "[[1.1248026]\n",
      " [1.0096996]] \n",
      "\n",
      "After 8000 training steps,w1 is \n",
      "[[1.1151826]\n",
      " [1.0409834]] \n",
      "\n",
      "After 8500 training steps,w1 is \n",
      "[[1.1055626]\n",
      " [1.0722672]] \n",
      "\n",
      "After 9000 training steps,w1 is \n",
      "[[1.1545763]\n",
      " [1.1148446]] \n",
      "\n",
      "After 9500 training steps,w1 is \n",
      "[[1.144956]\n",
      " [1.146128]] \n",
      "\n",
      "Final w1 is:  [[1.1255957]\n",
      " [1.0237043]]\n"
     ]
    }
   ],
   "source": [
    "SEED = 23455\n",
    "COST = 1\n",
    "PROFIT = 99\n",
    "\n",
    "rdm = np.random.RandomState(SEED)\n",
    "x = rdm.rand(32, 2)\n",
    "y_ = [[x1 + x2 + (rdm.rand() / 10.0 - 0.05)] for (x1, x2) in x]  # 生成噪声[0,1)/10=[0,0.1); [0,0.1)-0.05=[-0.05,0.05)\n",
    "x = tf.cast(x, dtype=tf.float32)\n",
    "\n",
    "w1 = tf.Variable(tf.random.normal([2, 1], stddev=1, seed=1))\n",
    "\n",
    "epoch = 10000\n",
    "lr = 0.002\n",
    "\n",
    "for epoch in range(epoch):\n",
    "    with tf.GradientTape() as tape:\n",
    "        y = tf.matmul(x, w1)\n",
    "        loss = tf.reduce_sum(tf.where(tf.greater(y, y_), (y - y_) * COST, (y_ - y) * PROFIT))\n",
    "\n",
    "    grads = tape.gradient(loss, w1)\n",
    "    w1.assign_sub(lr * grads)\n",
    "\n",
    "    if epoch % 500 == 0:\n",
    "        print(\"After %d training steps,w1 is \" % (epoch))\n",
    "        print(w1.numpy(), \"\\n\")\n",
    "print(\"Final w1 is: \", w1.numpy())\n",
    "\n",
    "# 自定义损失函数\n",
    "# 酸奶成本1元， 酸奶利润99元\n",
    "# 成本很低，利润很高，人们希望多预测些，生成模型系数大于1，往多了预测"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fce46162",
   "metadata": {},
   "source": [
    "交叉熵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a221b162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0.5108256, shape=(), dtype=float32)\n",
      "tf.Tensor(0.22314353, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "loss_ce1 = tf.losses.categorical_crossentropy([1,0],[0.6,0.4])\n",
    "loss_ce2 = tf.losses.categorical_crossentropy([1,0],[0.8,0.2])\n",
    "print(loss_ce1)\n",
    "print(loss_ce2)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d03f6e71",
   "metadata": {},
   "source": [
    "欠拟合，过拟合"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9611d048",
   "metadata": {},
   "source": [
    "正则化缓解过拟合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e71d3b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入所需模块\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "62e0eeae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读入数据/标签 生成x_train y_train\n",
    "df = pd.read_csv('dot.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4da771c2",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y_c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.416758</td>\n",
       "      <td>-0.056267</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.136196</td>\n",
       "      <td>1.640271</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.793436</td>\n",
       "      <td>-0.841747</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.502881</td>\n",
       "      <td>-1.245288</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.057952</td>\n",
       "      <td>-0.909008</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>-0.320935</td>\n",
       "      <td>0.249514</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>0.256308</td>\n",
       "      <td>0.767625</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>0.783020</td>\n",
       "      <td>-0.407063</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>-0.524892</td>\n",
       "      <td>-0.589809</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>-0.862531</td>\n",
       "      <td>-1.742873</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           x1        x2  y_c\n",
       "0   -0.416758 -0.056267    1\n",
       "1   -2.136196  1.640271    0\n",
       "2   -1.793436 -0.841747    0\n",
       "3    0.502881 -1.245288    1\n",
       "4   -1.057952 -0.909008    1\n",
       "..        ...       ...  ...\n",
       "295 -0.320935  0.249514    1\n",
       "296  0.256308  0.767625    1\n",
       "297  0.783020 -0.407063    1\n",
       "298 -0.524892 -0.589809    1\n",
       "299 -0.862531 -1.742873    0\n",
       "\n",
       "[300 rows x 3 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0a3fe4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = np.array(df[['x1', 'x2']])\n",
    "y_data = np.array(df['y_c'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7badd1a4",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-4.16757847e-01, -5.62668270e-02],\n",
       "       [-2.13619610e+00,  1.64027081e+00],\n",
       "       [-1.79343559e+00, -8.41747366e-01],\n",
       "       [ 5.02881417e-01, -1.24528809e+00],\n",
       "       [-1.05795222e+00, -9.09007615e-01],\n",
       "       [ 5.51454045e-01,  2.29220801e+00],\n",
       "       [ 4.15393930e-02, -1.11792545e+00],\n",
       "       [ 5.39058321e-01, -5.96159700e-01],\n",
       "       [-1.91304970e-02,  1.17500122e+00],\n",
       "       [-7.47870949e-01,  9.02525100e-03],\n",
       "       [-8.78107893e-01, -1.56434170e-01],\n",
       "       [ 2.56570452e-01, -9.88779049e-01],\n",
       "       [-3.38821966e-01, -2.36184031e-01],\n",
       "       [-6.37655012e-01, -1.18761229e+00],\n",
       "       [-1.42121723e+00, -1.53495196e-01],\n",
       "       [-2.69056960e-01,  2.23136679e+00],\n",
       "       [-2.43476758e+00,  1.12726505e-01],\n",
       "       [ 3.70444537e-01,  1.35963386e+00],\n",
       "       [ 5.01857207e-01, -8.44213704e-01],\n",
       "       [ 9.76000000e-06,  5.42352572e-01],\n",
       "       [-3.13508197e-01,  7.71011738e-01],\n",
       "       [-1.86809066e+00,  1.73118467e+00],\n",
       "       [ 1.46767801e+00, -3.35677339e-01],\n",
       "       [ 6.11340780e-01,  4.79705920e-02],\n",
       "       [-8.29135289e-01,  8.77102180e-02],\n",
       "       [ 1.00036589e+00, -3.81092518e-01],\n",
       "       [-3.75669423e-01, -7.44707630e-02],\n",
       "       [ 4.33496330e-01,  1.27837923e+00],\n",
       "       [-6.34679305e-01,  5.08396243e-01],\n",
       "       [ 2.16116006e-01, -1.85861239e+00],\n",
       "       [-4.19316482e-01, -1.32328898e-01],\n",
       "       [-3.95702400e-02,  3.26003433e-01],\n",
       "       [-2.04032305e+00,  4.62555230e-02],\n",
       "       [-6.77675577e-01, -1.43943903e+00],\n",
       "       [ 5.24296430e-01,  7.35279576e-01],\n",
       "       [-6.53250268e-01,  8.42456282e-01],\n",
       "       [-3.81516482e-01,  6.64890090e-02],\n",
       "       [-1.09873895e+00,  1.58448706e+00],\n",
       "       [-2.65944946e+00, -9.14526230e-02],\n",
       "       [ 6.95119605e-01, -2.03346655e+00],\n",
       "       [-1.89469265e-01, -7.72186650e-02],\n",
       "       [ 8.24703005e-01,  1.24821292e+00],\n",
       "       [-4.03892269e-01, -1.38451867e+00],\n",
       "       [ 1.36723542e+00,  1.21788563e+00],\n",
       "       [-4.62005348e-01,  3.50888494e-01],\n",
       "       [ 3.81866234e-01,  5.66275441e-01],\n",
       "       [ 2.04207979e-01,  1.40669624e+00],\n",
       "       [-1.73795950e+00,  1.04082395e+00],\n",
       "       [ 3.80471970e-01, -2.17135269e-01],\n",
       "       [ 1.17353150e+00, -2.34360319e+00],\n",
       "       [ 1.16152149e+00,  3.86078048e-01],\n",
       "       [-1.13313327e+00,  4.33092555e-01],\n",
       "       [-3.04086439e-01,  2.58529487e+00],\n",
       "       [ 1.83533272e+00,  4.40689872e-01],\n",
       "       [-7.19253841e-01, -5.83414595e-01],\n",
       "       [-3.25049628e-01, -5.60234506e-01],\n",
       "       [-9.02246068e-01, -5.90972275e-01],\n",
       "       [-2.76179492e-01, -5.16883894e-01],\n",
       "       [-6.98589950e-01, -9.28891925e-01],\n",
       "       [ 2.55043824e+00, -1.47317325e+00],\n",
       "       [-1.02141473e+00,  4.32395701e-01],\n",
       "       [-3.23580070e-01,  4.23824708e-01],\n",
       "       [ 7.99179995e-01,  1.26261366e+00],\n",
       "       [ 7.51964849e-01, -9.93760983e-01],\n",
       "       [ 1.10914328e+00, -1.76491773e+00],\n",
       "       [-1.14421297e-01, -4.98174194e-01],\n",
       "       [-1.06079904e+00,  5.91666521e-01],\n",
       "       [-1.83256574e-01,  1.01985473e+00],\n",
       "       [-1.48246548e+00,  8.46311892e-01],\n",
       "       [ 4.97940148e-01,  1.26504175e-01],\n",
       "       [-1.41881055e+00, -2.51774118e-01],\n",
       "       [-1.54667461e+00, -2.08265194e+00],\n",
       "       [ 3.27974540e+00,  9.70861320e-01],\n",
       "       [ 1.79259285e+00, -4.29013319e-01],\n",
       "       [ 6.96197980e-01,  6.97416272e-01],\n",
       "       [ 6.01515814e-01,  3.65949100e-03],\n",
       "       [-2.28247558e-01, -2.06961226e+00],\n",
       "       [ 6.10144086e-01,  4.23496900e-01],\n",
       "       [ 1.11788673e+00, -2.74242089e-01],\n",
       "       [ 1.74181219e+00, -4.47500876e-01],\n",
       "       [-1.25542722e+00,  9.38163671e-01],\n",
       "       [-4.68346260e-01, -1.25472031e+00],\n",
       "       [ 1.24823646e-01,  7.56502143e-01],\n",
       "       [ 2.41439629e-01,  4.97425649e-01],\n",
       "       [ 4.10869262e+00,  8.21120877e-01],\n",
       "       [ 1.53176032e+00, -1.98584577e+00],\n",
       "       [ 3.65053516e-01,  7.74082033e-01],\n",
       "       [-3.64479092e-01, -8.75979478e-01],\n",
       "       [ 3.96520159e-01, -3.14617436e-01],\n",
       "       [-5.93755583e-01,  1.14950057e+00],\n",
       "       [ 1.33556617e+00,  3.02629336e-01],\n",
       "       [-4.54227855e-01,  5.14370717e-01],\n",
       "       [ 8.29458431e-01,  6.30621967e-01],\n",
       "       [-1.45336435e+00, -3.38017777e-01],\n",
       "       [ 3.59133332e-01,  6.22220414e-01],\n",
       "       [ 9.60781945e-01,  7.58370347e-01],\n",
       "       [-1.13431848e+00, -7.07420888e-01],\n",
       "       [-1.22142916e+00,  1.80447664e+00],\n",
       "       [ 1.80409807e-01,  5.53164274e-01],\n",
       "       [ 1.03302907e+00, -3.29002435e-01],\n",
       "       [-1.15100294e+00, -4.26522471e-01],\n",
       "       [-1.48147191e-01,  1.50143691e+00],\n",
       "       [ 8.69598198e-01, -1.08709057e+00],\n",
       "       [ 6.64221413e-01,  7.34884668e-01],\n",
       "       [-1.06136574e+00, -1.08516824e-01],\n",
       "       [-1.85040397e+00,  3.30488064e-01],\n",
       "       [-3.15693210e-01, -1.35000210e+00],\n",
       "       [-6.98170998e-01,  2.39951198e-01],\n",
       "       [-5.52949440e-01,  2.99526813e-01],\n",
       "       [ 5.52663696e-01, -8.40443012e-01],\n",
       "       [-3.12270670e-01,  2.14467809e+00],\n",
       "       [ 1.21105582e-01, -8.46828752e-01],\n",
       "       [ 6.04624490e-02, -1.33858888e+00],\n",
       "       [ 1.13274608e+00,  3.70304843e-01],\n",
       "       [ 1.08580640e+00,  9.02179395e-01],\n",
       "       [ 3.90296450e-01,  9.75509412e-01],\n",
       "       [ 1.91573647e-01, -6.62209012e-01],\n",
       "       [-1.02351499e+00, -4.48174823e-01],\n",
       "       [-2.50545813e+00,  1.82599446e+00],\n",
       "       [-1.71406741e+00, -7.66395640e-02],\n",
       "       [-1.31756727e+00, -2.02559359e+00],\n",
       "       [-8.22453750e-02, -3.04666585e-01],\n",
       "       [-1.59724130e-01,  5.48946560e-01],\n",
       "       [-6.18375485e-01,  3.78794466e-01],\n",
       "       [ 5.13251444e-01, -3.34844125e-01],\n",
       "       [-2.83519516e-01,  5.38424263e-01],\n",
       "       [ 5.72509470e-02,  1.59088487e-01],\n",
       "       [-2.37440268e+00,  5.85199350e-02],\n",
       "       [ 3.76545911e-01, -1.35479764e-01],\n",
       "       [ 3.35908395e-01,  1.90437591e+00],\n",
       "       [ 8.53644330e-02,  6.65334278e-01],\n",
       "       [-8.49995503e-01, -8.52341797e-01],\n",
       "       [-4.79985112e-01, -1.01964910e+00],\n",
       "       [-7.60113800e-03, -9.33830661e-01],\n",
       "       [-1.74996844e-01, -1.43714343e+00],\n",
       "       [-1.65220029e+00, -6.75661789e-01],\n",
       "       [-1.06706712e+00, -6.52931145e-01],\n",
       "       [-6.12094750e-01, -3.51262461e-01],\n",
       "       [ 1.04547799e+00,  1.36901602e+00],\n",
       "       [ 7.25353259e-01, -3.59474459e-01],\n",
       "       [ 1.49695179e+00, -1.53111111e+00],\n",
       "       [-2.02336394e+00,  2.67972576e-01],\n",
       "       [-2.20644500e-03, -1.39291883e-01],\n",
       "       [ 3.25654690e-02, -1.64056022e+00],\n",
       "       [-1.15669917e+00,  1.23403468e+00],\n",
       "       [ 1.02818490e+00, -7.21879726e-01],\n",
       "       [ 1.93315697e+00, -1.07079633e+00],\n",
       "       [-5.71381608e-01,  2.92432067e-01],\n",
       "       [-1.19499990e+00, -4.87930544e-01],\n",
       "       [-1.73071165e-01, -3.95346401e-01],\n",
       "       [ 8.70840765e-01,  5.92806797e-01],\n",
       "       [-1.09929731e+00, -6.81530644e-01],\n",
       "       [ 1.80066685e-01, -6.69310440e-02],\n",
       "       [-7.87749540e-01,  4.24753672e-01],\n",
       "       [ 8.19885117e-01, -6.31118683e-01],\n",
       "       [ 7.89059649e-01, -1.62167380e+00],\n",
       "       [-1.61049926e+00,  4.99939764e-01],\n",
       "       [-8.34515207e-01, -9.96959687e-01],\n",
       "       [-2.63388077e-01, -6.77360492e-01],\n",
       "       [ 3.27067038e-01, -1.45535945e+00],\n",
       "       [-3.71519124e-01,  3.16096597e+00],\n",
       "       [ 1.09951013e-01, -1.91352322e+00],\n",
       "       [ 5.99820429e-01,  5.49384465e-01],\n",
       "       [ 1.38378103e+00,  1.48349243e-01],\n",
       "       [-6.53541444e-01,  1.40883398e+00],\n",
       "       [ 7.12061227e-01, -1.80071604e+00],\n",
       "       [ 7.47598942e-01, -2.32897001e-01],\n",
       "       [ 1.11064528e+00, -3.73338813e-01],\n",
       "       [ 7.86146070e-01,  1.94168696e-01],\n",
       "       [ 5.86204098e-01, -2.03872920e-02],\n",
       "       [-4.14408598e-01,  6.73134120e-02],\n",
       "       [ 6.31798924e-01,  4.17592731e-01],\n",
       "       [ 1.61517627e+00,  4.25606211e-01],\n",
       "       [ 6.35363758e-01,  2.10222927e+00],\n",
       "       [ 6.61264170e-02,  5.35558351e-01],\n",
       "       [-6.03140792e-01,  4.19576290e-02],\n",
       "       [ 1.64191464e+00,  3.11697707e-01],\n",
       "       [ 1.45116990e+00, -1.06492788e+00],\n",
       "       [-1.40084546e+00,  3.07525527e-01],\n",
       "       [-1.36963867e+00,  2.67033724e+00],\n",
       "       [ 1.24845030e+00, -1.24572655e+00],\n",
       "       [-1.67168774e-01, -5.76610930e-01],\n",
       "       [ 4.16021749e-01, -5.78472630e-02],\n",
       "       [ 9.31887358e-01,  1.46833213e+00],\n",
       "       [-2.21320943e-01, -1.17315562e+00],\n",
       "       [ 5.62669078e-01, -1.64515057e-01],\n",
       "       [ 1.14485538e+00, -1.52117687e-01],\n",
       "       [ 8.29789046e-01,  3.36065952e-01],\n",
       "       [-1.89044051e-01, -4.49328601e-01],\n",
       "       [ 7.13524448e-01,  2.52973487e+00],\n",
       "       [ 8.37615794e-01, -1.31682403e-01],\n",
       "       [ 7.07592866e-01,  1.14053878e-01],\n",
       "       [-1.28089518e+00,  3.09846277e-01],\n",
       "       [ 1.54829069e+00, -3.15828043e-01],\n",
       "       [-1.12590378e+00,  4.88496666e-01],\n",
       "       [ 1.83094666e+00,  9.40175993e-01],\n",
       "       [ 1.01871705e+00,  2.30237829e+00],\n",
       "       [ 1.62109298e+00,  7.12683273e-01],\n",
       "       [-2.08703629e-01,  1.37617991e-01],\n",
       "       [-1.03352168e-01,  8.48350567e-01],\n",
       "       [-8.83125561e-01,  1.54538683e+00],\n",
       "       [ 1.45840073e-01, -4.00106056e-01],\n",
       "       [ 8.15206041e-01, -2.07492236e+00],\n",
       "       [-8.34437391e-01, -6.57718447e-01],\n",
       "       [ 8.20564332e-01, -4.89157001e-01],\n",
       "       [ 1.42496703e+00, -4.46857897e-01],\n",
       "       [ 5.21109431e-01, -7.08194380e-01],\n",
       "       [ 1.15553059e+00, -2.54530459e-01],\n",
       "       [ 5.18924924e-01, -4.92994911e-01],\n",
       "       [-1.08654815e+00, -2.30917497e-01],\n",
       "       [ 1.09801004e+00, -1.01787805e+00],\n",
       "       [-1.52939136e+00, -3.07987737e-01],\n",
       "       [ 7.80754356e-01, -1.05583964e+00],\n",
       "       [-5.43883381e-01,  1.84301739e-01],\n",
       "       [-3.30675843e-01,  2.87208202e-01],\n",
       "       [ 1.18952814e+00,  2.12015480e-02],\n",
       "       [-6.54096800e-02,  7.66115904e-01],\n",
       "       [-6.16350850e-02, -9.52897152e-01],\n",
       "       [-1.01446306e+00, -1.11526396e+00],\n",
       "       [ 1.91260068e+00, -4.52632030e-02],\n",
       "       [ 5.76909718e-01,  7.17805695e-01],\n",
       "       [-9.38998998e-01,  6.28775807e-01],\n",
       "       [-5.64493432e-01, -2.08780746e+00],\n",
       "       [-2.15050132e-01, -1.07502856e+00],\n",
       "       [-3.37972149e-01,  3.43212732e-01],\n",
       "       [ 2.28253964e+00, -4.95778848e-01],\n",
       "       [-1.63962832e-01,  3.71622161e-01],\n",
       "       [ 1.86521520e-01, -1.58429224e-01],\n",
       "       [-1.08292956e+00, -9.56625520e-01],\n",
       "       [-1.83376735e-01, -1.15980690e+00],\n",
       "       [-6.57768362e-01, -1.25144841e+00],\n",
       "       [ 1.12448286e+00, -1.49783981e+00],\n",
       "       [ 1.90201722e+00, -5.80383038e-01],\n",
       "       [-1.05491567e+00, -1.18275720e+00],\n",
       "       [ 7.79480054e-01,  1.02659795e+00],\n",
       "       [-8.48666001e-01,  3.31539648e-01],\n",
       "       [-1.49591353e-01, -2.42440600e-01],\n",
       "       [ 1.51197175e-01,  7.65069481e-01],\n",
       "       [-1.91663052e+00, -2.22734129e+00],\n",
       "       [ 2.06689897e-01, -7.08763560e-02],\n",
       "       [ 6.84759969e-01, -1.70753905e+00],\n",
       "       [-9.86569665e-01,  1.54353634e+00],\n",
       "       [-1.31027053e+00,  3.63433972e-01],\n",
       "       [-7.94872445e-01, -4.05286267e-01],\n",
       "       [-1.37775793e+00,  1.18604868e+00],\n",
       "       [-1.90382114e+00, -1.19814038e+00],\n",
       "       [-9.10065643e-01,  1.17645419e+00],\n",
       "       [ 2.99210670e-01,  6.79267178e-01],\n",
       "       [-1.76606800e-02,  2.36040923e-01],\n",
       "       [ 4.94035871e-01,  1.54627765e+00],\n",
       "       [ 2.46857508e-01, -1.46877580e+00],\n",
       "       [ 1.14709994e+00,  9.55569850e-02],\n",
       "       [-1.10743873e+00, -1.76286141e-01],\n",
       "       [-9.82755667e-01,  2.08668273e+00],\n",
       "       [-3.44623671e-01, -2.00207923e+00],\n",
       "       [ 3.03234433e-01, -8.29874845e-01],\n",
       "       [ 1.28876941e+00,  1.34925462e-01],\n",
       "       [-1.77860064e+00, -5.00791490e-01],\n",
       "       [-1.08816157e+00, -7.57855553e-01],\n",
       "       [-6.43744900e-01, -2.00878453e+00],\n",
       "       [ 1.96262894e-01, -8.75896370e-01],\n",
       "       [-8.93609209e-01,  7.51902355e-01],\n",
       "       [ 1.89693224e+00, -6.29079151e-01],\n",
       "       [ 1.81208553e+00, -2.05626574e+00],\n",
       "       [ 5.62704887e-01, -5.82070757e-01],\n",
       "       [-7.40029750e-02, -9.86496364e-01],\n",
       "       [-5.94722499e-01, -3.14811843e-01],\n",
       "       [-3.46940532e-01,  4.11443516e-01],\n",
       "       [ 2.32639090e+00, -6.34053128e-01],\n",
       "       [-1.54409962e-01, -1.74928880e+00],\n",
       "       [-2.51957930e+00,  1.39116243e+00],\n",
       "       [-1.32934644e+00, -7.45596414e-01],\n",
       "       [ 2.12608500e-02,  9.10917515e-01],\n",
       "       [ 3.15276082e-01,  1.86620820e+00],\n",
       "       [-1.82497623e-01, -1.82826634e+00],\n",
       "       [ 1.38955717e-01,  1.19450165e-01],\n",
       "       [-8.18899200e-01, -3.32639265e-01],\n",
       "       [-5.86387955e-01,  1.73451634e+00],\n",
       "       [-6.12751558e-01, -1.39344202e+00],\n",
       "       [ 2.79433757e-01, -1.82223127e+00],\n",
       "       [ 4.27017458e-01,  4.06987749e-01],\n",
       "       [-8.44308241e-01, -5.59820113e-01],\n",
       "       [-6.00520405e-01,  1.61487324e+00],\n",
       "       [ 3.94953220e-01, -1.20381347e+00],\n",
       "       [-1.24747243e+00, -7.75462500e-02],\n",
       "       [-1.33397510e-02, -7.68323250e-01],\n",
       "       [ 2.91234010e-01, -1.97330948e-01],\n",
       "       [ 1.07682965e+00,  4.37410232e-01],\n",
       "       [-9.31978660e-02,  1.35631416e-01],\n",
       "       [-8.82708822e-01,  8.84744194e-01],\n",
       "       [ 3.83204463e-01, -4.16994149e-01],\n",
       "       [ 1.17796550e-01, -5.36685309e-01],\n",
       "       [ 2.48718458e+00, -4.51361054e-01],\n",
       "       [ 5.18836127e-01,  3.64448005e-01],\n",
       "       [-7.98348729e-01,  5.65779700e-03],\n",
       "       [-3.20934708e-01,  2.49513550e-01],\n",
       "       [ 2.56308392e-01,  7.67625083e-01],\n",
       "       [ 7.83020087e-01, -4.07063047e-01],\n",
       "       [-5.24891667e-01, -5.89808683e-01],\n",
       "       [-8.62531086e-01, -1.74287290e+00]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ad6c7f00",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0,\n",
       "       0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0,\n",
       "       1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1,\n",
       "       1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1,\n",
       "       1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0,\n",
       "       1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "       1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "       1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0,\n",
       "       1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e22feb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_data\n",
    "y_train = y_data.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "11506aa6",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-4.16757847e-01, -5.62668270e-02],\n",
       "       [-2.13619610e+00,  1.64027081e+00],\n",
       "       [-1.79343559e+00, -8.41747366e-01],\n",
       "       [ 5.02881417e-01, -1.24528809e+00],\n",
       "       [-1.05795222e+00, -9.09007615e-01],\n",
       "       [ 5.51454045e-01,  2.29220801e+00],\n",
       "       [ 4.15393930e-02, -1.11792545e+00],\n",
       "       [ 5.39058321e-01, -5.96159700e-01],\n",
       "       [-1.91304970e-02,  1.17500122e+00],\n",
       "       [-7.47870949e-01,  9.02525100e-03],\n",
       "       [-8.78107893e-01, -1.56434170e-01],\n",
       "       [ 2.56570452e-01, -9.88779049e-01],\n",
       "       [-3.38821966e-01, -2.36184031e-01],\n",
       "       [-6.37655012e-01, -1.18761229e+00],\n",
       "       [-1.42121723e+00, -1.53495196e-01],\n",
       "       [-2.69056960e-01,  2.23136679e+00],\n",
       "       [-2.43476758e+00,  1.12726505e-01],\n",
       "       [ 3.70444537e-01,  1.35963386e+00],\n",
       "       [ 5.01857207e-01, -8.44213704e-01],\n",
       "       [ 9.76000000e-06,  5.42352572e-01],\n",
       "       [-3.13508197e-01,  7.71011738e-01],\n",
       "       [-1.86809066e+00,  1.73118467e+00],\n",
       "       [ 1.46767801e+00, -3.35677339e-01],\n",
       "       [ 6.11340780e-01,  4.79705920e-02],\n",
       "       [-8.29135289e-01,  8.77102180e-02],\n",
       "       [ 1.00036589e+00, -3.81092518e-01],\n",
       "       [-3.75669423e-01, -7.44707630e-02],\n",
       "       [ 4.33496330e-01,  1.27837923e+00],\n",
       "       [-6.34679305e-01,  5.08396243e-01],\n",
       "       [ 2.16116006e-01, -1.85861239e+00],\n",
       "       [-4.19316482e-01, -1.32328898e-01],\n",
       "       [-3.95702400e-02,  3.26003433e-01],\n",
       "       [-2.04032305e+00,  4.62555230e-02],\n",
       "       [-6.77675577e-01, -1.43943903e+00],\n",
       "       [ 5.24296430e-01,  7.35279576e-01],\n",
       "       [-6.53250268e-01,  8.42456282e-01],\n",
       "       [-3.81516482e-01,  6.64890090e-02],\n",
       "       [-1.09873895e+00,  1.58448706e+00],\n",
       "       [-2.65944946e+00, -9.14526230e-02],\n",
       "       [ 6.95119605e-01, -2.03346655e+00],\n",
       "       [-1.89469265e-01, -7.72186650e-02],\n",
       "       [ 8.24703005e-01,  1.24821292e+00],\n",
       "       [-4.03892269e-01, -1.38451867e+00],\n",
       "       [ 1.36723542e+00,  1.21788563e+00],\n",
       "       [-4.62005348e-01,  3.50888494e-01],\n",
       "       [ 3.81866234e-01,  5.66275441e-01],\n",
       "       [ 2.04207979e-01,  1.40669624e+00],\n",
       "       [-1.73795950e+00,  1.04082395e+00],\n",
       "       [ 3.80471970e-01, -2.17135269e-01],\n",
       "       [ 1.17353150e+00, -2.34360319e+00],\n",
       "       [ 1.16152149e+00,  3.86078048e-01],\n",
       "       [-1.13313327e+00,  4.33092555e-01],\n",
       "       [-3.04086439e-01,  2.58529487e+00],\n",
       "       [ 1.83533272e+00,  4.40689872e-01],\n",
       "       [-7.19253841e-01, -5.83414595e-01],\n",
       "       [-3.25049628e-01, -5.60234506e-01],\n",
       "       [-9.02246068e-01, -5.90972275e-01],\n",
       "       [-2.76179492e-01, -5.16883894e-01],\n",
       "       [-6.98589950e-01, -9.28891925e-01],\n",
       "       [ 2.55043824e+00, -1.47317325e+00],\n",
       "       [-1.02141473e+00,  4.32395701e-01],\n",
       "       [-3.23580070e-01,  4.23824708e-01],\n",
       "       [ 7.99179995e-01,  1.26261366e+00],\n",
       "       [ 7.51964849e-01, -9.93760983e-01],\n",
       "       [ 1.10914328e+00, -1.76491773e+00],\n",
       "       [-1.14421297e-01, -4.98174194e-01],\n",
       "       [-1.06079904e+00,  5.91666521e-01],\n",
       "       [-1.83256574e-01,  1.01985473e+00],\n",
       "       [-1.48246548e+00,  8.46311892e-01],\n",
       "       [ 4.97940148e-01,  1.26504175e-01],\n",
       "       [-1.41881055e+00, -2.51774118e-01],\n",
       "       [-1.54667461e+00, -2.08265194e+00],\n",
       "       [ 3.27974540e+00,  9.70861320e-01],\n",
       "       [ 1.79259285e+00, -4.29013319e-01],\n",
       "       [ 6.96197980e-01,  6.97416272e-01],\n",
       "       [ 6.01515814e-01,  3.65949100e-03],\n",
       "       [-2.28247558e-01, -2.06961226e+00],\n",
       "       [ 6.10144086e-01,  4.23496900e-01],\n",
       "       [ 1.11788673e+00, -2.74242089e-01],\n",
       "       [ 1.74181219e+00, -4.47500876e-01],\n",
       "       [-1.25542722e+00,  9.38163671e-01],\n",
       "       [-4.68346260e-01, -1.25472031e+00],\n",
       "       [ 1.24823646e-01,  7.56502143e-01],\n",
       "       [ 2.41439629e-01,  4.97425649e-01],\n",
       "       [ 4.10869262e+00,  8.21120877e-01],\n",
       "       [ 1.53176032e+00, -1.98584577e+00],\n",
       "       [ 3.65053516e-01,  7.74082033e-01],\n",
       "       [-3.64479092e-01, -8.75979478e-01],\n",
       "       [ 3.96520159e-01, -3.14617436e-01],\n",
       "       [-5.93755583e-01,  1.14950057e+00],\n",
       "       [ 1.33556617e+00,  3.02629336e-01],\n",
       "       [-4.54227855e-01,  5.14370717e-01],\n",
       "       [ 8.29458431e-01,  6.30621967e-01],\n",
       "       [-1.45336435e+00, -3.38017777e-01],\n",
       "       [ 3.59133332e-01,  6.22220414e-01],\n",
       "       [ 9.60781945e-01,  7.58370347e-01],\n",
       "       [-1.13431848e+00, -7.07420888e-01],\n",
       "       [-1.22142916e+00,  1.80447664e+00],\n",
       "       [ 1.80409807e-01,  5.53164274e-01],\n",
       "       [ 1.03302907e+00, -3.29002435e-01],\n",
       "       [-1.15100294e+00, -4.26522471e-01],\n",
       "       [-1.48147191e-01,  1.50143691e+00],\n",
       "       [ 8.69598198e-01, -1.08709057e+00],\n",
       "       [ 6.64221413e-01,  7.34884668e-01],\n",
       "       [-1.06136574e+00, -1.08516824e-01],\n",
       "       [-1.85040397e+00,  3.30488064e-01],\n",
       "       [-3.15693210e-01, -1.35000210e+00],\n",
       "       [-6.98170998e-01,  2.39951198e-01],\n",
       "       [-5.52949440e-01,  2.99526813e-01],\n",
       "       [ 5.52663696e-01, -8.40443012e-01],\n",
       "       [-3.12270670e-01,  2.14467809e+00],\n",
       "       [ 1.21105582e-01, -8.46828752e-01],\n",
       "       [ 6.04624490e-02, -1.33858888e+00],\n",
       "       [ 1.13274608e+00,  3.70304843e-01],\n",
       "       [ 1.08580640e+00,  9.02179395e-01],\n",
       "       [ 3.90296450e-01,  9.75509412e-01],\n",
       "       [ 1.91573647e-01, -6.62209012e-01],\n",
       "       [-1.02351499e+00, -4.48174823e-01],\n",
       "       [-2.50545813e+00,  1.82599446e+00],\n",
       "       [-1.71406741e+00, -7.66395640e-02],\n",
       "       [-1.31756727e+00, -2.02559359e+00],\n",
       "       [-8.22453750e-02, -3.04666585e-01],\n",
       "       [-1.59724130e-01,  5.48946560e-01],\n",
       "       [-6.18375485e-01,  3.78794466e-01],\n",
       "       [ 5.13251444e-01, -3.34844125e-01],\n",
       "       [-2.83519516e-01,  5.38424263e-01],\n",
       "       [ 5.72509470e-02,  1.59088487e-01],\n",
       "       [-2.37440268e+00,  5.85199350e-02],\n",
       "       [ 3.76545911e-01, -1.35479764e-01],\n",
       "       [ 3.35908395e-01,  1.90437591e+00],\n",
       "       [ 8.53644330e-02,  6.65334278e-01],\n",
       "       [-8.49995503e-01, -8.52341797e-01],\n",
       "       [-4.79985112e-01, -1.01964910e+00],\n",
       "       [-7.60113800e-03, -9.33830661e-01],\n",
       "       [-1.74996844e-01, -1.43714343e+00],\n",
       "       [-1.65220029e+00, -6.75661789e-01],\n",
       "       [-1.06706712e+00, -6.52931145e-01],\n",
       "       [-6.12094750e-01, -3.51262461e-01],\n",
       "       [ 1.04547799e+00,  1.36901602e+00],\n",
       "       [ 7.25353259e-01, -3.59474459e-01],\n",
       "       [ 1.49695179e+00, -1.53111111e+00],\n",
       "       [-2.02336394e+00,  2.67972576e-01],\n",
       "       [-2.20644500e-03, -1.39291883e-01],\n",
       "       [ 3.25654690e-02, -1.64056022e+00],\n",
       "       [-1.15669917e+00,  1.23403468e+00],\n",
       "       [ 1.02818490e+00, -7.21879726e-01],\n",
       "       [ 1.93315697e+00, -1.07079633e+00],\n",
       "       [-5.71381608e-01,  2.92432067e-01],\n",
       "       [-1.19499990e+00, -4.87930544e-01],\n",
       "       [-1.73071165e-01, -3.95346401e-01],\n",
       "       [ 8.70840765e-01,  5.92806797e-01],\n",
       "       [-1.09929731e+00, -6.81530644e-01],\n",
       "       [ 1.80066685e-01, -6.69310440e-02],\n",
       "       [-7.87749540e-01,  4.24753672e-01],\n",
       "       [ 8.19885117e-01, -6.31118683e-01],\n",
       "       [ 7.89059649e-01, -1.62167380e+00],\n",
       "       [-1.61049926e+00,  4.99939764e-01],\n",
       "       [-8.34515207e-01, -9.96959687e-01],\n",
       "       [-2.63388077e-01, -6.77360492e-01],\n",
       "       [ 3.27067038e-01, -1.45535945e+00],\n",
       "       [-3.71519124e-01,  3.16096597e+00],\n",
       "       [ 1.09951013e-01, -1.91352322e+00],\n",
       "       [ 5.99820429e-01,  5.49384465e-01],\n",
       "       [ 1.38378103e+00,  1.48349243e-01],\n",
       "       [-6.53541444e-01,  1.40883398e+00],\n",
       "       [ 7.12061227e-01, -1.80071604e+00],\n",
       "       [ 7.47598942e-01, -2.32897001e-01],\n",
       "       [ 1.11064528e+00, -3.73338813e-01],\n",
       "       [ 7.86146070e-01,  1.94168696e-01],\n",
       "       [ 5.86204098e-01, -2.03872920e-02],\n",
       "       [-4.14408598e-01,  6.73134120e-02],\n",
       "       [ 6.31798924e-01,  4.17592731e-01],\n",
       "       [ 1.61517627e+00,  4.25606211e-01],\n",
       "       [ 6.35363758e-01,  2.10222927e+00],\n",
       "       [ 6.61264170e-02,  5.35558351e-01],\n",
       "       [-6.03140792e-01,  4.19576290e-02],\n",
       "       [ 1.64191464e+00,  3.11697707e-01],\n",
       "       [ 1.45116990e+00, -1.06492788e+00],\n",
       "       [-1.40084546e+00,  3.07525527e-01],\n",
       "       [-1.36963867e+00,  2.67033724e+00],\n",
       "       [ 1.24845030e+00, -1.24572655e+00],\n",
       "       [-1.67168774e-01, -5.76610930e-01],\n",
       "       [ 4.16021749e-01, -5.78472630e-02],\n",
       "       [ 9.31887358e-01,  1.46833213e+00],\n",
       "       [-2.21320943e-01, -1.17315562e+00],\n",
       "       [ 5.62669078e-01, -1.64515057e-01],\n",
       "       [ 1.14485538e+00, -1.52117687e-01],\n",
       "       [ 8.29789046e-01,  3.36065952e-01],\n",
       "       [-1.89044051e-01, -4.49328601e-01],\n",
       "       [ 7.13524448e-01,  2.52973487e+00],\n",
       "       [ 8.37615794e-01, -1.31682403e-01],\n",
       "       [ 7.07592866e-01,  1.14053878e-01],\n",
       "       [-1.28089518e+00,  3.09846277e-01],\n",
       "       [ 1.54829069e+00, -3.15828043e-01],\n",
       "       [-1.12590378e+00,  4.88496666e-01],\n",
       "       [ 1.83094666e+00,  9.40175993e-01],\n",
       "       [ 1.01871705e+00,  2.30237829e+00],\n",
       "       [ 1.62109298e+00,  7.12683273e-01],\n",
       "       [-2.08703629e-01,  1.37617991e-01],\n",
       "       [-1.03352168e-01,  8.48350567e-01],\n",
       "       [-8.83125561e-01,  1.54538683e+00],\n",
       "       [ 1.45840073e-01, -4.00106056e-01],\n",
       "       [ 8.15206041e-01, -2.07492236e+00],\n",
       "       [-8.34437391e-01, -6.57718447e-01],\n",
       "       [ 8.20564332e-01, -4.89157001e-01],\n",
       "       [ 1.42496703e+00, -4.46857897e-01],\n",
       "       [ 5.21109431e-01, -7.08194380e-01],\n",
       "       [ 1.15553059e+00, -2.54530459e-01],\n",
       "       [ 5.18924924e-01, -4.92994911e-01],\n",
       "       [-1.08654815e+00, -2.30917497e-01],\n",
       "       [ 1.09801004e+00, -1.01787805e+00],\n",
       "       [-1.52939136e+00, -3.07987737e-01],\n",
       "       [ 7.80754356e-01, -1.05583964e+00],\n",
       "       [-5.43883381e-01,  1.84301739e-01],\n",
       "       [-3.30675843e-01,  2.87208202e-01],\n",
       "       [ 1.18952814e+00,  2.12015480e-02],\n",
       "       [-6.54096800e-02,  7.66115904e-01],\n",
       "       [-6.16350850e-02, -9.52897152e-01],\n",
       "       [-1.01446306e+00, -1.11526396e+00],\n",
       "       [ 1.91260068e+00, -4.52632030e-02],\n",
       "       [ 5.76909718e-01,  7.17805695e-01],\n",
       "       [-9.38998998e-01,  6.28775807e-01],\n",
       "       [-5.64493432e-01, -2.08780746e+00],\n",
       "       [-2.15050132e-01, -1.07502856e+00],\n",
       "       [-3.37972149e-01,  3.43212732e-01],\n",
       "       [ 2.28253964e+00, -4.95778848e-01],\n",
       "       [-1.63962832e-01,  3.71622161e-01],\n",
       "       [ 1.86521520e-01, -1.58429224e-01],\n",
       "       [-1.08292956e+00, -9.56625520e-01],\n",
       "       [-1.83376735e-01, -1.15980690e+00],\n",
       "       [-6.57768362e-01, -1.25144841e+00],\n",
       "       [ 1.12448286e+00, -1.49783981e+00],\n",
       "       [ 1.90201722e+00, -5.80383038e-01],\n",
       "       [-1.05491567e+00, -1.18275720e+00],\n",
       "       [ 7.79480054e-01,  1.02659795e+00],\n",
       "       [-8.48666001e-01,  3.31539648e-01],\n",
       "       [-1.49591353e-01, -2.42440600e-01],\n",
       "       [ 1.51197175e-01,  7.65069481e-01],\n",
       "       [-1.91663052e+00, -2.22734129e+00],\n",
       "       [ 2.06689897e-01, -7.08763560e-02],\n",
       "       [ 6.84759969e-01, -1.70753905e+00],\n",
       "       [-9.86569665e-01,  1.54353634e+00],\n",
       "       [-1.31027053e+00,  3.63433972e-01],\n",
       "       [-7.94872445e-01, -4.05286267e-01],\n",
       "       [-1.37775793e+00,  1.18604868e+00],\n",
       "       [-1.90382114e+00, -1.19814038e+00],\n",
       "       [-9.10065643e-01,  1.17645419e+00],\n",
       "       [ 2.99210670e-01,  6.79267178e-01],\n",
       "       [-1.76606800e-02,  2.36040923e-01],\n",
       "       [ 4.94035871e-01,  1.54627765e+00],\n",
       "       [ 2.46857508e-01, -1.46877580e+00],\n",
       "       [ 1.14709994e+00,  9.55569850e-02],\n",
       "       [-1.10743873e+00, -1.76286141e-01],\n",
       "       [-9.82755667e-01,  2.08668273e+00],\n",
       "       [-3.44623671e-01, -2.00207923e+00],\n",
       "       [ 3.03234433e-01, -8.29874845e-01],\n",
       "       [ 1.28876941e+00,  1.34925462e-01],\n",
       "       [-1.77860064e+00, -5.00791490e-01],\n",
       "       [-1.08816157e+00, -7.57855553e-01],\n",
       "       [-6.43744900e-01, -2.00878453e+00],\n",
       "       [ 1.96262894e-01, -8.75896370e-01],\n",
       "       [-8.93609209e-01,  7.51902355e-01],\n",
       "       [ 1.89693224e+00, -6.29079151e-01],\n",
       "       [ 1.81208553e+00, -2.05626574e+00],\n",
       "       [ 5.62704887e-01, -5.82070757e-01],\n",
       "       [-7.40029750e-02, -9.86496364e-01],\n",
       "       [-5.94722499e-01, -3.14811843e-01],\n",
       "       [-3.46940532e-01,  4.11443516e-01],\n",
       "       [ 2.32639090e+00, -6.34053128e-01],\n",
       "       [-1.54409962e-01, -1.74928880e+00],\n",
       "       [-2.51957930e+00,  1.39116243e+00],\n",
       "       [-1.32934644e+00, -7.45596414e-01],\n",
       "       [ 2.12608500e-02,  9.10917515e-01],\n",
       "       [ 3.15276082e-01,  1.86620820e+00],\n",
       "       [-1.82497623e-01, -1.82826634e+00],\n",
       "       [ 1.38955717e-01,  1.19450165e-01],\n",
       "       [-8.18899200e-01, -3.32639265e-01],\n",
       "       [-5.86387955e-01,  1.73451634e+00],\n",
       "       [-6.12751558e-01, -1.39344202e+00],\n",
       "       [ 2.79433757e-01, -1.82223127e+00],\n",
       "       [ 4.27017458e-01,  4.06987749e-01],\n",
       "       [-8.44308241e-01, -5.59820113e-01],\n",
       "       [-6.00520405e-01,  1.61487324e+00],\n",
       "       [ 3.94953220e-01, -1.20381347e+00],\n",
       "       [-1.24747243e+00, -7.75462500e-02],\n",
       "       [-1.33397510e-02, -7.68323250e-01],\n",
       "       [ 2.91234010e-01, -1.97330948e-01],\n",
       "       [ 1.07682965e+00,  4.37410232e-01],\n",
       "       [-9.31978660e-02,  1.35631416e-01],\n",
       "       [-8.82708822e-01,  8.84744194e-01],\n",
       "       [ 3.83204463e-01, -4.16994149e-01],\n",
       "       [ 1.17796550e-01, -5.36685309e-01],\n",
       "       [ 2.48718458e+00, -4.51361054e-01],\n",
       "       [ 5.18836127e-01,  3.64448005e-01],\n",
       "       [-7.98348729e-01,  5.65779700e-03],\n",
       "       [-3.20934708e-01,  2.49513550e-01],\n",
       "       [ 2.56308392e-01,  7.67625083e-01],\n",
       "       [ 7.83020087e-01, -4.07063047e-01],\n",
       "       [-5.24891667e-01, -5.89808683e-01],\n",
       "       [-8.62531086e-01, -1.74287290e+00]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "573bf76a",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0]], dtype=int64)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ce2941c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_c = [['red' if y else 'blue'] for y in y_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "71871ff3",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['red'],\n",
       " ['blue'],\n",
       " ['blue'],\n",
       " ['red'],\n",
       " ['red'],\n",
       " ['blue'],\n",
       " ['red'],\n",
       " ['red'],\n",
       " ['red'],\n",
       " ['red'],\n",
       " ['red'],\n",
       " ['red'],\n",
       " ['red'],\n",
       " ['red'],\n",
       " ['blue'],\n",
       " ['blue'],\n",
       " ['blue'],\n",
       " ['red'],\n",
       " ['red'],\n",
       " ['red'],\n",
       " ['red'],\n",
       " ['blue'],\n",
       " ['blue'],\n",
       " ['red'],\n",
       " ['red'],\n",
       " ['red'],\n",
       " ['red'],\n",
       " ['red'],\n",
       " ['red'],\n",
       " ['blue'],\n",
       " ['red'],\n",
       " ['red'],\n",
       " ['blue'],\n",
       " ['blue'],\n",
       " ['red'],\n",
       " ['red'],\n",
       " ['red'],\n",
       " ['blue'],\n",
       " ['blue'],\n",
       " ['blue'],\n",
       " ['red'],\n",
       " ['blue'],\n",
       " ['blue'],\n",
       " ['blue'],\n",
       " ['red'],\n",
       " ['red'],\n",
       " ['blue'],\n",
       " ['blue'],\n",
       " ['red'],\n",
       " ['blue'],\n",
       " ['red'],\n",
       " ['red'],\n",
       " ['blue'],\n",
       " ['blue'],\n",
       " ['red'],\n",
       " ['red'],\n",
       " ['red'],\n",
       " ['red'],\n",
       " ['red'],\n",
       " ['blue'],\n",
       " ['red'],\n",
       " ['red'],\n",
       " ['blue'],\n",
       " ['red'],\n",
       " ['blue'],\n",
       " ['red'],\n",
       " ['red'],\n",
       " ['red'],\n",
       " ['blue'],\n",
       " ['red'],\n",
       " ['blue'],\n",
       " ['blue'],\n",
       " ['blue'],\n",
       " ['blue'],\n",
       " ['red'],\n",
       " ['red'],\n",
       " ['blue'],\n",
       " ['red'],\n",
       " ['red'],\n",
       " ['blue'],\n",
       " ['blue'],\n",
       " ['red'],\n",
       " ['red'],\n",
       " ['red'],\n",
       " ['blue'],\n",
       " ['blue'],\n",
       " ['red'],\n",
       " ['red'],\n",
       " ['red'],\n",
       " ['red'],\n",
       " ['red'],\n",
       " ['red'],\n",
       " ['red'],\n",
       " ['blue'],\n",
       " ['red'],\n",
       " ['red'],\n",
       " ['red'],\n",
       " ['blue'],\n",
       " ['red'],\n",
       " ['red'],\n",
       " ['red'],\n",
       " ['blue'],\n",
       " ['red'],\n",
       " ['red'],\n",
       " ['red'],\n",
       " ['blue'],\n",
       " ['red'],\n",
       " ['red'],\n",
       " ['red'],\n",
       " ['red'],\n",
       " ['blue'],\n",
       " ['red'],\n",
       " ['red'],\n",
       " ['red'],\n",
       " ['red'],\n",
       " ['red'],\n",
       " ['red'],\n",
       " ['red'],\n",
       " ['blue'],\n",
       " ['blue'],\n",
       " ['blue'],\n",
       " ['red'],\n",
       " ['red'],\n",
       " ['red'],\n",
       " ['red'],\n",
       " ['red'],\n",
       " ['red'],\n",
       " ['blue'],\n",
       " ['red'],\n",
       " ['blue'],\n",
       " ['red'],\n",
       " ['red'],\n",
       " ['red'],\n",
       " ['red'],\n",
       " ['blue'],\n",
       " ['blue'],\n",
       " ['red'],\n",
       " ['red'],\n",
       " ['blue'],\n",
       " ['red'],\n",
       " ['blue'],\n",
       " ['blue'],\n",
       " ['red'],\n",
       " ['blue'],\n",
       " ['blue'],\n",
       " ['red'],\n",
       " ['blue'],\n",
       " ['red'],\n",
       " ['red'],\n",
       " ['red'],\n",
       " ['red'],\n",
       " ['red'],\n",
       " ['red'],\n",
       " ['red'],\n",
       " ['red'],\n",
       " ['blue'],\n",
       " ['blue'],\n",
       " ['red'],\n",
       " ['red'],\n",
       " ['blue'],\n",
       " ['blue'],\n",
       " ['blue'],\n",
       " ['red'],\n",
       " ['red'],\n",
       " ['blue'],\n",
       " ['blue'],\n",
       " ['red'],\n",
       " ['red'],\n",
       " ['red'],\n",
       " ['red'],\n",
       " ['red'],\n",
       " ['red'],\n",
       " ['blue'],\n",
       " ['blue'],\n",
       " ['red'],\n",
       " ['red'],\n",
       " ['blue'],\n",
       " ['blue'],\n",
       " ['blue'],\n",
       " ['blue'],\n",
       " ['blue'],\n",
       " ['red'],\n",
       " ['red'],\n",
       " ['blue'],\n",
       " ['red'],\n",
       " ['red'],\n",
       " ['red'],\n",
       " ['red'],\n",
       " ['red'],\n",
       " ['blue'],\n",
       " ['red'],\n",
       " ['red'],\n",
       " ['red'],\n",
       " ['blue'],\n",
       " ['red'],\n",
       " ['blue'],\n",
       " ['blue'],\n",
       " ['blue'],\n",
       " ['red'],\n",
       " ['red'],\n",
       " ['blue'],\n",
       " ['red'],\n",
       " ['blue'],\n",
       " ['red'],\n",
       " ['red'],\n",
       " ['blue'],\n",
       " ['red'],\n",
       " ['red'],\n",
       " ['red'],\n",
       " ['red'],\n",
       " ['blue'],\n",
       " ['blue'],\n",
       " ['red'],\n",
       " ['red'],\n",
       " ['red'],\n",
       " ['red'],\n",
       " ['red'],\n",
       " ['red'],\n",
       " ['blue'],\n",
       " ['blue'],\n",
       " ['red'],\n",
       " ['red'],\n",
       " ['blue'],\n",
       " ['red'],\n",
       " ['red'],\n",
       " ['blue'],\n",
       " ['red'],\n",
       " ['red'],\n",
       " ['blue'],\n",
       " ['red'],\n",
       " ['red'],\n",
       " ['blue'],\n",
       " ['blue'],\n",
       " ['blue'],\n",
       " ['red'],\n",
       " ['red'],\n",
       " ['red'],\n",
       " ['red'],\n",
       " ['blue'],\n",
       " ['red'],\n",
       " ['blue'],\n",
       " ['blue'],\n",
       " ['red'],\n",
       " ['red'],\n",
       " ['blue'],\n",
       " ['blue'],\n",
       " ['blue'],\n",
       " ['red'],\n",
       " ['red'],\n",
       " ['blue'],\n",
       " ['blue'],\n",
       " ['red'],\n",
       " ['red'],\n",
       " ['blue'],\n",
       " ['blue'],\n",
       " ['red'],\n",
       " ['red'],\n",
       " ['blue'],\n",
       " ['red'],\n",
       " ['blue'],\n",
       " ['red'],\n",
       " ['red'],\n",
       " ['blue'],\n",
       " ['blue'],\n",
       " ['red'],\n",
       " ['red'],\n",
       " ['red'],\n",
       " ['red'],\n",
       " ['blue'],\n",
       " ['blue'],\n",
       " ['blue'],\n",
       " ['blue'],\n",
       " ['red'],\n",
       " ['blue'],\n",
       " ['blue'],\n",
       " ['red'],\n",
       " ['red'],\n",
       " ['blue'],\n",
       " ['blue'],\n",
       " ['blue'],\n",
       " ['red'],\n",
       " ['red'],\n",
       " ['blue'],\n",
       " ['red'],\n",
       " ['red'],\n",
       " ['red'],\n",
       " ['red'],\n",
       " ['red'],\n",
       " ['red'],\n",
       " ['red'],\n",
       " ['red'],\n",
       " ['red'],\n",
       " ['blue'],\n",
       " ['red'],\n",
       " ['red'],\n",
       " ['red'],\n",
       " ['red'],\n",
       " ['red'],\n",
       " ['red'],\n",
       " ['blue']]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_c "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1b1ee178",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 转换x的数据类型，否则后面矩阵相乘时会因数据类型问题报错\n",
    "x_train = tf.cast(x_train, tf.float32)\n",
    "y_train = tf.cast(y_train, tf.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e35808d3",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(300, 2), dtype=float32, numpy=\n",
       "array([[-4.16757852e-01, -5.62668256e-02],\n",
       "       [-2.13619614e+00,  1.64027083e+00],\n",
       "       [-1.79343557e+00, -8.41747344e-01],\n",
       "       [ 5.02881408e-01, -1.24528813e+00],\n",
       "       [-1.05795217e+00, -9.09007609e-01],\n",
       "       [ 5.51454067e-01,  2.29220796e+00],\n",
       "       [ 4.15393934e-02, -1.11792541e+00],\n",
       "       [ 5.39058328e-01, -5.96159697e-01],\n",
       "       [-1.91304963e-02,  1.17500126e+00],\n",
       "       [-7.47870922e-01,  9.02525056e-03],\n",
       "       [-8.78107905e-01, -1.56434163e-01],\n",
       "       [ 2.56570458e-01, -9.88779068e-01],\n",
       "       [-3.38821977e-01, -2.36184031e-01],\n",
       "       [-6.37655020e-01, -1.18761230e+00],\n",
       "       [-1.42121720e+00, -1.53495193e-01],\n",
       "       [-2.69056946e-01,  2.23136687e+00],\n",
       "       [-2.43476748e+00,  1.12726502e-01],\n",
       "       [ 3.70444536e-01,  1.35963392e+00],\n",
       "       [ 5.01857221e-01, -8.44213724e-01],\n",
       "       [ 9.75999956e-06,  5.42352557e-01],\n",
       "       [-3.13508183e-01,  7.71011710e-01],\n",
       "       [-1.86809063e+00,  1.73118472e+00],\n",
       "       [ 1.46767807e+00, -3.35677326e-01],\n",
       "       [ 6.11340761e-01,  4.79705930e-02],\n",
       "       [-8.29135299e-01,  8.77102166e-02],\n",
       "       [ 1.00036585e+00, -3.81092519e-01],\n",
       "       [-3.75669420e-01, -7.44707659e-02],\n",
       "       [ 4.33496326e-01,  1.27837920e+00],\n",
       "       [-6.34679317e-01,  5.08396268e-01],\n",
       "       [ 2.16116011e-01, -1.85861242e+00],\n",
       "       [-4.19316471e-01, -1.32328898e-01],\n",
       "       [-3.95702384e-02,  3.26003432e-01],\n",
       "       [-2.04032302e+00,  4.62555215e-02],\n",
       "       [-6.77675605e-01, -1.43943906e+00],\n",
       "       [ 5.24296403e-01,  7.35279560e-01],\n",
       "       [-6.53250277e-01,  8.42456281e-01],\n",
       "       [-3.81516486e-01,  6.64890110e-02],\n",
       "       [-1.09873891e+00,  1.58448708e+00],\n",
       "       [-2.65944934e+00, -9.14526209e-02],\n",
       "       [ 6.95119619e-01, -2.03346658e+00],\n",
       "       [-1.89469263e-01, -7.72186667e-02],\n",
       "       [ 8.24702978e-01,  1.24821293e+00],\n",
       "       [-4.03892279e-01, -1.38451862e+00],\n",
       "       [ 1.36723542e+00,  1.21788561e+00],\n",
       "       [-4.62005347e-01,  3.50888491e-01],\n",
       "       [ 3.81866246e-01,  5.66275418e-01],\n",
       "       [ 2.04207972e-01,  1.40669620e+00],\n",
       "       [-1.73795950e+00,  1.04082394e+00],\n",
       "       [ 3.80471975e-01, -2.17135265e-01],\n",
       "       [ 1.17353153e+00, -2.34360313e+00],\n",
       "       [ 1.16152143e+00,  3.86078060e-01],\n",
       "       [-1.13313329e+00,  4.33092564e-01],\n",
       "       [-3.04086447e-01,  2.58529496e+00],\n",
       "       [ 1.83533275e+00,  4.40689862e-01],\n",
       "       [-7.19253838e-01, -5.83414614e-01],\n",
       "       [-3.25049639e-01, -5.60234487e-01],\n",
       "       [-9.02246058e-01, -5.90972304e-01],\n",
       "       [-2.76179492e-01, -5.16883910e-01],\n",
       "       [-6.98589921e-01, -9.28891897e-01],\n",
       "       [ 2.55043817e+00, -1.47317326e+00],\n",
       "       [-1.02141476e+00,  4.32395697e-01],\n",
       "       [-3.23580056e-01,  4.23824698e-01],\n",
       "       [ 7.99179971e-01,  1.26261365e+00],\n",
       "       [ 7.51964867e-01, -9.93761003e-01],\n",
       "       [ 1.10914326e+00, -1.76491773e+00],\n",
       "       [-1.14421301e-01, -4.98174191e-01],\n",
       "       [-1.06079900e+00,  5.91666520e-01],\n",
       "       [-1.83256581e-01,  1.01985478e+00],\n",
       "       [-1.48246551e+00,  8.46311867e-01],\n",
       "       [ 4.97940153e-01,  1.26504168e-01],\n",
       "       [-1.41881061e+00, -2.51774132e-01],\n",
       "       [-1.54667461e+00, -2.08265185e+00],\n",
       "       [ 3.27974534e+00,  9.70861316e-01],\n",
       "       [ 1.79259288e+00, -4.29013312e-01],\n",
       "       [ 6.96197987e-01,  6.97416246e-01],\n",
       "       [ 6.01515830e-01,  3.65949096e-03],\n",
       "       [-2.28247553e-01, -2.06961226e+00],\n",
       "       [ 6.10144079e-01,  4.23496902e-01],\n",
       "       [ 1.11788678e+00, -2.74242103e-01],\n",
       "       [ 1.74181223e+00, -4.47500885e-01],\n",
       "       [-1.25542724e+00,  9.38163698e-01],\n",
       "       [-4.68346268e-01, -1.25472033e+00],\n",
       "       [ 1.24823645e-01,  7.56502151e-01],\n",
       "       [ 2.41439626e-01,  4.97425646e-01],\n",
       "       [ 4.10869265e+00,  8.21120858e-01],\n",
       "       [ 1.53176033e+00, -1.98584580e+00],\n",
       "       [ 3.65053505e-01,  7.74082005e-01],\n",
       "       [-3.64479095e-01, -8.75979483e-01],\n",
       "       [ 3.96520168e-01, -3.14617425e-01],\n",
       "       [-5.93755603e-01,  1.14950061e+00],\n",
       "       [ 1.33556616e+00,  3.02629322e-01],\n",
       "       [-4.54227865e-01,  5.14370739e-01],\n",
       "       [ 8.29458416e-01,  6.30621970e-01],\n",
       "       [-1.45336437e+00, -3.38017792e-01],\n",
       "       [ 3.59133333e-01,  6.22220397e-01],\n",
       "       [ 9.60781932e-01,  7.58370340e-01],\n",
       "       [-1.13431847e+00, -7.07420886e-01],\n",
       "       [-1.22142911e+00,  1.80447662e+00],\n",
       "       [ 1.80409804e-01,  5.53164303e-01],\n",
       "       [ 1.03302908e+00, -3.29002440e-01],\n",
       "       [-1.15100300e+00, -4.26522464e-01],\n",
       "       [-1.48147196e-01,  1.50143695e+00],\n",
       "       [ 8.69598210e-01, -1.08709061e+00],\n",
       "       [ 6.64221406e-01,  7.34884679e-01],\n",
       "       [-1.06136572e+00, -1.08516827e-01],\n",
       "       [-1.85040402e+00,  3.30488056e-01],\n",
       "       [-3.15693200e-01, -1.35000205e+00],\n",
       "       [-6.98171020e-01,  2.39951193e-01],\n",
       "       [-5.52949429e-01,  2.99526811e-01],\n",
       "       [ 5.52663684e-01, -8.40443015e-01],\n",
       "       [-3.12270671e-01,  2.14467812e+00],\n",
       "       [ 1.21105582e-01, -8.46828759e-01],\n",
       "       [ 6.04624487e-02, -1.33858883e+00],\n",
       "       [ 1.13274610e+00,  3.70304853e-01],\n",
       "       [ 1.08580637e+00,  9.02179420e-01],\n",
       "       [ 3.90296459e-01,  9.75509405e-01],\n",
       "       [ 1.91573650e-01, -6.62209034e-01],\n",
       "       [-1.02351499e+00, -4.48174834e-01],\n",
       "       [-2.50545812e+00,  1.82599449e+00],\n",
       "       [-1.71406746e+00, -7.66395628e-02],\n",
       "       [-1.31756723e+00, -2.02559352e+00],\n",
       "       [-8.22453722e-02, -3.04666579e-01],\n",
       "       [-1.59724131e-01,  5.48946559e-01],\n",
       "       [-6.18375480e-01,  3.78794461e-01],\n",
       "       [ 5.13251424e-01, -3.34844112e-01],\n",
       "       [-2.83519506e-01,  5.38424253e-01],\n",
       "       [ 5.72509468e-02,  1.59088492e-01],\n",
       "       [-2.37440276e+00,  5.85199334e-02],\n",
       "       [ 3.76545906e-01, -1.35479763e-01],\n",
       "       [ 3.35908383e-01,  1.90437591e+00],\n",
       "       [ 8.53644311e-02,  6.65334284e-01],\n",
       "       [-8.49995494e-01, -8.52341771e-01],\n",
       "       [-4.79985118e-01, -1.01964915e+00],\n",
       "       [-7.60113820e-03, -9.33830678e-01],\n",
       "       [-1.74996838e-01, -1.43714345e+00],\n",
       "       [-1.65220034e+00, -6.75661802e-01],\n",
       "       [-1.06706715e+00, -6.52931154e-01],\n",
       "       [-6.12094760e-01, -3.51262450e-01],\n",
       "       [ 1.04547799e+00,  1.36901605e+00],\n",
       "       [ 7.25353241e-01, -3.59474450e-01],\n",
       "       [ 1.49695182e+00, -1.53111112e+00],\n",
       "       [-2.02336383e+00,  2.67972589e-01],\n",
       "       [-2.20644497e-03, -1.39291883e-01],\n",
       "       [ 3.25654708e-02, -1.64056027e+00],\n",
       "       [-1.15669918e+00,  1.23403466e+00],\n",
       "       [ 1.02818489e+00, -7.21879721e-01],\n",
       "       [ 1.93315697e+00, -1.07079637e+00],\n",
       "       [-5.71381629e-01,  2.92432070e-01],\n",
       "       [-1.19499993e+00, -4.87930536e-01],\n",
       "       [-1.73071161e-01, -3.95346403e-01],\n",
       "       [ 8.70840788e-01,  5.92806816e-01],\n",
       "       [-1.09929729e+00, -6.81530654e-01],\n",
       "       [ 1.80066690e-01, -6.69310465e-02],\n",
       "       [-7.87749529e-01,  4.24753666e-01],\n",
       "       [ 8.19885135e-01, -6.31118655e-01],\n",
       "       [ 7.89059639e-01, -1.62167382e+00],\n",
       "       [-1.61049926e+00,  4.99939770e-01],\n",
       "       [-8.34515214e-01, -9.96959686e-01],\n",
       "       [-2.63388067e-01, -6.77360475e-01],\n",
       "       [ 3.27067047e-01, -1.45535946e+00],\n",
       "       [-3.71519119e-01,  3.16096592e+00],\n",
       "       [ 1.09951012e-01, -1.91352320e+00],\n",
       "       [ 5.99820435e-01,  5.49384475e-01],\n",
       "       [ 1.38378108e+00,  1.48349240e-01],\n",
       "       [-6.53541446e-01,  1.40883398e+00],\n",
       "       [ 7.12061226e-01, -1.80071604e+00],\n",
       "       [ 7.47598946e-01, -2.32896999e-01],\n",
       "       [ 1.11064529e+00, -3.73338819e-01],\n",
       "       [ 7.86146045e-01,  1.94168702e-01],\n",
       "       [ 5.86204112e-01, -2.03872919e-02],\n",
       "       [-4.14408594e-01,  6.73134103e-02],\n",
       "       [ 6.31798923e-01,  4.17592734e-01],\n",
       "       [ 1.61517632e+00,  4.25606221e-01],\n",
       "       [ 6.35363758e-01,  2.10222936e+00],\n",
       "       [ 6.61264136e-02,  5.35558343e-01],\n",
       "       [-6.03140771e-01,  4.19576280e-02],\n",
       "       [ 1.64191461e+00,  3.11697721e-01],\n",
       "       [ 1.45116985e+00, -1.06492794e+00],\n",
       "       [-1.40084541e+00,  3.07525516e-01],\n",
       "       [-1.36963868e+00,  2.67033720e+00],\n",
       "       [ 1.24845028e+00, -1.24572659e+00],\n",
       "       [-1.67168781e-01, -5.76610923e-01],\n",
       "       [ 4.16021734e-01, -5.78472614e-02],\n",
       "       [ 9.31887329e-01,  1.46833217e+00],\n",
       "       [-2.21320942e-01, -1.17315567e+00],\n",
       "       [ 5.62669098e-01, -1.64515063e-01],\n",
       "       [ 1.14485538e+00, -1.52117684e-01],\n",
       "       [ 8.29789042e-01,  3.36065948e-01],\n",
       "       [-1.89044058e-01, -4.49328601e-01],\n",
       "       [ 7.13524461e-01,  2.52973485e+00],\n",
       "       [ 8.37615788e-01, -1.31682396e-01],\n",
       "       [ 7.07592845e-01,  1.14053875e-01],\n",
       "       [-1.28089523e+00,  3.09846282e-01],\n",
       "       [ 1.54829073e+00, -3.15828055e-01],\n",
       "       [-1.12590373e+00,  4.88496661e-01],\n",
       "       [ 1.83094668e+00,  9.40176010e-01],\n",
       "       [ 1.01871705e+00,  2.30237818e+00],\n",
       "       [ 1.62109303e+00,  7.12683260e-01],\n",
       "       [-2.08703622e-01,  1.37617990e-01],\n",
       "       [-1.03352167e-01,  8.48350585e-01],\n",
       "       [-8.83125544e-01,  1.54538679e+00],\n",
       "       [ 1.45840079e-01, -4.00106043e-01],\n",
       "       [ 8.15206051e-01, -2.07492232e+00],\n",
       "       [-8.34437370e-01, -6.57718420e-01],\n",
       "       [ 8.20564330e-01, -4.89156991e-01],\n",
       "       [ 1.42496705e+00, -4.46857899e-01],\n",
       "       [ 5.21109402e-01, -7.08194375e-01],\n",
       "       [ 1.15553057e+00, -2.54530460e-01],\n",
       "       [ 5.18924952e-01, -4.92994905e-01],\n",
       "       [-1.08654821e+00, -2.30917498e-01],\n",
       "       [ 1.09801006e+00, -1.01787806e+00],\n",
       "       [-1.52939141e+00, -3.07987750e-01],\n",
       "       [ 7.80754328e-01, -1.05583966e+00],\n",
       "       [-5.43883383e-01,  1.84301734e-01],\n",
       "       [-3.30675840e-01,  2.87208200e-01],\n",
       "       [ 1.18952811e+00,  2.12015472e-02],\n",
       "       [-6.54096827e-02,  7.66115904e-01],\n",
       "       [-6.16350845e-02, -9.52897131e-01],\n",
       "       [-1.01446307e+00, -1.11526394e+00],\n",
       "       [ 1.91260064e+00, -4.52632047e-02],\n",
       "       [ 5.76909721e-01,  7.17805684e-01],\n",
       "       [-9.38998997e-01,  6.28775835e-01],\n",
       "       [-5.64493418e-01, -2.08780742e+00],\n",
       "       [-2.15050131e-01, -1.07502854e+00],\n",
       "       [-3.37972134e-01,  3.43212724e-01],\n",
       "       [ 2.28253961e+00, -4.95778859e-01],\n",
       "       [-1.63962826e-01,  3.71622175e-01],\n",
       "       [ 1.86521515e-01, -1.58429220e-01],\n",
       "       [-1.08292961e+00, -9.56625521e-01],\n",
       "       [-1.83376729e-01, -1.15980685e+00],\n",
       "       [-6.57768369e-01, -1.25144839e+00],\n",
       "       [ 1.12448287e+00, -1.49783981e+00],\n",
       "       [ 1.90201724e+00, -5.80383062e-01],\n",
       "       [-1.05491567e+00, -1.18275726e+00],\n",
       "       [ 7.79480040e-01,  1.02659798e+00],\n",
       "       [-8.48666012e-01,  3.31539661e-01],\n",
       "       [-1.49591357e-01, -2.42440596e-01],\n",
       "       [ 1.51197180e-01,  7.65069485e-01],\n",
       "       [-1.91663051e+00, -2.22734118e+00],\n",
       "       [ 2.06689894e-01, -7.08763525e-02],\n",
       "       [ 6.84759974e-01, -1.70753908e+00],\n",
       "       [-9.86569643e-01,  1.54353631e+00],\n",
       "       [-1.31027055e+00,  3.63433957e-01],\n",
       "       [-7.94872463e-01, -4.05286252e-01],\n",
       "       [-1.37775791e+00,  1.18604863e+00],\n",
       "       [-1.90382111e+00, -1.19814038e+00],\n",
       "       [-9.10065651e-01,  1.17645419e+00],\n",
       "       [ 2.99210668e-01,  6.79267168e-01],\n",
       "       [-1.76606793e-02,  2.36040920e-01],\n",
       "       [ 4.94035870e-01,  1.54627764e+00],\n",
       "       [ 2.46857509e-01, -1.46877575e+00],\n",
       "       [ 1.14709997e+00,  9.55569819e-02],\n",
       "       [-1.10743868e+00, -1.76286146e-01],\n",
       "       [-9.82755661e-01,  2.08668280e+00],\n",
       "       [-3.44623685e-01, -2.00207925e+00],\n",
       "       [ 3.03234428e-01, -8.29874873e-01],\n",
       "       [ 1.28876936e+00,  1.34925455e-01],\n",
       "       [-1.77860069e+00, -5.00791490e-01],\n",
       "       [-1.08816159e+00, -7.57855535e-01],\n",
       "       [-6.43744886e-01, -2.00878453e+00],\n",
       "       [ 1.96262896e-01, -8.75896394e-01],\n",
       "       [-8.93609226e-01,  7.51902342e-01],\n",
       "       [ 1.89693224e+00, -6.29079163e-01],\n",
       "       [ 1.81208551e+00, -2.05626583e+00],\n",
       "       [ 5.62704861e-01, -5.82070768e-01],\n",
       "       [-7.40029737e-02, -9.86496389e-01],\n",
       "       [-5.94722509e-01, -3.14811856e-01],\n",
       "       [-3.46940517e-01,  4.11443502e-01],\n",
       "       [ 2.32639098e+00, -6.34053111e-01],\n",
       "       [-1.54409960e-01, -1.74928880e+00],\n",
       "       [-2.51957941e+00,  1.39116240e+00],\n",
       "       [-1.32934642e+00, -7.45596409e-01],\n",
       "       [ 2.12608501e-02,  9.10917521e-01],\n",
       "       [ 3.15276086e-01,  1.86620820e+00],\n",
       "       [-1.82497621e-01, -1.82826638e+00],\n",
       "       [ 1.38955712e-01,  1.19450167e-01],\n",
       "       [-8.18899214e-01, -3.32639277e-01],\n",
       "       [-5.86387932e-01,  1.73451638e+00],\n",
       "       [-6.12751544e-01, -1.39344203e+00],\n",
       "       [ 2.79433757e-01, -1.82223129e+00],\n",
       "       [ 4.27017450e-01,  4.06987756e-01],\n",
       "       [-8.44308257e-01, -5.59820116e-01],\n",
       "       [-6.00520432e-01,  1.61487329e+00],\n",
       "       [ 3.94953221e-01, -1.20381343e+00],\n",
       "       [-1.24747241e+00, -7.75462463e-02],\n",
       "       [-1.33397514e-02, -7.68323243e-01],\n",
       "       [ 2.91234016e-01, -1.97330952e-01],\n",
       "       [ 1.07682967e+00,  4.37410235e-01],\n",
       "       [-9.31978673e-02,  1.35631412e-01],\n",
       "       [-8.82708848e-01,  8.84744167e-01],\n",
       "       [ 3.83204460e-01, -4.16994154e-01],\n",
       "       [ 1.17796548e-01, -5.36685288e-01],\n",
       "       [ 2.48718452e+00, -4.51361060e-01],\n",
       "       [ 5.18836141e-01,  3.64448011e-01],\n",
       "       [-7.98348725e-01,  5.65779721e-03],\n",
       "       [-3.20934713e-01,  2.49513552e-01],\n",
       "       [ 2.56308407e-01,  7.67625093e-01],\n",
       "       [ 7.83020079e-01, -4.07063037e-01],\n",
       "       [-5.24891675e-01, -5.89808702e-01],\n",
       "       [-8.62531066e-01, -1.74287295e+00]], dtype=float32)>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "83884d00",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(300, 1), dtype=float32, numpy=\n",
       "array([[1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.]], dtype=float32)>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "abfe069f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from_tensor_slices函数切分传入的张量的第一个维度，生成相应的数据集，使输入特征和标签值一一对应\n",
    "train_db = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dd517a5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((None, 2), (None, 1)), types: (tf.float32, tf.float32)>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_db "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "15dfcdf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成神经网络的参数，输入层为4个神经元，隐藏层为32个神经元，2层隐藏层，输出层为3个神经元\n",
    "# 用tf.Variable()保证参数可训练\n",
    "w1 = tf.Variable(tf.random.normal([2, 11]), dtype=tf.float32)\n",
    "b1 = tf.Variable(tf.constant(0.01, shape=[11]))\n",
    "\n",
    "w2 = tf.Variable(tf.random.normal([11, 1]), dtype=tf.float32)\n",
    "b2 = tf.Variable(tf.constant(0.01, shape=[1]))\n",
    "\n",
    "lr = 0.01  # 学习率为\n",
    "epoch = 400  # 循环轮数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d05c68fc",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(2, 11) dtype=float32, numpy=\n",
       "array([[-1.0683796 , -0.23511137, -0.43792856,  0.35813963, -2.3991294 ,\n",
       "         0.4479319 ,  1.0332392 ,  0.56996197,  1.2068752 ,  0.12311532,\n",
       "         0.89513475],\n",
       "       [-1.7256345 , -0.35760075,  0.03294048, -1.5186663 ,  1.1043756 ,\n",
       "        -0.6642298 , -0.34775767, -0.19347635, -0.91795075,  0.5516641 ,\n",
       "         1.6876026 ]], dtype=float32)>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7c051462",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(11,) dtype=float32, numpy=\n",
       "array([0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "769133a1",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(11, 1) dtype=float32, numpy=\n",
       "array([[-1.0691246 ],\n",
       "       [-0.0899193 ],\n",
       "       [-1.1486549 ],\n",
       "       [-0.3957618 ],\n",
       "       [ 1.4094455 ],\n",
       "       [-1.0363579 ],\n",
       "       [ 0.4956743 ],\n",
       "       [ 0.08657303],\n",
       "       [-0.5767533 ],\n",
       "       [-0.40025845],\n",
       "       [-0.41651708]], dtype=float32)>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f335a803",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(1,) dtype=float32, numpy=array([0.01], dtype=float32)>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "242a98cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.01  # 学习率为\n",
    "epoch = 400  # 循环轮数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c85ca5fd",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 loss: 1.7510802745819092\n",
      "epoch: 20 loss: 0.35573363304138184\n",
      "epoch: 40 loss: 0.3123984932899475\n",
      "epoch: 60 loss: 0.28019797801971436\n",
      "epoch: 80 loss: 0.25338828563690186\n",
      "epoch: 100 loss: 0.22911790013313293\n",
      "epoch: 120 loss: 0.20762529969215393\n",
      "epoch: 140 loss: 0.1890803426504135\n",
      "epoch: 160 loss: 0.17291587591171265\n",
      "epoch: 180 loss: 0.15896451473236084\n",
      "epoch: 200 loss: 0.14666518568992615\n",
      "epoch: 220 loss: 0.13620918989181519\n",
      "epoch: 240 loss: 0.12713982164859772\n",
      "epoch: 260 loss: 0.11934638768434525\n",
      "epoch: 280 loss: 0.11251966655254364\n",
      "epoch: 300 loss: 0.10614205151796341\n",
      "epoch: 320 loss: 0.10087697952985764\n",
      "epoch: 340 loss: 0.09653689712285995\n",
      "epoch: 360 loss: 0.09298424422740936\n",
      "epoch: 380 loss: 0.09008965641260147\n"
     ]
    }
   ],
   "source": [
    "# 训练部分\n",
    "for epoch in range(epoch):\n",
    "    for step, (x_train, y_train) in enumerate(train_db):\n",
    "        with tf.GradientTape() as tape:  # 记录梯度信息\n",
    "\n",
    "            h1 = tf.matmul(x_train, w1) + b1  # 记录神经网络乘加运算\n",
    "            h1 = tf.nn.relu(h1)\n",
    "            y = tf.matmul(h1, w2) + b2\n",
    "\n",
    "            # 采用均方误差损失函数mse = mean(sum(y-out)^2)\n",
    "            loss_mse = tf.reduce_mean(tf.square(y_train - y))\n",
    "            # 添加l2正则化\n",
    "            loss_regularization = []\n",
    "            # tf.nn.l2_loss(w)=sum(w ** 2) / 2\n",
    "            loss_regularization.append(tf.nn.l2_loss(w1))\n",
    "            loss_regularization.append(tf.nn.l2_loss(w2))\n",
    "            # 求和\n",
    "            # 例：x=tf.constant(([1,1,1],[1,1,1]))\n",
    "            #   tf.reduce_sum(x)\n",
    "            # >>>6\n",
    "            # loss_regularization = tf.reduce_sum(tf.stack(loss_regularization))\n",
    "            loss_regularization = tf.reduce_sum(loss_regularization)\n",
    "            loss = loss_mse + 0.03 * loss_regularization #REGULARIZER = 0.03\n",
    "\n",
    "        # 计算loss对各个参数的梯度\n",
    "        variables = [w1, b1, w2, b2]\n",
    "        grads = tape.gradient(loss, variables)\n",
    "\n",
    "        # 实现梯度更新\n",
    "        # w1 = w1 - lr * w1_grad\n",
    "        w1.assign_sub(lr * grads[0])\n",
    "        b1.assign_sub(lr * grads[1])\n",
    "        w2.assign_sub(lr * grads[2])\n",
    "        b2.assign_sub(lr * grads[3])\n",
    "\n",
    "    # 每200个epoch，打印loss信息\n",
    "    if epoch % 20 == 0:\n",
    "        print('epoch:', epoch, 'loss:', float(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b15cf757",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******predict*******\n"
     ]
    }
   ],
   "source": [
    "# 预测部分\n",
    "print(\"*******predict*******\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "91e68582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xx在-3到3之间以步长为0.01，yy在-3到3之间以步长0.01,生成间隔数值点\n",
    "xx, yy = np.mgrid[-3:3:.1, -3:3:.1]\n",
    "# 将xx, yy拉直，并合并配对为二维张量，生成二维坐标点\n",
    "grid = np.c_[xx.ravel(), yy.ravel()]\n",
    "grid = tf.cast(grid, tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "56e40cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将网格坐标点喂入神经网络，进行预测，probs为输出\n",
    "probs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "87a5b377",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "for x_predict in grid:\n",
    "    # 使用训练好的参数进行预测\n",
    "    h1 = tf.matmul([x_predict], w1) + b1\n",
    "    h1 = tf.nn.relu(h1)\n",
    "    y = tf.matmul(h1, w2) + b2  # y为预测结果\n",
    "    probs.append(y)\n",
    "\n",
    "# 取第0列给x1，取第1列给x2\n",
    "x1 = x_data[:, 0]\n",
    "x2 = x_data[:, 1]\n",
    "# probs的shape调整成xx的样子\n",
    "probs = np.array(probs).reshape(xx.shape)\n",
    "plt.scatter(x1, x2, color=np.squeeze(Y_c))\n",
    "# 把坐标xx yy和对应的值probs放入contour<[‘kɑntʊr]>函数，给probs值为0.5的所有点上色  plt点show后 显示的是红蓝点的分界线\n",
    "plt.contour(xx, yy, probs, levels=[.5])\n",
    "plt.show()\n",
    "\n",
    "# 读入红蓝点，画出分割线，包含正则化\n",
    "# 不清楚的数据，建议print出来查看 "
   ]
  },
  {
   "cell_type": "raw",
   "id": "cd8daab5",
   "metadata": {},
   "source": [
    "如上是有正则化的分类，没有正则化的分类可以自行运行。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "25f28f1b",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, loss: 0.2821310982108116\n",
      "Test_acc: 0.16666666666666666\n",
      "--------------------------\n",
      "Epoch 1, loss: 0.25459614023566246\n",
      "Test_acc: 0.16666666666666666\n",
      "--------------------------\n",
      "Epoch 2, loss: 0.22570250183343887\n",
      "Test_acc: 0.16666666666666666\n",
      "--------------------------\n",
      "Epoch 3, loss: 0.21028400212526321\n",
      "Test_acc: 0.16666666666666666\n",
      "--------------------------\n",
      "Epoch 4, loss: 0.19942265003919601\n",
      "Test_acc: 0.16666666666666666\n",
      "--------------------------\n",
      "Epoch 5, loss: 0.18873638287186623\n",
      "Test_acc: 0.5\n",
      "--------------------------\n",
      "Epoch 6, loss: 0.17851299419999123\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 7, loss: 0.16922875493764877\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 8, loss: 0.16107673197984695\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 9, loss: 0.15404684096574783\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 10, loss: 0.14802725985646248\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 11, loss: 0.14287303388118744\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 12, loss: 0.1384414155036211\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 13, loss: 0.13460607267916203\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 14, loss: 0.1312607266008854\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 15, loss: 0.12831821851432323\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 16, loss: 0.12570794858038425\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 17, loss: 0.12337299063801765\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 18, loss: 0.12126746959984303\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 19, loss: 0.11935433000326157\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 20, loss: 0.11760355532169342\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 21, loss: 0.11599067784845829\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 22, loss: 0.11449568346142769\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 23, loss: 0.11310208030045033\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 24, loss: 0.11179621517658234\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 25, loss: 0.11056671850383282\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 26, loss: 0.1094040796160698\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 27, loss: 0.10830028168857098\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 28, loss: 0.10724855586886406\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 29, loss: 0.10624313727021217\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 30, loss: 0.1052791029214859\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 31, loss: 0.10435222089290619\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 32, loss: 0.10345886647701263\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 33, loss: 0.10259587690234184\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 34, loss: 0.10176053084433079\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 35, loss: 0.10095042362809181\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 36, loss: 0.10016347281634808\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 37, loss: 0.09939785301685333\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 38, loss: 0.098651934415102\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 39, loss: 0.09792428836226463\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 40, loss: 0.09721364639699459\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 41, loss: 0.09651889279484749\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 42, loss: 0.09583901055157185\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 43, loss: 0.09517310746014118\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 44, loss: 0.09452036395668983\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 45, loss: 0.0938800685107708\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 46, loss: 0.09325156174600124\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 47, loss: 0.09263424947857857\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 48, loss: 0.09202760085463524\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 49, loss: 0.09143111668527126\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 50, loss: 0.09084436297416687\n",
      "Test_acc: 0.5666666666666667\n",
      "--------------------------\n",
      "Epoch 51, loss: 0.09026693738996983\n",
      "Test_acc: 0.5666666666666667\n",
      "--------------------------\n",
      "Epoch 52, loss: 0.08969846740365028\n",
      "Test_acc: 0.5666666666666667\n",
      "--------------------------\n",
      "Epoch 53, loss: 0.08913861028850079\n",
      "Test_acc: 0.6\n",
      "--------------------------\n",
      "Epoch 54, loss: 0.08858705312013626\n",
      "Test_acc: 0.6\n",
      "--------------------------\n",
      "Epoch 55, loss: 0.08804351277649403\n",
      "Test_acc: 0.6\n",
      "--------------------------\n",
      "Epoch 56, loss: 0.08750772476196289\n",
      "Test_acc: 0.6\n",
      "--------------------------\n",
      "Epoch 57, loss: 0.08697944693267345\n",
      "Test_acc: 0.6\n",
      "--------------------------\n",
      "Epoch 58, loss: 0.08645843341946602\n",
      "Test_acc: 0.6\n",
      "--------------------------\n",
      "Epoch 59, loss: 0.08594449236989021\n",
      "Test_acc: 0.6\n",
      "--------------------------\n",
      "Epoch 60, loss: 0.08543741516768932\n",
      "Test_acc: 0.6\n",
      "--------------------------\n",
      "Epoch 61, loss: 0.08493702113628387\n",
      "Test_acc: 0.6\n",
      "--------------------------\n",
      "Epoch 62, loss: 0.08444313704967499\n",
      "Test_acc: 0.6333333333333333\n",
      "--------------------------\n",
      "Epoch 63, loss: 0.08395560085773468\n",
      "Test_acc: 0.6333333333333333\n",
      "--------------------------\n",
      "Epoch 64, loss: 0.08347426354885101\n",
      "Test_acc: 0.6333333333333333\n",
      "--------------------------\n",
      "Epoch 65, loss: 0.08299897983670235\n",
      "Test_acc: 0.6333333333333333\n",
      "--------------------------\n",
      "Epoch 66, loss: 0.08252961002290249\n",
      "Test_acc: 0.6333333333333333\n",
      "--------------------------\n",
      "Epoch 67, loss: 0.08206603676080704\n",
      "Test_acc: 0.6333333333333333\n",
      "--------------------------\n",
      "Epoch 68, loss: 0.0816081278026104\n",
      "Test_acc: 0.6333333333333333\n",
      "--------------------------\n",
      "Epoch 69, loss: 0.08115577697753906\n",
      "Test_acc: 0.6333333333333333\n",
      "--------------------------\n",
      "Epoch 70, loss: 0.08070887438952923\n",
      "Test_acc: 0.6333333333333333\n",
      "--------------------------\n",
      "Epoch 71, loss: 0.08026730641722679\n",
      "Test_acc: 0.6333333333333333\n",
      "--------------------------\n",
      "Epoch 72, loss: 0.07983098179101944\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 73, loss: 0.07939981482923031\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 74, loss: 0.07897369377315044\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 75, loss: 0.07855254411697388\n",
      "Test_acc: 0.7\n",
      "--------------------------\n",
      "Epoch 76, loss: 0.07813627645373344\n",
      "Test_acc: 0.7\n",
      "--------------------------\n",
      "Epoch 77, loss: 0.07772481068968773\n",
      "Test_acc: 0.7\n",
      "--------------------------\n",
      "Epoch 78, loss: 0.07731806486845016\n",
      "Test_acc: 0.7\n",
      "--------------------------\n",
      "Epoch 79, loss: 0.07691597566008568\n",
      "Test_acc: 0.7\n",
      "--------------------------\n",
      "Epoch 80, loss: 0.07651845179498196\n",
      "Test_acc: 0.7\n",
      "--------------------------\n",
      "Epoch 81, loss: 0.07612544111907482\n",
      "Test_acc: 0.7333333333333333\n",
      "--------------------------\n",
      "Epoch 82, loss: 0.07573685608804226\n",
      "Test_acc: 0.7333333333333333\n",
      "--------------------------\n",
      "Epoch 83, loss: 0.07535265013575554\n",
      "Test_acc: 0.7333333333333333\n",
      "--------------------------\n",
      "Epoch 84, loss: 0.07497275061905384\n",
      "Test_acc: 0.7333333333333333\n",
      "--------------------------\n",
      "Epoch 85, loss: 0.07459708210080862\n",
      "Test_acc: 0.7666666666666667\n",
      "--------------------------\n",
      "Epoch 86, loss: 0.07422559335827827\n",
      "Test_acc: 0.7666666666666667\n",
      "--------------------------\n",
      "Epoch 87, loss: 0.07385822758078575\n",
      "Test_acc: 0.7666666666666667\n",
      "--------------------------\n",
      "Epoch 88, loss: 0.07349492330104113\n",
      "Test_acc: 0.7666666666666667\n",
      "--------------------------\n",
      "Epoch 89, loss: 0.0731356181204319\n",
      "Test_acc: 0.7666666666666667\n",
      "--------------------------\n",
      "Epoch 90, loss: 0.0727802598848939\n",
      "Test_acc: 0.7666666666666667\n",
      "--------------------------\n",
      "Epoch 91, loss: 0.07242879830300808\n",
      "Test_acc: 0.7666666666666667\n",
      "--------------------------\n",
      "Epoch 92, loss: 0.07208118122071028\n",
      "Test_acc: 0.7666666666666667\n",
      "--------------------------\n",
      "Epoch 93, loss: 0.07173734251409769\n",
      "Test_acc: 0.8\n",
      "--------------------------\n",
      "Epoch 94, loss: 0.07139723561704159\n",
      "Test_acc: 0.8\n",
      "--------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95, loss: 0.07106082048267126\n",
      "Test_acc: 0.8\n",
      "--------------------------\n",
      "Epoch 96, loss: 0.07072803843766451\n",
      "Test_acc: 0.8\n",
      "--------------------------\n",
      "Epoch 97, loss: 0.07039883732795715\n",
      "Test_acc: 0.8\n",
      "--------------------------\n",
      "Epoch 98, loss: 0.07007318176329136\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 99, loss: 0.0697510102763772\n",
      "Test_acc: 0.8666666666666667\n",
      "--------------------------\n",
      "Epoch 100, loss: 0.06943229492753744\n",
      "Test_acc: 0.8666666666666667\n",
      "--------------------------\n",
      "Epoch 101, loss: 0.06911696959286928\n",
      "Test_acc: 0.8666666666666667\n",
      "--------------------------\n",
      "Epoch 102, loss: 0.06880500260740519\n",
      "Test_acc: 0.8666666666666667\n",
      "--------------------------\n",
      "Epoch 103, loss: 0.068496348336339\n",
      "Test_acc: 0.8666666666666667\n",
      "--------------------------\n",
      "Epoch 104, loss: 0.06819095741957426\n",
      "Test_acc: 0.8666666666666667\n",
      "--------------------------\n",
      "Epoch 105, loss: 0.06788879353553057\n",
      "Test_acc: 0.8666666666666667\n",
      "--------------------------\n",
      "Epoch 106, loss: 0.06758981756865978\n",
      "Test_acc: 0.8666666666666667\n",
      "--------------------------\n",
      "Epoch 107, loss: 0.0672939782962203\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 108, loss: 0.06700124125927687\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 109, loss: 0.06671155989170074\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 110, loss: 0.06642490718513727\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 111, loss: 0.06614123564213514\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 112, loss: 0.06586050800979137\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 113, loss: 0.06558268237859011\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 114, loss: 0.06530772428959608\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 115, loss: 0.06503560300916433\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 116, loss: 0.06476627010852098\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 117, loss: 0.06449970323592424\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 118, loss: 0.06423585396260023\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 119, loss: 0.06397469528019428\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 120, loss: 0.06371619179844856\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 121, loss: 0.06346031185239553\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 122, loss: 0.06320700887590647\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 123, loss: 0.06295627169311047\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 124, loss: 0.06270804442465305\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 125, loss: 0.062462314032018185\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 126, loss: 0.062219033017754555\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 127, loss: 0.061978185549378395\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 128, loss: 0.06173973437398672\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 129, loss: 0.06150364130735397\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 130, loss: 0.06126988586038351\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 131, loss: 0.06103843078017235\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 132, loss: 0.060809263959527016\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 133, loss: 0.06058233231306076\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 134, loss: 0.06035762373358011\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 135, loss: 0.06013510562479496\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 136, loss: 0.05991474352777004\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 137, loss: 0.05969652719795704\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 138, loss: 0.05948041472584009\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 139, loss: 0.059266386553645134\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 140, loss: 0.059054408222436905\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 141, loss: 0.058844465762376785\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 142, loss: 0.05863652750849724\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 143, loss: 0.058430563658475876\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 144, loss: 0.058226559311151505\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 145, loss: 0.05802448187023401\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 146, loss: 0.05782431084662676\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 147, loss: 0.0576260257512331\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 148, loss: 0.05742959305644035\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 149, loss: 0.057234992273151875\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 150, loss: 0.05704221595078707\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 151, loss: 0.05685121938586235\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 152, loss: 0.05666199326515198\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 153, loss: 0.05647451523691416\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 154, loss: 0.0562887629494071\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 155, loss: 0.05610471125692129\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 156, loss: 0.05592234432697296\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 157, loss: 0.0557416332885623\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 158, loss: 0.05556256324052811\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 159, loss: 0.05538512021303177\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 160, loss: 0.05520927160978317\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 161, loss: 0.0550350034609437\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 162, loss: 0.054862307384610176\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 163, loss: 0.05469114426523447\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 164, loss: 0.05452151037752628\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 165, loss: 0.05435337871313095\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 166, loss: 0.05418673437088728\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 167, loss: 0.054021554067730904\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 168, loss: 0.053857832215726376\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 169, loss: 0.05369554739445448\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 170, loss: 0.05353467632085085\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 171, loss: 0.05337520316243172\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 172, loss: 0.05321711581200361\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 173, loss: 0.053060390055179596\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 174, loss: 0.05290501844137907\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 175, loss: 0.05275098513811827\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 176, loss: 0.0525982566177845\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 177, loss: 0.05244683939963579\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 178, loss: 0.05229670740664005\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 179, loss: 0.05214785039424896\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 180, loss: 0.052000246942043304\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 181, loss: 0.05185388680547476\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 182, loss: 0.05170875135809183\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 183, loss: 0.0515648303553462\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 184, loss: 0.0514221116900444\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 185, loss: 0.05128058046102524\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 186, loss: 0.05114021524786949\n",
      "Test_acc: 1.0\n",
      "--------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 187, loss: 0.051001012325286865\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 188, loss: 0.0508629409596324\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 189, loss: 0.05072600767016411\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 190, loss: 0.05059019848704338\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 191, loss: 0.05045548640191555\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 192, loss: 0.050321875140070915\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 193, loss: 0.05018933489918709\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 194, loss: 0.05005786381661892\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 195, loss: 0.04992745537310839\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 196, loss: 0.04979807883501053\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 197, loss: 0.04966974165290594\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 198, loss: 0.04954242426902056\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 199, loss: 0.04941611457616091\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 200, loss: 0.049290805123746395\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 201, loss: 0.049166472628712654\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 202, loss: 0.04904312454164028\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 203, loss: 0.04892073106020689\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 204, loss: 0.04879929404705763\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 205, loss: 0.04867880046367645\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 206, loss: 0.04855923913419247\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 207, loss: 0.048440598882734776\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 208, loss: 0.04832286946475506\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 209, loss: 0.04820604622364044\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 210, loss: 0.04809010960161686\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 211, loss: 0.04797505959868431\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 212, loss: 0.04786087851971388\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 213, loss: 0.047747560776770115\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 214, loss: 0.04763508960604668\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 215, loss: 0.04752346687018871\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 216, loss: 0.0474126823246479\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 217, loss: 0.04730272572487593\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 218, loss: 0.04719358030706644\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 219, loss: 0.04708524979650974\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 220, loss: 0.046977708116173744\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 221, loss: 0.046870965510606766\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 222, loss: 0.04676500242203474\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 223, loss: 0.046659816056489944\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 224, loss: 0.046555391512811184\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 225, loss: 0.04645173158496618\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 226, loss: 0.046348825097084045\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 227, loss: 0.04624664504081011\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 228, loss: 0.046145214699208736\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 229, loss: 0.04604450333863497\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 230, loss: 0.04594451282173395\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 231, loss: 0.045845234766602516\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 232, loss: 0.04574666079133749\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 233, loss: 0.04564878437668085\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 234, loss: 0.04555159714072943\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 235, loss: 0.04545509163290262\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 236, loss: 0.045359269715845585\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 237, loss: 0.04526410344988108\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 238, loss: 0.04516960680484772\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 239, loss: 0.04507576581090689\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 240, loss: 0.044982570223510265\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 241, loss: 0.04489001724869013\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 242, loss: 0.04479810781776905\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 243, loss: 0.04470681864768267\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 244, loss: 0.04461614973843098\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 245, loss: 0.04452611040323973\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 246, loss: 0.04443667363375425\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 247, loss: 0.044347839429974556\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 248, loss: 0.04425961058586836\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 249, loss: 0.04417197220027447\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 250, loss: 0.044084908440709114\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 251, loss: 0.043998440727591515\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 252, loss: 0.04391253925859928\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 253, loss: 0.043827205896377563\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 254, loss: 0.04374244436621666\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 255, loss: 0.04365824069827795\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 256, loss: 0.04357459116727114\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 257, loss: 0.043491488322615623\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 258, loss: 0.043408920988440514\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 259, loss: 0.043326896615326405\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 260, loss: 0.04324540589004755\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 261, loss: 0.043164435774087906\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 262, loss: 0.04308399651199579\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 263, loss: 0.043004062958061695\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 264, loss: 0.04292465187609196\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 265, loss: 0.04284573998302221\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 266, loss: 0.04276733938604593\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 267, loss: 0.042689427733421326\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 268, loss: 0.042612009681761265\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 269, loss: 0.042535084299743176\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 270, loss: 0.04245864413678646\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 271, loss: 0.0423826826736331\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 272, loss: 0.042307195253670216\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 273, loss: 0.04223217722028494\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 274, loss: 0.0421576201915741\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 275, loss: 0.042083533480763435\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 276, loss: 0.04200989939272404\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 277, loss: 0.041936714202165604\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 278, loss: 0.041863986290991306\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 279, loss: 0.04179169982671738\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 280, loss: 0.041719854809343815\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 281, loss: 0.041648441925644875\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 282, loss: 0.04157746955752373\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 283, loss: 0.04150692094117403\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 284, loss: 0.04143680352717638\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 285, loss: 0.04136709962040186\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 286, loss: 0.04129782039672136\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 287, loss: 0.04122895374894142\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 288, loss: 0.04116049408912659\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 289, loss: 0.04109244793653488\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 290, loss: 0.04102479945868254\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 291, loss: 0.04095755238085985\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 292, loss: 0.040890694595873356\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 293, loss: 0.040824233554303646\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 294, loss: 0.040758166462183\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 295, loss: 0.040692479349672794\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 296, loss: 0.04062717128545046\n",
      "Test_acc: 1.0\n",
      "--------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 297, loss: 0.040562248788774014\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 298, loss: 0.04049769788980484\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 299, loss: 0.04043351951986551\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 300, loss: 0.04036970995366573\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 301, loss: 0.040306271985173225\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 302, loss: 0.04024319350719452\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 303, loss: 0.04018046986311674\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 304, loss: 0.040118103846907616\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 305, loss: 0.04005609406158328\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 306, loss: 0.03999443957582116\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 307, loss: 0.03993312222883105\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 308, loss: 0.039872155059129\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 309, loss: 0.03981153108179569\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 310, loss: 0.03975124144926667\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 311, loss: 0.03969129454344511\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 312, loss: 0.03963167825713754\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 313, loss: 0.039572385139763355\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 314, loss: 0.0395134249702096\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 315, loss: 0.039454787503927946\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 316, loss: 0.039396482054144144\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 317, loss: 0.03933848813176155\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 318, loss: 0.03928081039339304\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 319, loss: 0.039223446510732174\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 320, loss: 0.039166401606053114\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 321, loss: 0.039109662640839815\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 322, loss: 0.03905322263017297\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 323, loss: 0.03899709461256862\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 324, loss: 0.03894126648083329\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 325, loss: 0.038885737769305706\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 326, loss: 0.03883049916476011\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 327, loss: 0.03877555998042226\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 328, loss: 0.03872091369703412\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 329, loss: 0.038666556123644114\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 330, loss: 0.0386124849319458\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 331, loss: 0.038558701518923044\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 332, loss: 0.03850520169362426\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 333, loss: 0.03845197660848498\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 334, loss: 0.03839903511106968\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 335, loss: 0.03834636742249131\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 336, loss: 0.03829397866502404\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 337, loss: 0.038241852074861526\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 338, loss: 0.03819000208750367\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 339, loss: 0.03813841659575701\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 340, loss: 0.038087102584540844\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 341, loss: 0.03803604608401656\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 342, loss: 0.037985255010426044\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 343, loss: 0.0379347144626081\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 344, loss: 0.03788443887606263\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 345, loss: 0.037834418937563896\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 346, loss: 0.03778465045616031\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 347, loss: 0.03773513110354543\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 348, loss: 0.03768586413934827\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 349, loss: 0.03763684118166566\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 350, loss: 0.037588071543723345\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 351, loss: 0.037539539858698845\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 352, loss: 0.03749124659225345\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 353, loss: 0.03744320431724191\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 354, loss: 0.03739539487287402\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 355, loss: 0.037347821053117514\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 356, loss: 0.037300472147762775\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 357, loss: 0.03725337469950318\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 358, loss: 0.03720649937167764\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 359, loss: 0.037159846629947424\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 360, loss: 0.03711343090981245\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 361, loss: 0.03706724522635341\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 362, loss: 0.03702127141878009\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 363, loss: 0.036975531373173\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 364, loss: 0.036930006463080645\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 365, loss: 0.036884702276438475\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 366, loss: 0.03683961182832718\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 367, loss: 0.036794747691601515\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 368, loss: 0.03675009263679385\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 369, loss: 0.03670565178617835\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 370, loss: 0.03666142327710986\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 371, loss: 0.036617396865040064\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 372, loss: 0.03657358651980758\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 373, loss: 0.03652997827157378\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 374, loss: 0.03648658422753215\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 375, loss: 0.03644339134916663\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 376, loss: 0.03640039125457406\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 377, loss: 0.03635760257020593\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 378, loss: 0.0363150117918849\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 379, loss: 0.03627262031659484\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 380, loss: 0.036230423022061586\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 381, loss: 0.03618842549622059\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 382, loss: 0.03614661982282996\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 383, loss: 0.036105002742260695\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 384, loss: 0.03606357332319021\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 385, loss: 0.036022343672811985\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 386, loss: 0.03598130075260997\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 387, loss: 0.0359404431656003\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 388, loss: 0.035899775102734566\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 389, loss: 0.03585928911343217\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 390, loss: 0.035818991251289845\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 391, loss: 0.03577886475250125\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 392, loss: 0.035738930106163025\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 393, loss: 0.035699169617146254\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 394, loss: 0.03565958747640252\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 395, loss: 0.0356201883405447\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 396, loss: 0.03558096336200833\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 397, loss: 0.035541911609470844\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 398, loss: 0.035503033082932234\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 399, loss: 0.03546432685106993\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 400, loss: 0.03542578825727105\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 401, loss: 0.03538742894306779\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 402, loss: 0.03534923028200865\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 403, loss: 0.03531120624393225\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 404, loss: 0.03527334099635482\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 405, loss: 0.035235646180808544\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 406, loss: 0.035198114812374115\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 407, loss: 0.03516074409708381\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 408, loss: 0.03512354753911495\n",
      "Test_acc: 1.0\n",
      "--------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 409, loss: 0.035086496733129025\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 410, loss: 0.03504961961880326\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 411, loss: 0.03501288779079914\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 412, loss: 0.03497632406651974\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 413, loss: 0.034939910750836134\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 414, loss: 0.034903660882264376\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 415, loss: 0.03486755723133683\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 416, loss: 0.034831615164875984\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 417, loss: 0.03479582257568836\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 418, loss: 0.034760179463773966\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 419, loss: 0.03472469002008438\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 420, loss: 0.034689351450651884\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 421, loss: 0.03465416468679905\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 422, loss: 0.03461912088096142\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 423, loss: 0.034584226086735725\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 424, loss: 0.0345494719222188\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 425, loss: 0.03451487235724926\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 426, loss: 0.034480408765375614\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 427, loss: 0.03444609651342034\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 428, loss: 0.03441191930323839\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 429, loss: 0.034377888310700655\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 430, loss: 0.0343439974822104\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 431, loss: 0.03431024495512247\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 432, loss: 0.034276632592082024\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 433, loss: 0.03424314921721816\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 434, loss: 0.034209814853966236\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 435, loss: 0.034176611341536045\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 436, loss: 0.03414354659616947\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 437, loss: 0.034110613632947206\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 438, loss: 0.03407781524583697\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 439, loss: 0.03404514491558075\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 440, loss: 0.03401261428371072\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 441, loss: 0.03398020705208182\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 442, loss: 0.03394793579354882\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 443, loss: 0.03391578933224082\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 444, loss: 0.033883774653077126\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 445, loss: 0.03385189222171903\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 446, loss: 0.03382013039663434\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 447, loss: 0.033788496162742376\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 448, loss: 0.033756992779672146\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 449, loss: 0.03372560581192374\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 450, loss: 0.03369434829801321\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 451, loss: 0.03366321278735995\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 452, loss: 0.03363220160827041\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 453, loss: 0.03360130963847041\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 454, loss: 0.033570545725524426\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 455, loss: 0.03353988938033581\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 456, loss: 0.03350936621427536\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 457, loss: 0.03347895201295614\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 458, loss: 0.03344865795224905\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 459, loss: 0.033418478444218636\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 460, loss: 0.033388426061719656\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 461, loss: 0.033358484506607056\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 462, loss: 0.033328657038509846\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 463, loss: 0.033298940397799015\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 464, loss: 0.033269339706748724\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 465, loss: 0.03323985496535897\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 466, loss: 0.03321048337966204\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 467, loss: 0.03318122075870633\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 468, loss: 0.0331520764157176\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 469, loss: 0.033123028464615345\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 470, loss: 0.033094107173383236\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 471, loss: 0.033065286464989185\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 472, loss: 0.0330365770496428\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 473, loss: 0.03300797566771507\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 474, loss: 0.03297947999089956\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 475, loss: 0.03295109001919627\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 476, loss: 0.03292280342429876\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 477, loss: 0.03289463231340051\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 478, loss: 0.0328665585257113\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 479, loss: 0.03283859835937619\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 480, loss: 0.03281073085963726\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 481, loss: 0.03278297046199441\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 482, loss: 0.032755312509834766\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 483, loss: 0.03272775420919061\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 484, loss: 0.03270029416307807\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 485, loss: 0.032672947738319635\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 486, loss: 0.032645690720528364\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 487, loss: 0.03261853428557515\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 488, loss: 0.03259148681536317\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 489, loss: 0.03256453387439251\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 490, loss: 0.032537673600018024\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 491, loss: 0.03251091670244932\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 492, loss: 0.03248425014317036\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 493, loss: 0.0324576823040843\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 494, loss: 0.032431211322546005\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 495, loss: 0.03240483347326517\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 496, loss: 0.03237855713814497\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 497, loss: 0.03235236741602421\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 498, loss: 0.03232627175748348\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 499, loss: 0.0323002771474421\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "total_time 12.974931001663208\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAAeE0lEQVR4nO3de5RcZZ3u8e+TG50b6dxoIJ2kA4TJxQRkmoCCioIIikFmVIjMEhzGzHgAcfBwQM0Chxk9jrrGo0dwhJmR4SzuooiIAQ0oKtdASEgTMCEm0iGQkO4kpDud6nT/zh+1q1J0Okkn6eqqrv181qqV2rt21f7tpumn3v2+796KCMzMLL0GlLoAMzMrLQeBmVnKOQjMzFLOQWBmlnIOAjOzlHMQmJmlnIPAzCzlHARW0ST9RlKzpEOK8NmS9HlJyyW1SGqUdI+kWb29L7NichBYxZJUB7wHCGBuEXbxXeAK4PPAGOBY4D7gI/v7QZIG9WplZvvBQWCV7NPAk8AtwEWFL0iaKOknkjZK2iTp+wWvfVbSCklvSXpR0gldP1jSVOBSYF5EPBIROyKiNSJui4hvJNv8RtLfFbznYkm/L1gOSZdKWgmslPQDSd/usp+fSboyeX6kpHuTmv8k6fO98DMycxBYRfs0cFvy+JCkGgBJA4EHgLVAHTABuDN57RPAV5P3Hkq2JbGpm88+HWiMiKcPssaPAScBM4A7gPMlKallNHAmcKekAcDPgaVJvacDX5D0oYPcv5mDwCqTpFOBycDdEfEs8ArwqeTlOcCRwFUR0RIRbRGR+6b+d8A3I+KZyFoVEWu72cVYYH0vlPq/I6IpIrYDvyN7Gus9yWsfB56IiNeAE4HxEXF9RGQiYjVwM3BBL9RgKecgsEp1EfBwRLyZLN/OrtNDE4G1EbGzm/dNJBsa+7IJOOKgq4RXc08iewXIO4F5yapPkW3NQDbUjpS0OfcAvgzU9EINlnLuoLKKI2ko8ElgoKTXk9WHANWSjiP7x3eSpEHdhMGrwNE92M0i4AZJ9RGxeA/btADDCpYP72abrpf/vQN4WNI3yJ4yOq+grj9FxNQe1Ga2X9wisEr0MaCD7Hn345PHdLKnXj4NPE32tM43JA2XVCXplOS9/wH8T0l/mQwPPUbS5K47iIiVwI3AHZJOkzQk+ZwLJF2TbPY88FeShkk6BrhkX4VHxBLgzaSOhyJic/LS08Bbkq6WNFTSQEnvkHTifv5szHbjILBKdBHwo4j4c0S8nnsA3wcuBAR8FDgG+DPQCJwPEBH3AF8jeyrpLbLDQcfsYT+fTz7zBmAz2VNK55Ht1AX4DpAB3gD+m12nefblduCM5F+SujqAc8iG2p/YFRajeviZZnsk35jGzCzd3CIwM0s5B4GZWco5CMzMUs5BYGaWcv1uHsG4ceOirq6u1GWYmfUrzz777JsRMb671/pdENTV1bF48Z7m75iZWXckdXepFMCnhszMUs9BYGaWcg4CM7OUcxCYmaWcg8DMLOWKFgSS/kvSBknL9/C6JH1P0ipJy7q7HaCZmRVfMVsEtwBn7eX1s4GpyWM+8IMi1mJmZntQtHkEEfGYpLq9bHIucGtyV6YnJVVLOiIieuP2f1aB/vjGWzyw9LVSl2FWMqdPr+G4idW9/rmlnFA2gYLb9JG9JvwEurkPrKT5ZFsNTJo0qU+Ks/Lz7795hZ8sWUf21u5m6XPYoVUVFwQ9FhE3ATcB1NfX+wYKKfVmS4bjakfxs8tOLXUpZhWllKOG1pG9UXhObbLOrFubWzOMHj6k1GWYVZxSBsH9wKeT0UMnA1vcP2B709SSYcwwB4FZbyvaqSFJdwCnAeMkNQLXAYMBIuLfgQeBDwOrgFbgM8WqxSpDc4tbBGbFUMxRQ/P28XoAlxZr/1ZZ2to7aMl0MMZBYNbrPLPY+oXNre0AjPapIbNe1y9GDVnlaWxu5abHVtPe0bNBYFu354JgcDHLMkslB4GVxIMvrOfWJ9YybsQhPZ4XMHnsMGYeOaq4hZmlkIPASqKppZ0hAwfwzFdOR54hZlZS7iOwksiOABrsEDArAw4CK4mm1ow7fs3KhIPASqK5JeOhoGZlwkFgJdHky0WYlQ0HgZVEc0vGQ0HNyoRHDRkdncG1P1vOG1t39Nk+N29v93WDzMqEg8B4bfN2bnvqz0yoHsqooX3zLX3WhFG859jxfbIvM9s7B4HR1JIB4PpzZ3L69JoSV2Nmfc19BEZTazYI3Hlrlk4OAqM5aRH4nL1ZOjkILH9qyC0Cs3RyEBjNrRkGDhCHVrnLyCyNHARGc2s7o4f5uj9maeWvgCmyta2dS297jq1tO9+2fu2mFsaPOKREVZlZqTkIUuSl9W/xu5VvctzEaqoL5gtU11ZzxgwPGzVLKwdBiuQ6hb9+3jt8gxczy3MfQYo05+YLeJiomRVwEKSIg8DMuuMgSJHmlgxDBw9k6JCBpS7FzMqIgyBFmlrafTMYM9uNgyBFNrdmqPY9AMysC48aqlCZnZ186uYnWb+lLb9u41s7mDNlTAmrMrNy5CCoUG9sbWPx2mbm1I1h0thh+fUfPe7IElZlZuXIQVChciOE5r/3KE8WM7O9ch9Bhdp1RVH3CZjZ3jkIKtTm1nbAcwbMbN8cBBUq1yLwcFEz2xcHQYVqbs0wQHBolU8NmdneOQgqVHNrhuphQxgwwPcYMLO9cxBUqOaW7M1mzMz2xUFQoZpaMu4fMLMecRBUqNypITOzfXEQVKjm1gxjHARm1gMOggoUEdk+Ap8aMrMecBBUoJZMB5mOTncWm1mPFDUIJJ0l6WVJqyRd083rkyQ9KmmJpGWSPlzMetKiOX95CbcIzGzfihYEkgYCNwBnAzOAeZJmdNlsAXB3RLwTuAC4sVj1pEFnZ7CltZ1Xm1sB3EdgZj1SzKuPzgFWRcRqAEl3AucCLxZsE8ChyfNRwGtFrKfiXfXjZdz7XGN+eewIB4GZ7Vsxg2AC8GrBciNwUpdtvgo8LOlyYDhwRncfJGk+MB9g0qRJvV5opXj5ja38Rc1Izj9xIiOqBnFcbXWpSzKzfqDUncXzgFsiohb4MPD/JO1WU0TcFBH1EVE/fvz4Pi+yv2huaWfmhEP521On8Mn6ib68hJn1SDGDYB0wsWC5NllX6BLgboCIeAKoAsYVsaaK5rkDZnYgihkEzwBTJU2RNIRsZ/D9Xbb5M3A6gKTpZINgYxFrqlht7R20Zjo8UsjM9lvRgiAidgKXAQ8BK8iODmqQdL2kuclmXwQ+K2kpcAdwcUREsWqqZLlbU/pGNGa2v4p6z+KIeBB4sMu6awuevwicUswa0qK5JXtHsjG+NaWZ7SffvL6f2tnRyZpNrfnlF9dvBdwiMLP95yDop77xy5f4j9//abf1hx1aVYJqzKw/cxD0U2ubWplQPZSrz56WXzd62GCmjBtewqrMrD9yEPRTm1szTBozjLnHHVnqUsysnyv1hDI7QL4DmZn1FgdBP9Xc2k61LzNtZr3AQdAPdXYGm1vdIjCz3uEg6Ie2trXTGR4qama9w53F/cyqDdtYvm4LgFsEZtYrHAT9SMuOnZz93cdo78heheOIUZ4zYGYHz0HQj2zalqG9I/jcaUdz1szDmV07qtQlmVkFcBD0I03JheXqJ4/muInVpS3GzCqGO4v7Ed+U3syKwUHQjzQlQeCbz5hZb3IQ9CP5ew64RWBmvchB0I80t2YYOEAcWuWuHTPrPf6LUubWbd7Os2ubAVjWuIXRwwYj+ab0ZtZ7HARl7rqfLefXKzbkl0+YVF26YsysIjkIytwbW3dw0pQxfO28WYAnkZlZ73MQlLmmlgxTa8ZwzGEjSl2KmVUodxaXuebWjIeLmllROQjKWFt7B62ZDg8XNbOichCUsdy8AV9l1MyKyUFQxnIziUf7TmRmVkQOgjL1+pY27lncCPgGNGZWXA6CMvWfv1/NLY+v4ZBBA5g8dnipyzGzCubho2XqzW0ZJlQPZdEX30fV4IGlLsfMKphbBGWqqSXDuBFDHAJmVnQOgjLV3Jqh2n0DZtYHHARlqrk142GjZtYnHARlqrml3aOFzKxPOAjKUGZnJ9t27PT8ATPrEx41VGLL123hgWXr37aurb0D8J3IzKxvOAhK7Ae/fYVfLFvPkEFvb5yNrBrEzCMPLVFVZpYmDoISa9qW4cS60dzzD+8udSlmllLuIyix5taMO4XNrKQcBCXW1OJhomZWWg6CEooITxwzs5IrahBIOkvSy5JWSbpmD9t8UtKLkhok3V7MespNS6aD9o5gzHAPEzWz0tlnZ7Gk4cD2iOhMlgcAVRHRuo/3DQRuAD4INALPSLo/Il4s2GYq8CXglIholnTYgR9K/9Ocv9+AWwRmVjo9GTW0CDgD2JYsDwMeBvY1zGUOsCoiVgNIuhM4F3ixYJvPAjdERDNARGzoeen9S0dn8M2FL/Hmtkx+3ZbtvgOZmZVeT4KgKiJyIUBEbJM0rAfvmwC8WrDcCJzUZZtjAST9ARgIfDUiFnb9IEnzgfkAkyZN6sGuy8/qjdv44WOrGTv87VcUPbZmBDM8X8DMSqgnQdAi6YSIeA5A0l8C23tx/1OB04Ba4DFJsyJic+FGEXETcBNAfX199NK++1TutpPfveCdnDp1XImrMTPbpSdB8AXgHkmvAQIOB87vwfvWARMLlmuTdYUagacioh34k6Q/kg2GZ3rw+f1Kc2s7AKPdMWxmZWafQRARz0iaBvxFsurl5A/3vjwDTJU0hWwAXAB8qss29wHzgB9JGkf2VNHqHtberzS3umPYzMrTPoePSroUGB4RyyNiOTBC0v/Y1/siYidwGfAQsAK4OyIaJF0vaW6y2UPAJkkvAo8CV0XEpgM9mHLW5BFCZlamenJq6LMRcUNuIRnm+Vngxn29MSIeBB7ssu7agucBXJk8KlpzS4ahgwcydIhvPWlm5aUnE8oGSlJuIZkf4K+1+6m5td3DRM2sLPWkRbAQuEvSD5Plvwd+WbySKs83fvkSv/3jBg4fVVXqUszMdtOTILia7Bj+f0iWl5EdOWQ90NEZ/PCxV6gZWcV576wtdTlmZrvZ56mh5NISTwFryM4W/gDZzl/rgS3b24mAv3/fUVxy6pRSl2Nmtps9tggkHUt2aOc84E3gLoCIeH/flFYZcqOF3D9gZuVqb6eGXgJ+B5wTEasAJP1jn1RVQTZ7/oCZlbm9nRr6K2A98KikmyWdTnZmse0Hzx8ws3K3xyCIiPsi4gJgGtnJXl8ADpP0A0ln9lF9/V5+RrEvLWFmZaonncUtEXF7RHyU7PWClpAdSWQ90NSSvRqH+wjMrFz1ZPhoXnLfgPyVQPuz7y1aycLlrxd9Pxve2sGQQQMYOtgzis2sPO1XEFSS+55fR+uODt4xYVRR93Nk9VBm146iYHK2mVlZSW0QNLdk+MjsI/iXj80qdSlmZiVV1JvXl6uOzmDL9nbGeCSPmVk6g2Dr9nY6A0a7A9fMLJ1B0NTq2b5mZjmpDILmZJJXtU8NmZmlMwjy1/9xEJiZpTMINic3kq8e5tm+ZmapDIIdOzsAfNtIMzNSGgSdkf13gCd5mZmlNQiySTDAOWBmltYgyP7ryz6YmaU0CMItAjOzvFQGwa5TQ04CM7OUBkH2XweBmVlqgyCbBM4BM7OUBkG4RWBmlpfKIOjsdIvAzCwnnUHgFoGZWV5Kg8DDR83MclIZBJHvLHYSmJmlMgg6w60BM7OclAZBuH/AzCyR0iBwR7GZWU4qgyAiPHTUzCyRziDALQIzs5xUBkFnZ7iz2Mwskc4gcB+BmVleUYNA0lmSXpa0StI1e9nuryWFpPpi1pPT6T4CM7O8ogWBpIHADcDZwAxgnqQZ3Ww3ErgCeKpYtXQVEQzwuSEzM6C4LYI5wKqIWB0RGeBO4Nxutvtn4F+BtiLW8jY+NWRmtksxg2AC8GrBcmOyLk/SCcDEiPhFEevYTXZCWV/u0cysfJWss1jSAODfgC/2YNv5khZLWrxx48aD3ndn+DpDZmY5xQyCdcDEguXaZF3OSOAdwG8krQFOBu7vrsM4Im6KiPqIqB8/fvxBFxZuEZiZ5RUzCJ4BpkqaImkIcAFwf+7FiNgSEeMioi4i6oAngbkRsbiINQG+1pCZWaGiBUFE7AQuAx4CVgB3R0SDpOslzS3WfnvCncVmZrsMKuaHR8SDwINd1l27h21PK2YthTyPwMxsl1TOLA63CMzM8lIZBB4+ama2S0qDwC0CM7OclAaB+wjMzHJSGQTh4aNmZnmpDILOTp8aMjPLSWcQ+NSQmVleSoPALQIzs5xUBkH2fgSlrsLMrDyk8s+hrzVkZrZLSoPAl6E2M8tJaRB4ZrGZWU4qg8DXGjIz2yWVQeAWgZnZLqkNAvcRmJllpTQIcIvAzCyRyiDwtYbMzHZJZRBkh4+Wugozs/KQ0iBwi8DMLCelQeAJZWZmOakMgvDwUTOzvFQGgU8NmZntks4g6PTwUTOznHQGgSeUmZnlpTIIwhPKzMzyUhkE7iMwM9vFQWBmlnKpDILwzGIzs7xUBoFbBGZmu6Q0CNxZbGaWk9IgcIvAzCwnlUEQvtaQmVleKoPAt6o0M9tlUKkLKAWfGjIrH+3t7TQ2NtLW1lbqUipCVVUVtbW1DB48uMfvSWUQRMCAVLaFzMpPY2MjI0eOpK6uzqdsD1JEsGnTJhobG5kyZUqP35fKP4e+H4FZ+Whra2Ps2LH+f7IXSGLs2LH73bpKZRD4fgRm5cUh0HsO5GeZyiBwH4GZ2S4pDQIcBGZmiaIGgaSzJL0saZWka7p5/UpJL0paJmmRpMnFrCcnez+CvtiTmVn5K1oQSBoI3ACcDcwA5kma0WWzJUB9RMwGfgx8s1j1FAq3CMxsDy6//HImT+6T76Rlo5gtgjnAqohYHREZ4E7g3MINIuLRiGhNFp8EaotYT54nlJlZd9asWcOjjz5KJpPhrbfeKtp+Ojo6ivbZB6KY8wgmAK8WLDcCJ+1l+0uAX3b3gqT5wHyASZMmHXRh7iw2K0//9PMGXnxta69+5owjD+W6j87s0bbXXXcdCxYs4Oabb6ahoYGTTz4ZgNdee43LL7+c1atXs337dm699VZqa2t3Wzdnzhze9a53cfvttzNlyhTWrVvH3LlzefbZZ/nEJz7BmDFjWLp0Keeccw7Tpk3j29/+Ntu3b2fkyJH89Kc/Zfz48d3ua9iwYcyfP5/HH38cgOeee46rrrqKRYsW9crPqCw6iyX9DVAPfKu71yPipoioj4j68ePHH/T+PI/AzLpqaGhg+fLlnH/++UyfPp3ly5cDsHPnTs4++2w+85nPsGTJEp577jmmT5/e7brOzk7Wrl1LXV0dAMuWLWP27NkAvPDCC9TU1PDkk0+yYMEC3v/+9/Pkk0+ydOlSPvjBD3L33XfvcV8zZsxg9erV+ZbElVdeybe+1e2fywNSzBbBOmBiwXJtsu5tJJ0BfAV4X0TsKGI9eZ5HYFaeevrNvRgWLFjA9ddfjySmT59OQ0MDAPfddx/Tp0/nnHPOAWDYsGH8+Mc/3m0dwMqVK5kyZUr+i+ayZcuYNWsWbW1tNDU1ce211+b3d8stt3DXXXexY8cOXn/9db7+9a93u6+cmTNn0tDQwMqVK5k8eTInnHBCrx17MYPgGWCqpClkA+AC4FOFG0h6J/BD4KyI2FDEWt7Gw0fNrNBTTz3FwoULWbJkCZdeeiltbW3MmjULgOeffz5/iiinu3WQ/dafex/A4sWLmT9/Pg0NDZx00kkMGpT9k3vrrbfy9NNP88gjjzBixAje+973MnPmTB544IFuPxfg5JNP5g9/+AM33ngjCxcu7K1DB4p4aigidgKXAQ8BK4C7I6JB0vWS5iabfQsYAdwj6XlJ9xernkLuLDazQl/+8pf5+c9/zpo1a1izZg1Lly7NtwgOP/zw/HOAjRs3drsOoKmpierqagBWrFjBL37xC2bPns0LL7yQP0UE2cB497vfzYgRI7j33nt5/PHHmTVr1h4/F7JBsGDBAs477zwmTJjQq8df1D6CiHgwIo6NiKMj4mvJumsj4v7k+RkRURMRxyePuXv/xF6pyfcjMLO8X//612QyGc4444z8upqaGrZt20ZTUxMXX3wxb7zxBjNnzuT444/niSee6HYdwIc+9CEWLlzIhRdeyD333MPYsWOpqanZLQguvvhibrzxRubMmcOSJUs46qijGD58+B4/F2DatGkccsghXH311b3+M1BE9PqHFlN9fX0sXrz4gN/f2Rkc9eUH+cczjuWKM6b2YmVmdiBWrFjB9OnTS11G2bvssss48cQTueiii/a5bXc/U0nPRkR9d9un5jLUdz/zKjf/bjW52HODwMz6g1deeYWPfOQjnHLKKT0KgQORmiCoHjaYqTUjAJh2+EjOnFlT4orMzPbt6KOP5qWXXirqPlITBGfOPJwzZx5e6jLMzMpOWUwoMzOz0nEQmFnJ9bdBK+XsQH6WDgIzK6mqqio2bdrkMOgFuXsWV1VV7df7UtNHYGblqba2lsbGxrdNnrIDV1VVRW3t/l3I2UFgZiU1ePBgpkyZUuoyUs2nhszMUs5BYGaWcg4CM7OU63fXGpK0EVh7gG8fB7zZi+X0Bz7mdPAxp8PBHPPkiOj2zl79LggOhqTFe7roUqXyMaeDjzkdinXMPjVkZpZyDgIzs5RLWxDcVOoCSsDHnA4+5nQoyjGnqo/AzMx2l7YWgZmZdeEgMDNLudQEgaSzJL0saZWka0pdT2+R9F+SNkhaXrBujKRfSVqZ/Ds6WS9J30t+BssknVC6yg+cpImSHpX0oqQGSVck6yv2uCVVSXpa0tLkmP8pWT9F0lPJsd0laUiy/pBkeVXyel1JD+AASRooaYmkB5Llij5eAElrJL0g6XlJi5N1Rf3dTkUQSBoI3ACcDcwA5kmaUdqqes0twFld1l0DLIqIqcCiZBmyxz81ecwHftBHNfa2ncAXI2IGcDJwafLfs5KPewfwgYg4DjgeOEvSycC/At+JiGOAZuCSZPtLgOZk/XeS7fqjK4AVBcuVfrw574+I4wvmDBT3dzsiKv4BvAt4qGD5S8CXSl1XLx5fHbC8YPll4Ijk+RHAy8nzHwLzutuuPz+AnwEfTMtxA8OA54CTyM4yHZSsz/+eAw8B70qeD0q2U6lr38/jrE3+6H0AeABQJR9vwXGvAcZ1WVfU3+1UtAiACcCrBcuNybpKVRMR65PnrwM1yfOK+zkkpwDeCTxFhR93cprkeWAD8CvgFWBzROxMNik8rvwxJ69vAcb2acEH7/8A/wvoTJbHUtnHmxPAw5KelTQ/WVfU323fj6DCRURIqsgxwpJGAPcCX4iIrZLyr1XicUdEB3C8pGrgp8C00lZUPJLOATZExLOSTitxOX3t1IhYJ+kw4FeSXip8sRi/22lpEawDJhYs1ybrKtUbko4ASP7dkKyvmJ+DpMFkQ+C2iPhJsrrijxsgIjYDj5I9NVItKfeFrvC48secvD4K2NS3lR6UU4C5ktYAd5I9PfRdKvd48yJiXfLvBrKBP4ci/26nJQieAaYmIw6GABcA95e4pmK6H7goeX4R2XPoufWfTkYanAxsKWhu9hvKfvX/T2BFRPxbwUsVe9ySxictASQNJdsnsoJsIHw82azrMed+Fh8HHonkJHJ/EBFfiojaiKgj+//rIxFxIRV6vDmShksamXsOnAksp9i/26XuGOnDDpgPA38ke171K6WupxeP6w5gPdBO9vzgJWTPjS4CVgK/BsYk24rs6KlXgBeA+lLXf4DHfCrZ86jLgOeTx4cr+biB2cCS5JiXA9cm648CngZWAfcAhyTrq5LlVcnrR5X6GA7i2E8DHkjD8SbHtzR5NOT+VhX7d9uXmDAzS7m0nBoyM7M9cBCYmaWcg8DMLOUcBGZmKecgMDNLOQeBWReSOpIrP+YevXa1Wkl1KrhSrFk58CUmzHa3PSKOL3URZn3FLQKzHkquE//N5FrxT0s6JllfJ+mR5HrwiyRNStbXSPppcg+BpZLenXzUQEk3J/cVeDiZKWxWMg4Cs90N7XJq6PyC17ZExCzg+2Svjgnwf4H/jojZwG3A95L13wN+G9l7CJxAdqYoZK8df0NEzAQ2A39d1KMx2wfPLDbrQtK2iBjRzfo1ZG8Oszq56N3rETFW0ptkrwHfnqxfHxHjJG0EaiNiR8Fn1AG/iuwNRpB0NTA4Iv6lDw7NrFtuEZjtn9jD8/2xo+B5B+6rsxJzEJjtn/ML/n0ief442StkAlwI/C55vgj4HORvKjOqr4o02x/+JmK2u6HJncByFkZEbgjpaEnLyH6rn5esuxz4kaSrgI3AZ5L1VwA3SbqE7Df/z5G9UqxZWXEfgVkPJX0E9RHxZqlrMetNPjVkZpZybhGYmaWcWwRmZinnIDAzSzkHgZlZyjkIzMxSzkFgZpZy/x/K2VlgbHg8FwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 利用鸢尾花数据集，实现前向传播、反向传播，可视化loss曲线\n",
    "\n",
    "# 导入所需模块\n",
    "import tensorflow as tf\n",
    "from sklearn import datasets\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import time  ##1##\n",
    "\n",
    "# 导入数据，分别为输入特征和标签\n",
    "x_data = datasets.load_iris().data\n",
    "y_data = datasets.load_iris().target\n",
    "\n",
    "# 随机打乱数据（因为原始数据是顺序的，顺序不打乱会影响准确率）\n",
    "# seed: 随机数种子，是一个整数，当设置之后，每次生成的随机数都一样（为方便教学，以保每位同学结果一致）\n",
    "np.random.seed(116)  # 使用相同的seed，保证输入特征和标签一一对应\n",
    "np.random.shuffle(x_data)\n",
    "np.random.seed(116)\n",
    "np.random.shuffle(y_data)\n",
    "tf.random.set_seed(116)\n",
    "\n",
    "# 将打乱后的数据集分割为训练集和测试集，训练集为前120行，测试集为后30行\n",
    "x_train = x_data[:-30]\n",
    "y_train = y_data[:-30]\n",
    "x_test = x_data[-30:]\n",
    "y_test = y_data[-30:]\n",
    "\n",
    "# 转换x的数据类型，否则后面矩阵相乘时会因数据类型不一致报错\n",
    "x_train = tf.cast(x_train, tf.float32)\n",
    "x_test = tf.cast(x_test, tf.float32)\n",
    "\n",
    "# from_tensor_slices函数使输入特征和标签值一一对应。（把数据集分批次，每个批次batch组数据）\n",
    "train_db = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(32)\n",
    "test_db = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(32)\n",
    "\n",
    "# 生成神经网络的参数，4个输入特征故，输入层为4个输入节点；因为3分类，故输出层为3个神经元\n",
    "# 用tf.Variable()标记参数可训练\n",
    "# 使用seed使每次生成的随机数相同（方便教学，使大家结果都一致，在现实使用时不写seed）\n",
    "w1 = tf.Variable(tf.random.truncated_normal([4, 3], stddev=0.1, seed=1))\n",
    "b1 = tf.Variable(tf.random.truncated_normal([3], stddev=0.1, seed=1))\n",
    "\n",
    "lr = 0.1  # 学习率为0.1\n",
    "train_loss_results = []  # 将每轮的loss记录在此列表中，为后续画loss曲线提供数据\n",
    "test_acc = []  # 将每轮的acc记录在此列表中，为后续画acc曲线提供数据\n",
    "epoch = 500  # 循环500轮\n",
    "loss_all = 0  # 每轮分4个step，loss_all记录四个step生成的4个loss的和\n",
    "\n",
    "# 训练部分\n",
    "now_time = time.time()  ##2##\n",
    "for epoch in range(epoch):  # 数据集级别的循环，每个epoch循环一次数据集\n",
    "    for step, (x_train, y_train) in enumerate(train_db):  # batch级别的循环 ，每个step循环一个batch\n",
    "        with tf.GradientTape() as tape:  # with结构记录梯度信息\n",
    "            y = tf.matmul(x_train, w1) + b1  # 神经网络乘加运算\n",
    "            y = tf.nn.softmax(y)  # 使输出y符合概率分布（此操作后与独热码同量级，可相减求loss）\n",
    "            y_ = tf.one_hot(y_train, depth=3)  # 将标签值转换为独热码格式，方便计算loss和accuracy\n",
    "            loss = tf.reduce_mean(tf.square(y_ - y))  # 采用均方误差损失函数mse = mean(sum(y-out)^2)\n",
    "            loss_all += loss.numpy()  # 将每个step计算出的loss累加，为后续求loss平均值提供数据，这样计算的loss更准确\n",
    "        # 计算loss对各个参数的梯度\n",
    "        grads = tape.gradient(loss, [w1, b1])\n",
    "\n",
    "        # 实现梯度更新 w1 = w1 - lr * w1_grad    b = b - lr * b_grad\n",
    "        w1.assign_sub(lr * grads[0])  # 参数w1自更新\n",
    "        b1.assign_sub(lr * grads[1])  # 参数b自更新\n",
    "\n",
    "    # 每个epoch，打印loss信息\n",
    "    print(\"Epoch {}, loss: {}\".format(epoch, loss_all / 4))\n",
    "    train_loss_results.append(loss_all / 4)  # 将4个step的loss求平均记录在此变量中\n",
    "    loss_all = 0  # loss_all归零，为记录下一个epoch的loss做准备\n",
    "\n",
    "    # 测试部分\n",
    "    # total_correct为预测对的样本个数, total_number为测试的总样本数，将这两个变量都初始化为0\n",
    "    total_correct, total_number = 0, 0\n",
    "    for x_test, y_test in test_db:\n",
    "        # 使用更新后的参数进行预测\n",
    "        y = tf.matmul(x_test, w1) + b1\n",
    "        y = tf.nn.softmax(y)\n",
    "        pred = tf.argmax(y, axis=1)  # 返回y中最大值的索引，即预测的分类\n",
    "        # 将pred转换为y_test的数据类型\n",
    "        pred = tf.cast(pred, dtype=y_test.dtype)\n",
    "        # 若分类正确，则correct=1，否则为0，将bool型的结果转换为int型\n",
    "        correct = tf.cast(tf.equal(pred, y_test), dtype=tf.int32)\n",
    "        # 将每个batch的correct数加起来\n",
    "        correct = tf.reduce_sum(correct)\n",
    "        # 将所有batch中的correct数加起来\n",
    "        total_correct += int(correct)\n",
    "        # total_number为测试的总样本数，也就是x_test的行数，shape[0]返回变量的行数\n",
    "        total_number += x_test.shape[0]\n",
    "    # 总的准确率等于total_correct/total_number\n",
    "    acc = total_correct / total_number\n",
    "    test_acc.append(acc)\n",
    "    print(\"Test_acc:\", acc)\n",
    "    print(\"--------------------------\")\n",
    "total_time = time.time() - now_time  ##3##\n",
    "print(\"total_time\", total_time)  ##4##\n",
    "\n",
    "# 绘制 loss 曲线\n",
    "plt.title('Loss Function Curve')  # 图片标题\n",
    "plt.xlabel('Epoch')  # x轴变量名称\n",
    "plt.ylabel('Loss')  # y轴变量名称\n",
    "plt.plot(train_loss_results, label=\"$Loss$\")  # 逐点画出trian_loss_results值并连线，连线图标是Loss\n",
    "plt.legend()  # 画出曲线图标\n",
    "plt.show()  # 画出图像\n",
    "\n",
    "# 绘制 Accuracy 曲线\n",
    "plt.title('Acc Curve')  # 图片标题\n",
    "plt.xlabel('Epoch')  # x轴变量名称\n",
    "plt.ylabel('Acc')  # y轴变量名称\n",
    "plt.plot(test_acc, label=\"$Accuracy$\")  # 逐点画出test_acc值并连线，连线图标是Accuracy\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 本文件较 class1\\p45_iris.py 仅添加四处时间记录  用 ##n## 标识\n",
    "# 请将loss曲线、ACC曲线、total_time记录到 class2\\优化器对比.docx  对比各优化器收敛情况\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2a534bf6",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, loss: 0.2961867228150368\n",
      "Test_acc: 0.16666666666666666\n",
      "--------------------------\n",
      "Epoch 1, loss: 0.28081151843070984\n",
      "Test_acc: 0.16666666666666666\n",
      "--------------------------\n",
      "Epoch 2, loss: 0.26392312347888947\n",
      "Test_acc: 0.16666666666666666\n",
      "--------------------------\n",
      "Epoch 3, loss: 0.2419254034757614\n",
      "Test_acc: 0.16666666666666666\n",
      "--------------------------\n",
      "Epoch 4, loss: 0.2185598500072956\n",
      "Test_acc: 0.16666666666666666\n",
      "--------------------------\n",
      "Epoch 5, loss: 0.20465286448597908\n",
      "Test_acc: 0.16666666666666666\n",
      "--------------------------\n",
      "Epoch 6, loss: 0.1955692060291767\n",
      "Test_acc: 0.16666666666666666\n",
      "--------------------------\n",
      "Epoch 7, loss: 0.18339980766177177\n",
      "Test_acc: 0.5\n",
      "--------------------------\n",
      "Epoch 8, loss: 0.17289478331804276\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 9, loss: 0.1638195775449276\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 10, loss: 0.1557205766439438\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 11, loss: 0.14825156331062317\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 12, loss: 0.14126422069966793\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 13, loss: 0.1357906050980091\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 14, loss: 0.13151294365525246\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 15, loss: 0.12771007791161537\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 16, loss: 0.12420251406729221\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 17, loss: 0.12114137224853039\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 18, loss: 0.11857618018984795\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 19, loss: 0.11636175028979778\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 20, loss: 0.11436180770397186\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 21, loss: 0.11252962984144688\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 22, loss: 0.11085252091288567\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 23, loss: 0.10932632349431515\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 24, loss: 0.10794146358966827\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 25, loss: 0.10666536539793015\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 26, loss: 0.10546092316508293\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 27, loss: 0.10430946759879589\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 28, loss: 0.10321032255887985\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 29, loss: 0.10216889157891273\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 30, loss: 0.10118389502167702\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 31, loss: 0.10024458169937134\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 32, loss: 0.09933911822736263\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 33, loss: 0.09846180863678455\n",
      "Test_acc: 0.5666666666666667\n",
      "--------------------------\n",
      "Epoch 34, loss: 0.09761266596615314\n",
      "Test_acc: 0.5666666666666667\n",
      "--------------------------\n",
      "Epoch 35, loss: 0.0967924427241087\n",
      "Test_acc: 0.6\n",
      "--------------------------\n",
      "Epoch 36, loss: 0.09599894098937511\n",
      "Test_acc: 0.6\n",
      "--------------------------\n",
      "Epoch 37, loss: 0.09522782824933529\n",
      "Test_acc: 0.6\n",
      "--------------------------\n",
      "Epoch 38, loss: 0.09447569027543068\n",
      "Test_acc: 0.6\n",
      "--------------------------\n",
      "Epoch 39, loss: 0.09374143555760384\n",
      "Test_acc: 0.6\n",
      "--------------------------\n",
      "Epoch 40, loss: 0.0930252056568861\n",
      "Test_acc: 0.6\n",
      "--------------------------\n",
      "Epoch 41, loss: 0.09232662431895733\n",
      "Test_acc: 0.6333333333333333\n",
      "--------------------------\n",
      "Epoch 42, loss: 0.09164422005414963\n",
      "Test_acc: 0.6333333333333333\n",
      "--------------------------\n",
      "Epoch 43, loss: 0.09097621217370033\n",
      "Test_acc: 0.6333333333333333\n",
      "--------------------------\n",
      "Epoch 44, loss: 0.090321509167552\n",
      "Test_acc: 0.6333333333333333\n",
      "--------------------------\n",
      "Epoch 45, loss: 0.08967970497906208\n",
      "Test_acc: 0.6333333333333333\n",
      "--------------------------\n",
      "Epoch 46, loss: 0.0890505425632\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 47, loss: 0.08843343704938889\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 48, loss: 0.08782759308815002\n",
      "Test_acc: 0.7\n",
      "--------------------------\n",
      "Epoch 49, loss: 0.08723233081400394\n",
      "Test_acc: 0.7\n",
      "--------------------------\n",
      "Epoch 50, loss: 0.08664725348353386\n",
      "Test_acc: 0.7333333333333333\n",
      "--------------------------\n",
      "Epoch 51, loss: 0.08607210591435432\n",
      "Test_acc: 0.7333333333333333\n",
      "--------------------------\n",
      "Epoch 52, loss: 0.08550658822059631\n",
      "Test_acc: 0.7333333333333333\n",
      "--------------------------\n",
      "Epoch 53, loss: 0.084950290620327\n",
      "Test_acc: 0.7333333333333333\n",
      "--------------------------\n",
      "Epoch 54, loss: 0.08440281823277473\n",
      "Test_acc: 0.7333333333333333\n",
      "--------------------------\n",
      "Epoch 55, loss: 0.08386384136974812\n",
      "Test_acc: 0.7333333333333333\n",
      "--------------------------\n",
      "Epoch 56, loss: 0.08333314210176468\n",
      "Test_acc: 0.7333333333333333\n",
      "--------------------------\n",
      "Epoch 57, loss: 0.08281049691140652\n",
      "Test_acc: 0.7666666666666667\n",
      "--------------------------\n",
      "Epoch 58, loss: 0.08229565061628819\n",
      "Test_acc: 0.7666666666666667\n",
      "--------------------------\n",
      "Epoch 59, loss: 0.08178836852312088\n",
      "Test_acc: 0.7666666666666667\n",
      "--------------------------\n",
      "Epoch 60, loss: 0.0812884084880352\n",
      "Test_acc: 0.8\n",
      "--------------------------\n",
      "Epoch 61, loss: 0.08079559355974197\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 62, loss: 0.08030974864959717\n",
      "Test_acc: 0.8666666666666667\n",
      "--------------------------\n",
      "Epoch 63, loss: 0.07983069308102131\n",
      "Test_acc: 0.8666666666666667\n",
      "--------------------------\n",
      "Epoch 64, loss: 0.07935826107859612\n",
      "Test_acc: 0.8666666666666667\n",
      "--------------------------\n",
      "Epoch 65, loss: 0.07889229990541935\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 66, loss: 0.07843263447284698\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 67, loss: 0.07797914929687977\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 68, loss: 0.07753170281648636\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 69, loss: 0.07709016371518373\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 70, loss: 0.07665440812706947\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 71, loss: 0.07622430194169283\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 72, loss: 0.07579975295811892\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 73, loss: 0.07538063917309046\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 74, loss: 0.07496685441583395\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 75, loss: 0.07455830182880163\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 76, loss: 0.07415488827973604\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 77, loss: 0.07375650014728308\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 78, loss: 0.07336306851357222\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 79, loss: 0.07297447975724936\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 80, loss: 0.0725906677544117\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 81, loss: 0.07221154123544693\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 82, loss: 0.07183701638132334\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 83, loss: 0.07146701496094465\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 84, loss: 0.0711014624685049\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 85, loss: 0.07074028719216585\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 86, loss: 0.07038341369479895\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 87, loss: 0.0700307684019208\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 88, loss: 0.06968228612095118\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 89, loss: 0.06933789234608412\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 90, loss: 0.06899752654135227\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 91, loss: 0.06866112072020769\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 92, loss: 0.06832861807197332\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93, loss: 0.06799995619803667\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 94, loss: 0.06767507176846266\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 95, loss: 0.06735390797257423\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 96, loss: 0.06703640427440405\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 97, loss: 0.06672250758856535\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 98, loss: 0.06641215737909079\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 99, loss: 0.0661053080111742\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 100, loss: 0.06580189801752567\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 101, loss: 0.0655018799006939\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 102, loss: 0.06520519778132439\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 103, loss: 0.06491181533783674\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 104, loss: 0.06462167762219906\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 105, loss: 0.06433472223579884\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 106, loss: 0.06405091471970081\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 107, loss: 0.06377021223306656\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 108, loss: 0.06349255703389645\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 109, loss: 0.06321791838854551\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 110, loss: 0.06294624507427216\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 111, loss: 0.06267749145627022\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 112, loss: 0.062411622144281864\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 113, loss: 0.062148584984242916\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 114, loss: 0.06188835483044386\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 115, loss: 0.06163087673485279\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 116, loss: 0.06137612834572792\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 117, loss: 0.0611240491271019\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 118, loss: 0.06087461858987808\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 119, loss: 0.06062778923660517\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 120, loss: 0.06038353871554136\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 121, loss: 0.06014181021600962\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 122, loss: 0.05990258790552616\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 123, loss: 0.059665813110768795\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 124, loss: 0.05943147744983435\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 125, loss: 0.059199534356594086\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 126, loss: 0.058969960547983646\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 127, loss: 0.058742702938616276\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 128, loss: 0.05851774848997593\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 129, loss: 0.0582950534299016\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 130, loss: 0.05807459447532892\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 131, loss: 0.05785634275525808\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 132, loss: 0.057640266604721546\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 133, loss: 0.057426322251558304\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 134, loss: 0.057214503176510334\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 135, loss: 0.05700476188212633\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 136, loss: 0.05679708439856768\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 137, loss: 0.05659143999218941\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 138, loss: 0.056387798860669136\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 139, loss: 0.05618612840771675\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 140, loss: 0.055986409075558186\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 141, loss: 0.05578862316906452\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 142, loss: 0.0555927325040102\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 143, loss: 0.05539871193468571\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 144, loss: 0.05520654562860727\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 145, loss: 0.05501620005816221\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 146, loss: 0.05482766032218933\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 147, loss: 0.05464089382439852\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 148, loss: 0.05445588007569313\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 149, loss: 0.05427259672433138\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 150, loss: 0.05409103445708752\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 151, loss: 0.05391116067767143\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 152, loss: 0.05373294372111559\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 153, loss: 0.053556364960968494\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 154, loss: 0.053381421603262424\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 155, loss: 0.05320807080715895\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 156, loss: 0.05303630419075489\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 157, loss: 0.05286610312759876\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 158, loss: 0.05269744712859392\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 159, loss: 0.052530307322740555\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 160, loss: 0.052364674396812916\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 161, loss: 0.052200522273778915\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 162, loss: 0.05203784350305796\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 163, loss: 0.0518766101449728\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 164, loss: 0.05171679798513651\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 165, loss: 0.05155839305371046\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 166, loss: 0.051401399075984955\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 167, loss: 0.05124577786773443\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 168, loss: 0.05109151639044285\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 169, loss: 0.050938596948981285\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 170, loss: 0.05078699719160795\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 171, loss: 0.050636718049645424\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 172, loss: 0.050487727858126163\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 173, loss: 0.050340018235147\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 174, loss: 0.05019357055425644\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 175, loss: 0.05004837550222874\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 176, loss: 0.0499044107273221\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 177, loss: 0.04976166319102049\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 178, loss: 0.04962012358009815\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 179, loss: 0.0494797695428133\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 180, loss: 0.04934058524668217\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 181, loss: 0.04920257069170475\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 182, loss: 0.049065710976719856\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 183, loss: 0.0489299651235342\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 184, loss: 0.048795356415212154\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 185, loss: 0.0486618485301733\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 186, loss: 0.04852943401783705\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 187, loss: 0.04839810635894537\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 188, loss: 0.0482678422704339\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 189, loss: 0.04813864268362522\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 190, loss: 0.04801047779619694\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 191, loss: 0.04788334388285875\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 192, loss: 0.047757250256836414\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 193, loss: 0.04763214197009802\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 194, loss: 0.04750804044306278\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 195, loss: 0.047384923323988914\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 196, loss: 0.04726278316229582\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 197, loss: 0.047141607850790024\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 198, loss: 0.047021384350955486\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 199, loss: 0.046902100555598736\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 200, loss: 0.04678374622017145\n",
      "Test_acc: 1.0\n",
      "--------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 201, loss: 0.046666319482028484\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 202, loss: 0.04654979985207319\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 203, loss: 0.046434177085757256\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 204, loss: 0.0463194502517581\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 205, loss: 0.046205601654946804\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 206, loss: 0.04609262477606535\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 207, loss: 0.045980505645275116\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 208, loss: 0.04586923401802778\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 209, loss: 0.045758819207549095\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 210, loss: 0.04564923048019409\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 211, loss: 0.04554046783596277\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 212, loss: 0.04543251916766167\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 213, loss: 0.04532537516206503\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 214, loss: 0.04521902557462454\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 215, loss: 0.045113472267985344\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 216, loss: 0.045008694753050804\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 217, loss: 0.044904688373208046\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 218, loss: 0.04480145126581192\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 219, loss: 0.04469895642250776\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 220, loss: 0.044597224332392216\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 221, loss: 0.044496236369013786\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 222, loss: 0.04439597111195326\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 223, loss: 0.04429642390459776\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 224, loss: 0.044197602197527885\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 225, loss: 0.04409949015825987\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 226, loss: 0.04400207847356796\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 227, loss: 0.043905358761548996\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 228, loss: 0.043809326365590096\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 229, loss: 0.043713975697755814\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 230, loss: 0.04361929465085268\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 231, loss: 0.04352528229355812\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 232, loss: 0.043431926518678665\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 233, loss: 0.04333922918885946\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 234, loss: 0.04324717726558447\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 235, loss: 0.04315576329827309\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 236, loss: 0.043064975179731846\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 237, loss: 0.042974820360541344\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 238, loss: 0.04288528487086296\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 239, loss: 0.042796360328793526\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 240, loss: 0.042708052322268486\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 241, loss: 0.04262033849954605\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 242, loss: 0.0425332160666585\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 243, loss: 0.0424466896802187\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 244, loss: 0.042360748164355755\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 245, loss: 0.0422753831371665\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 246, loss: 0.042190590873360634\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 247, loss: 0.04210636578500271\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 248, loss: 0.042022693902254105\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 249, loss: 0.04193959105759859\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 250, loss: 0.04185703629627824\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 251, loss: 0.04177501704543829\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 252, loss: 0.04169354308396578\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 253, loss: 0.04161259951069951\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 254, loss: 0.041532190050929785\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 255, loss: 0.04145230120047927\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 256, loss: 0.0413729315623641\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 257, loss: 0.04129408160224557\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 258, loss: 0.04121573595330119\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 259, loss: 0.04113789135590196\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 260, loss: 0.04106055432930589\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 261, loss: 0.04098370671272278\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 262, loss: 0.04090734804049134\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 263, loss: 0.04083148017525673\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 264, loss: 0.04075609054416418\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 265, loss: 0.04068117821589112\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 266, loss: 0.04060674272477627\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 267, loss: 0.040532763581722975\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 268, loss: 0.040459247305989265\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 269, loss: 0.04038619715720415\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 270, loss: 0.0403136033564806\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 271, loss: 0.0402414589188993\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 272, loss: 0.04016975359991193\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 273, loss: 0.04009849391877651\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 274, loss: 0.040027682203799486\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 275, loss: 0.03995728911831975\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 276, loss: 0.039887330029159784\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 277, loss: 0.03981780307367444\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 278, loss: 0.0397486905567348\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 279, loss: 0.039680005982518196\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 280, loss: 0.03961173119023442\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 281, loss: 0.039543870370835066\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 282, loss: 0.03947641747072339\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 283, loss: 0.03940937155857682\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 284, loss: 0.03934271074831486\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 285, loss: 0.03927646344527602\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 286, loss: 0.03921059984713793\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 287, loss: 0.039145133923739195\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 288, loss: 0.03908004751428962\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 289, loss: 0.039015342481434345\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 290, loss: 0.038951022550463676\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 291, loss: 0.03888707235455513\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 292, loss: 0.038823505863547325\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 293, loss: 0.03876029932871461\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 294, loss: 0.038697462528944016\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 295, loss: 0.038634989876300097\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 296, loss: 0.03857287857681513\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 297, loss: 0.03851111885160208\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 298, loss: 0.038449717685580254\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 299, loss: 0.03838866902515292\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 300, loss: 0.03832796635106206\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 301, loss: 0.03826760733500123\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 302, loss: 0.038207586854696274\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 303, loss: 0.0381479156203568\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 304, loss: 0.03808857221156359\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 305, loss: 0.03802957059815526\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 306, loss: 0.03797089448198676\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 307, loss: 0.0379125471226871\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 308, loss: 0.03785452013835311\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 309, loss: 0.037796818651258945\n",
      "Test_acc: 1.0\n",
      "--------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 310, loss: 0.03773943800479174\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 311, loss: 0.03768237493932247\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 312, loss: 0.037625623401254416\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 313, loss: 0.03756918711587787\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 314, loss: 0.037513060960918665\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 315, loss: 0.03745723515748978\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 316, loss: 0.03740171808749437\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 317, loss: 0.037346504628658295\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 318, loss: 0.03729158826172352\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 319, loss: 0.03723696805536747\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 320, loss: 0.03718263888731599\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 321, loss: 0.03712860634550452\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 322, loss: 0.03707486670464277\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 323, loss: 0.037021410185843706\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 324, loss: 0.03696824284270406\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 325, loss: 0.036915349308401346\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 326, loss: 0.03686273982748389\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 327, loss: 0.036810411140322685\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 328, loss: 0.03675835765898228\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 329, loss: 0.03670658729970455\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 330, loss: 0.03665507724508643\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 331, loss: 0.03660383261740208\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 332, loss: 0.03655285993590951\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 333, loss: 0.036502163391560316\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 334, loss: 0.036451712250709534\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 335, loss: 0.03640153491869569\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 336, loss: 0.036351613234728575\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 337, loss: 0.036301950458437204\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 338, loss: 0.03625253541395068\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 339, loss: 0.03620337834581733\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 340, loss: 0.03615447273477912\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 341, loss: 0.036105822306126356\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 342, loss: 0.03605741122737527\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 343, loss: 0.03600924555212259\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 344, loss: 0.03596133133396506\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 345, loss: 0.03591364761814475\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 346, loss: 0.03586621256545186\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 347, loss: 0.035819011740386486\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 348, loss: 0.03577204281464219\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 349, loss: 0.03572532255202532\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 350, loss: 0.03567882254719734\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 351, loss: 0.03563255537301302\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 352, loss: 0.035586514975875616\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 353, loss: 0.0355407097376883\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 354, loss: 0.03549512708559632\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 355, loss: 0.03544977027922869\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 356, loss: 0.035404634196311235\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 357, loss: 0.03535971278324723\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 358, loss: 0.035315020475536585\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 359, loss: 0.03527053352445364\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 360, loss: 0.03522627195343375\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 361, loss: 0.03518222738057375\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 362, loss: 0.035138390492647886\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 363, loss: 0.035094758961349726\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 364, loss: 0.03505134116858244\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 365, loss: 0.0350081380456686\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 366, loss: 0.03496513748541474\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 367, loss: 0.0349223418161273\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 368, loss: 0.03487975196912885\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 369, loss: 0.034837364219129086\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 370, loss: 0.034795173443853855\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 371, loss: 0.034753176383674145\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 372, loss: 0.034711390268057585\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 373, loss: 0.03466978808864951\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 374, loss: 0.03462838986888528\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 375, loss: 0.03458718443289399\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 376, loss: 0.03454617038369179\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 377, loss: 0.03450534725561738\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 378, loss: 0.034464708529412746\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 379, loss: 0.03442425699904561\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 380, loss: 0.03438399964943528\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 381, loss: 0.03434392949566245\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 382, loss: 0.03430404048413038\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 383, loss: 0.034264333080500364\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 384, loss: 0.03422480775043368\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 385, loss: 0.03418545983731747\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 386, loss: 0.03414629586040974\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 387, loss: 0.034107301849871874\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 388, loss: 0.0340684917755425\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 389, loss: 0.034029862843453884\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 390, loss: 0.033991404343396425\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 391, loss: 0.03395310789346695\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 392, loss: 0.03391498886048794\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 393, loss: 0.0338770505040884\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 394, loss: 0.033839274663478136\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 395, loss: 0.03380166180431843\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 396, loss: 0.03376422077417374\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 397, loss: 0.03372694458812475\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 398, loss: 0.0336898397654295\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 399, loss: 0.03365289652720094\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 400, loss: 0.033616107888519764\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 401, loss: 0.03357949247583747\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 402, loss: 0.03354302607476711\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 403, loss: 0.03350672498345375\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 404, loss: 0.033470586873590946\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 405, loss: 0.03343459730967879\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 406, loss: 0.033398767467588186\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 407, loss: 0.03336309269070625\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 408, loss: 0.033327578101307154\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 409, loss: 0.033292215783149004\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 410, loss: 0.03325699456036091\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 411, loss: 0.033221937250345945\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 412, loss: 0.03318702196702361\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 413, loss: 0.03315225336700678\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 414, loss: 0.033117645885795355\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 415, loss: 0.03308317344635725\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 416, loss: 0.03304885420948267\n",
      "Test_acc: 1.0\n",
      "--------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 417, loss: 0.03301468072459102\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 418, loss: 0.032980648800730705\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 419, loss: 0.032946758437901735\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 420, loss: 0.032913010101765394\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 421, loss: 0.03287941077724099\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 422, loss: 0.032845946960151196\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 423, loss: 0.03281261911615729\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 424, loss: 0.03277944214642048\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 425, loss: 0.0327463923022151\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 426, loss: 0.03271348727867007\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 427, loss: 0.032680710311979055\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 428, loss: 0.03264807444065809\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 429, loss: 0.03261556616052985\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 430, loss: 0.03258320176973939\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 431, loss: 0.03255097009241581\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 432, loss: 0.03251886647194624\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 433, loss: 0.032486895099282265\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 434, loss: 0.03245505038648844\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 435, loss: 0.032423331402242184\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 436, loss: 0.032391751650720835\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 437, loss: 0.032360299956053495\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 438, loss: 0.03232896886765957\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 439, loss: 0.032297768630087376\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 440, loss: 0.03226668620482087\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 441, loss: 0.03223573789000511\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 442, loss: 0.03220490925014019\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 443, loss: 0.032174211461097\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 444, loss: 0.03214363055303693\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 445, loss: 0.03211316838860512\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 446, loss: 0.03208282729610801\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 447, loss: 0.032052607741206884\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 448, loss: 0.032022513914853334\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 449, loss: 0.03199253790080547\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 450, loss: 0.03196267131716013\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 451, loss: 0.03193293185904622\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 452, loss: 0.031903300900012255\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 453, loss: 0.03187378961592913\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 454, loss: 0.03184439428150654\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 455, loss: 0.03181512467563152\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 456, loss: 0.03178595006465912\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 457, loss: 0.031756891403347254\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 458, loss: 0.031727951020002365\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 459, loss: 0.031699119601398706\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 460, loss: 0.03167040226981044\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 461, loss: 0.031641792971640825\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 462, loss: 0.03161329263821244\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 463, loss: 0.03158490778878331\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 464, loss: 0.03155662817880511\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 465, loss: 0.03152844961732626\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 466, loss: 0.03150038653984666\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 467, loss: 0.03147242870181799\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 468, loss: 0.03144457656890154\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 469, loss: 0.03141682920977473\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 470, loss: 0.031389190815389156\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 471, loss: 0.03136165160685778\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 472, loss: 0.031334218103438616\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 473, loss: 0.03130688378587365\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 474, loss: 0.03127965470775962\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 475, loss: 0.031252529472112656\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 476, loss: 0.031225502490997314\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 477, loss: 0.031198578886687756\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 478, loss: 0.031171757262200117\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 479, loss: 0.03114503249526024\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 480, loss: 0.03111840318888426\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 481, loss: 0.0310918758623302\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 482, loss: 0.03106543654575944\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 483, loss: 0.03103910805657506\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 484, loss: 0.03101287828758359\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 485, loss: 0.030986735597252846\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 486, loss: 0.03096069348976016\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 487, loss: 0.030934737529605627\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 488, loss: 0.030908885411918163\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 489, loss: 0.03088311990723014\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 490, loss: 0.030857461504638195\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 491, loss: 0.030831881798803806\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 492, loss: 0.030806399881839752\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 493, loss: 0.030781006440520287\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 494, loss: 0.03075570845976472\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 495, loss: 0.030730505473911762\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 496, loss: 0.030705390498042107\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 497, loss: 0.030680352821946144\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 498, loss: 0.030655425507575274\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 499, loss: 0.03063056943938136\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "total_time 13.941068410873413\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 利用鸢尾花数据集，实现前向传播、反向传播，可视化loss曲线\n",
    "\n",
    "# 导入所需模块\n",
    "import tensorflow as tf\n",
    "from sklearn import datasets\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import time  ##1##\n",
    "\n",
    "# 导入数据，分别为输入特征和标签\n",
    "x_data = datasets.load_iris().data\n",
    "y_data = datasets.load_iris().target\n",
    "\n",
    "# 随机打乱数据（因为原始数据是顺序的，顺序不打乱会影响准确率）\n",
    "# seed: 随机数种子，是一个整数，当设置之后，每次生成的随机数都一样（为方便教学，以保每位同学结果一致）\n",
    "np.random.seed(116)  # 使用相同的seed，保证输入特征和标签一一对应\n",
    "np.random.shuffle(x_data)\n",
    "np.random.seed(116)\n",
    "np.random.shuffle(y_data)\n",
    "tf.random.set_seed(116)\n",
    "\n",
    "# 将打乱后的数据集分割为训练集和测试集，训练集为前120行，测试集为后30行\n",
    "x_train = x_data[:-30]\n",
    "y_train = y_data[:-30]\n",
    "x_test = x_data[-30:]\n",
    "y_test = y_data[-30:]\n",
    "\n",
    "# 转换x的数据类型，否则后面矩阵相乘时会因数据类型不一致报错\n",
    "x_train = tf.cast(x_train, tf.float32)\n",
    "x_test = tf.cast(x_test, tf.float32)\n",
    "\n",
    "# from_tensor_slices函数使输入特征和标签值一一对应。（把数据集分批次，每个批次batch组数据）\n",
    "train_db = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(32)\n",
    "test_db = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(32)\n",
    "\n",
    "# 生成神经网络的参数，4个输入特征故，输入层为4个输入节点；因为3分类，故输出层为3个神经元\n",
    "# 用tf.Variable()标记参数可训练\n",
    "# 使用seed使每次生成的随机数相同（方便教学，使大家结果都一致，在现实使用时不写seed）\n",
    "w1 = tf.Variable(tf.random.truncated_normal([4, 3], stddev=0.1, seed=1))\n",
    "b1 = tf.Variable(tf.random.truncated_normal([3], stddev=0.1, seed=1))\n",
    "\n",
    "lr = 0.1  # 学习率为0.1\n",
    "train_loss_results = []  # 将每轮的loss记录在此列表中，为后续画loss曲线提供数据\n",
    "test_acc = []  # 将每轮的acc记录在此列表中，为后续画acc曲线提供数据\n",
    "epoch = 500  # 循环500轮\n",
    "loss_all = 0  # 每轮分4个step，loss_all记录四个step生成的4个loss的和\n",
    "\n",
    "##########################################################################\n",
    "m_w, m_b = 0, 0\n",
    "beta = 0.9\n",
    "##########################################################################\n",
    "\n",
    "# 训练部分\n",
    "now_time = time.time()  ##2##\n",
    "for epoch in range(epoch):  # 数据集级别的循环，每个epoch循环一次数据集\n",
    "    for step, (x_train, y_train) in enumerate(train_db):  # batch级别的循环 ，每个step循环一个batch\n",
    "        with tf.GradientTape() as tape:  # with结构记录梯度信息\n",
    "            y = tf.matmul(x_train, w1) + b1  # 神经网络乘加运算\n",
    "            y = tf.nn.softmax(y)  # 使输出y符合概率分布（此操作后与独热码同量级，可相减求loss）\n",
    "            y_ = tf.one_hot(y_train, depth=3)  # 将标签值转换为独热码格式，方便计算loss和accuracy\n",
    "            loss = tf.reduce_mean(tf.square(y_ - y))  # 采用均方误差损失函数mse = mean(sum(y-out)^2)\n",
    "            loss_all += loss.numpy()  # 将每个step计算出的loss累加，为后续求loss平均值提供数据，这样计算的loss更准确\n",
    "        # 计算loss对各个参数的梯度\n",
    "        grads = tape.gradient(loss, [w1, b1])\n",
    "\n",
    "        ##########################################################################\n",
    "        # sgd-momentun  \n",
    "        m_w = beta * m_w + (1 - beta) * grads[0]\n",
    "        m_b = beta * m_b + (1 - beta) * grads[1]\n",
    "        w1.assign_sub(lr * m_w)\n",
    "        b1.assign_sub(lr * m_b)\n",
    "    ##########################################################################\n",
    "\n",
    "    # 每个epoch，打印loss信息\n",
    "    print(\"Epoch {}, loss: {}\".format(epoch, loss_all / 4))\n",
    "    train_loss_results.append(loss_all / 4)  # 将4个step的loss求平均记录在此变量中\n",
    "    loss_all = 0  # loss_all归零，为记录下一个epoch的loss做准备\n",
    "\n",
    "    # 测试部分\n",
    "    # total_correct为预测对的样本个数, total_number为测试的总样本数，将这两个变量都初始化为0\n",
    "    total_correct, total_number = 0, 0\n",
    "    for x_test, y_test in test_db:\n",
    "        # 使用更新后的参数进行预测\n",
    "        y = tf.matmul(x_test, w1) + b1\n",
    "        y = tf.nn.softmax(y)\n",
    "        pred = tf.argmax(y, axis=1)  # 返回y中最大值的索引，即预测的分类\n",
    "        # 将pred转换为y_test的数据类型\n",
    "        pred = tf.cast(pred, dtype=y_test.dtype)\n",
    "        # 若分类正确，则correct=1，否则为0，将bool型的结果转换为int型\n",
    "        correct = tf.cast(tf.equal(pred, y_test), dtype=tf.int32)\n",
    "        # 将每个batch的correct数加起来\n",
    "        correct = tf.reduce_sum(correct)\n",
    "        # 将所有batch中的correct数加起来\n",
    "        total_correct += int(correct)\n",
    "        # total_number为测试的总样本数，也就是x_test的行数，shape[0]返回变量的行数\n",
    "        total_number += x_test.shape[0]\n",
    "    # 总的准确率等于total_correct/total_number\n",
    "    acc = total_correct / total_number\n",
    "    test_acc.append(acc)\n",
    "    print(\"Test_acc:\", acc)\n",
    "    print(\"--------------------------\")\n",
    "total_time = time.time() - now_time  ##3##\n",
    "print(\"total_time\", total_time)  ##4##\n",
    "\n",
    "# 绘制 loss 曲线\n",
    "plt.title('Loss Function Curve')  # 图片标题\n",
    "plt.xlabel('Epoch')  # x轴变量名称\n",
    "plt.ylabel('Loss')  # y轴变量名称\n",
    "plt.plot(train_loss_results, label=\"$Loss$\")  # 逐点画出trian_loss_results值并连线，连线图标是Loss\n",
    "plt.legend()  # 画出曲线图标\n",
    "plt.show()  # 画出图像\n",
    "\n",
    "# 绘制 Accuracy 曲线\n",
    "plt.title('Acc Curve')  # 图片标题\n",
    "plt.xlabel('Epoch')  # x轴变量名称\n",
    "plt.ylabel('Acc')  # y轴变量名称\n",
    "plt.plot(test_acc, label=\"$Accuracy$\")  # 逐点画出test_acc值并连线，连线图标是Accuracy\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 请将loss曲线、ACC曲线、total_time记录到 class2\\优化器对比.docx  对比各优化器收敛情况\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "50632083",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, loss: 0.3926013857126236\n",
      "Test_acc: 0.16666666666666666\n",
      "--------------------------\n",
      "Epoch 1, loss: 0.20467261411249638\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 2, loss: 0.17201939597725868\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 3, loss: 0.15918194875121117\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 4, loss: 0.15706614404916763\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 5, loss: 0.21816574037075043\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 6, loss: 0.14377842098474503\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 7, loss: 0.175712738186121\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 8, loss: 0.18757154047489166\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 9, loss: 0.19608472101390362\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 10, loss: 0.09835131280124187\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 11, loss: 0.12403554655611515\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 12, loss: 0.18723830580711365\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 13, loss: 0.1682581789791584\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 14, loss: 0.10289530828595161\n",
      "Test_acc: 0.8\n",
      "--------------------------\n",
      "Epoch 15, loss: 0.19125016406178474\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 16, loss: 0.10690360330045223\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 17, loss: 0.1670762002468109\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 18, loss: 0.09712468646466732\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 19, loss: 0.14692728035151958\n",
      "Test_acc: 0.8666666666666667\n",
      "--------------------------\n",
      "Epoch 20, loss: 0.1130000613629818\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 21, loss: 0.1312888991087675\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 22, loss: 0.14335670322179794\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 23, loss: 0.14184510335326195\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 24, loss: 0.09614701103419065\n",
      "Test_acc: 0.8666666666666667\n",
      "--------------------------\n",
      "Epoch 25, loss: 0.06645769346505404\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 26, loss: 0.09875406604260206\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 27, loss: 0.121444221585989\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 28, loss: 0.13192315585911274\n",
      "Test_acc: 0.6\n",
      "--------------------------\n",
      "Epoch 29, loss: 0.11436496302485466\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 30, loss: 0.09751834813505411\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 31, loss: 0.08348445501178503\n",
      "Test_acc: 0.8666666666666667\n",
      "--------------------------\n",
      "Epoch 32, loss: 0.03387556970119476\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 33, loss: 0.11853593960404396\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 34, loss: 0.0932916309684515\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 35, loss: 0.11712169740349054\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 36, loss: 0.10019966308027506\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 37, loss: 0.07477776939049363\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 38, loss: 0.07422938151285052\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 39, loss: 0.09871878754347563\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 40, loss: 0.070330910384655\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 41, loss: 0.07131194975227118\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 42, loss: 0.08518253965303302\n",
      "Test_acc: 0.6\n",
      "--------------------------\n",
      "Epoch 43, loss: 0.08418530132621527\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 44, loss: 0.07050436874851584\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 45, loss: 0.07280492968857288\n",
      "Test_acc: 0.5666666666666667\n",
      "--------------------------\n",
      "Epoch 46, loss: 0.05779838189482689\n",
      "Test_acc: 0.6\n",
      "--------------------------\n",
      "Epoch 47, loss: 0.08658631145954132\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 48, loss: 0.06231005070731044\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 49, loss: 0.06802953639999032\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 50, loss: 0.055858150124549866\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 51, loss: 0.07325917342677712\n",
      "Test_acc: 0.5666666666666667\n",
      "--------------------------\n",
      "Epoch 52, loss: 0.05218164040707052\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 53, loss: 0.08286307286471128\n",
      "Test_acc: 0.5666666666666667\n",
      "--------------------------\n",
      "Epoch 54, loss: 0.05124968849122524\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 55, loss: 0.07729693502187729\n",
      "Test_acc: 0.5666666666666667\n",
      "--------------------------\n",
      "Epoch 56, loss: 0.05052058678120375\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 57, loss: 0.07210225146263838\n",
      "Test_acc: 0.6\n",
      "--------------------------\n",
      "Epoch 58, loss: 0.048650020034983754\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 59, loss: 0.07164605148136616\n",
      "Test_acc: 0.6\n",
      "--------------------------\n",
      "Epoch 60, loss: 0.04740914236754179\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 61, loss: 0.07039465755224228\n",
      "Test_acc: 0.6\n",
      "--------------------------\n",
      "Epoch 62, loss: 0.04643832240253687\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 63, loss: 0.06870645936578512\n",
      "Test_acc: 0.6\n",
      "--------------------------\n",
      "Epoch 64, loss: 0.04564674315042794\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 65, loss: 0.06680149119347334\n",
      "Test_acc: 0.6333333333333333\n",
      "--------------------------\n",
      "Epoch 66, loss: 0.045027958462014794\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 67, loss: 0.06487354729324579\n",
      "Test_acc: 0.7\n",
      "--------------------------\n",
      "Epoch 68, loss: 0.0445692609064281\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 69, loss: 0.06296336464583874\n",
      "Test_acc: 0.7\n",
      "--------------------------\n",
      "Epoch 70, loss: 0.04427331080660224\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 71, loss: 0.06105491425842047\n",
      "Test_acc: 0.7333333333333333\n",
      "--------------------------\n",
      "Epoch 72, loss: 0.04415719397366047\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 73, loss: 0.05909866280853748\n",
      "Test_acc: 0.7666666666666667\n",
      "--------------------------\n",
      "Epoch 74, loss: 0.04425172647461295\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 75, loss: 0.057036496698856354\n",
      "Test_acc: 0.8\n",
      "--------------------------\n",
      "Epoch 76, loss: 0.044594576582312584\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 77, loss: 0.05482097156345844\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 78, loss: 0.045206377282738686\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 79, loss: 0.05245483946055174\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 80, loss: 0.046009110286831856\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 81, loss: 0.0500737065449357\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 82, loss: 0.04664709884673357\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 83, loss: 0.04797809990122914\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 84, loss: 0.046533601358532906\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 85, loss: 0.04636092856526375\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 86, loss: 0.045636437367647886\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 87, loss: 0.045101707335561514\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 88, loss: 0.044561204966157675\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 89, loss: 0.04407221358269453\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 90, loss: 0.043622033670544624\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 91, loss: 0.04320198157802224\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 92, loss: 0.0428042383864522\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 93, loss: 0.04242284270003438\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 94, loss: 0.042054098565131426\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 95, loss: 0.041695843916386366\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 96, loss: 0.04134663753211498\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 97, loss: 0.04100561002269387\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 98, loss: 0.04067212762311101\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 99, loss: 0.0403456655330956\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 100, loss: 0.040025873109698296\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 101, loss: 0.039712433237582445\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 102, loss: 0.03940500505268574\n",
      "Test_acc: 1.0\n",
      "--------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 103, loss: 0.03910341626033187\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 104, loss: 0.038807373493909836\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 105, loss: 0.03851672541350126\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 106, loss: 0.03823128994554281\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 107, loss: 0.037950919941067696\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 108, loss: 0.03767540492117405\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 109, loss: 0.037404711823910475\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 110, loss: 0.03713862085714936\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 111, loss: 0.0368770444765687\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 112, loss: 0.036619946360588074\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 113, loss: 0.03636711277067661\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 114, loss: 0.03611843567341566\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 115, loss: 0.03587393742054701\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 116, loss: 0.03563342010602355\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 117, loss: 0.035396863240748644\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 118, loss: 0.03516412852331996\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 119, loss: 0.0349351956974715\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 120, loss: 0.03470994648523629\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 121, loss: 0.03448832663707435\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 122, loss: 0.03427030146121979\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 123, loss: 0.03405570378527045\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 124, loss: 0.0338445904199034\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 125, loss: 0.03363689221441746\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 126, loss: 0.03343246388249099\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 127, loss: 0.03323126211762428\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 128, loss: 0.033033370738849044\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 129, loss: 0.032838572515174747\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 130, loss: 0.03264689049683511\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 131, loss: 0.0324583116453141\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 132, loss: 0.03227274236269295\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 133, loss: 0.03209020406939089\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 134, loss: 0.031910536577925086\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 135, loss: 0.03173386328853667\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 136, loss: 0.03156005195342004\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 137, loss: 0.03138910164125264\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 138, loss: 0.031220964388921857\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 139, loss: 0.0310556807089597\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 140, loss: 0.03089311276562512\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 141, loss: 0.030733278719708323\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 142, loss: 0.030576284741982818\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 143, loss: 0.03042199439369142\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 144, loss: 0.030270383460447192\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 145, loss: 0.030121515737846494\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 146, loss: 0.029975346056744456\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 147, loss: 0.029831886058673263\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 148, loss: 0.02969117439351976\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 149, loss: 0.0295531100127846\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 150, loss: 0.02941780653782189\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 151, loss: 0.02928525093011558\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 152, loss: 0.02915552817285061\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 153, loss: 0.029028499266132712\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 154, loss: 0.028904365142807364\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 155, loss: 0.02878308924846351\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 156, loss: 0.02866475679911673\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 157, loss: 0.028549399925395846\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 158, loss: 0.028437081025913358\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 159, loss: 0.02832793234847486\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 160, loss: 0.0282219504006207\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 161, loss: 0.028119311667978764\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 162, loss: 0.028020158875733614\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 163, loss: 0.027924555586650968\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 164, loss: 0.027832666877657175\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 165, loss: 0.027744697174057364\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 166, loss: 0.027660861844196916\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 167, loss: 0.027581333415582776\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 168, loss: 0.0275064236484468\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 169, loss: 0.027436402859166265\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 170, loss: 0.027371617732569575\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 171, loss: 0.027312430320307612\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 172, loss: 0.027259256690740585\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 173, loss: 0.027212624670937657\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 174, loss: 0.027173121343366802\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 175, loss: 0.0271412655711174\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 176, loss: 0.02711780706886202\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 177, loss: 0.027103488333523273\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 178, loss: 0.02709920413326472\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 179, loss: 0.027105811517685652\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 180, loss: 0.02712427929509431\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 181, loss: 0.027155703399330378\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 182, loss: 0.02720083820167929\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 183, loss: 0.02726082585286349\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 184, loss: 0.027336192200891674\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 185, loss: 0.027427393943071365\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 186, loss: 0.02753435226622969\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 187, loss: 0.02765638951677829\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 188, loss: 0.027791825705207884\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 189, loss: 0.027938233339227736\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 190, loss: 0.02809203031938523\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 191, loss: 0.028248872025869787\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 192, loss: 0.028403849457390606\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 193, loss: 0.028552147676236928\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 194, loss: 0.028689414903055876\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 195, loss: 0.028812544886022806\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 196, loss: 0.028919867414515465\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 197, loss: 0.029011089354753494\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 198, loss: 0.02908712951466441\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 199, loss: 0.029149639478418976\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 200, loss: 0.02920066175283864\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 201, loss: 0.029242231918033212\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 202, loss: 0.02927614323562011\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 203, loss: 0.02930398628814146\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 204, loss: 0.029326878488063812\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 205, loss: 0.02934590744553134\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 206, loss: 0.029361722234170884\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 207, loss: 0.02937487995950505\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 208, loss: 0.029385761416051537\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 209, loss: 0.029394637560471892\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 210, loss: 0.02940186596242711\n",
      "Test_acc: 1.0\n",
      "--------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 211, loss: 0.029407549474854022\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 212, loss: 0.02941185235977173\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 213, loss: 0.029414930671919137\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 214, loss: 0.029416835925076157\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 215, loss: 0.029417784593533725\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 216, loss: 0.029417753510642797\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 217, loss: 0.029416916717309505\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 218, loss: 0.029415257507935166\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 219, loss: 0.02941283449763432\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 220, loss: 0.029409810551442206\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 221, loss: 0.029406092304270715\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 222, loss: 0.029401879641227424\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 223, loss: 0.029397130478173494\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 224, loss: 0.029391881718765944\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 225, loss: 0.029386205365881324\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 226, loss: 0.029380147287156433\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 227, loss: 0.029373677039984614\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 228, loss: 0.02936688851332292\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 229, loss: 0.029359779611695558\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 230, loss: 0.029352375131566077\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 231, loss: 0.029344671667786315\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 232, loss: 0.029336778650758788\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 233, loss: 0.029328645672649145\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 234, loss: 0.02932030535885133\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 235, loss: 0.02931180686573498\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 236, loss: 0.029303104936843738\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 237, loss: 0.029294265987118706\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 238, loss: 0.029285278025781736\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 239, loss: 0.029276190063683316\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 240, loss: 0.029266988072777167\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 241, loss: 0.029257707530632615\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 242, loss: 0.02924832809367217\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 243, loss: 0.029238873132271692\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 244, loss: 0.02922935938113369\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 245, loss: 0.029219785152236\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 246, loss: 0.029210170498117805\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 247, loss: 0.02920052781701088\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 248, loss: 0.02919086758629419\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 249, loss: 0.029181131772929803\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 250, loss: 0.029171435540774837\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 251, loss: 0.029161736863898113\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 252, loss: 0.02915205984027125\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 253, loss: 0.029142334271455184\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 254, loss: 0.029132642404874787\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 255, loss: 0.029122935520717874\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 256, loss: 0.029113335855072364\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 257, loss: 0.029103690205374733\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 258, loss: 0.029094100231304765\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 259, loss: 0.029084552952554077\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 260, loss: 0.029075044149067253\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 261, loss: 0.029065559327136725\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 262, loss: 0.02905615995405242\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 263, loss: 0.029046740208286792\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 264, loss: 0.029037429892923683\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 265, loss: 0.029028181335888803\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 266, loss: 0.029018974804785103\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 267, loss: 0.029009802849031985\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 268, loss: 0.029000692127738148\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 269, loss: 0.02899166994029656\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 270, loss: 0.02898272214224562\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 271, loss: 0.028973847103770822\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 272, loss: 0.028965031553525478\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 273, loss: 0.028956253838259727\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 274, loss: 0.02894757391186431\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 275, loss: 0.028938967443536967\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 276, loss: 0.0289304296602495\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 277, loss: 0.028921983146574348\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 278, loss: 0.028913600195664912\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 279, loss: 0.02890529646538198\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 280, loss: 0.028897050127852708\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 281, loss: 0.028888913162518293\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 282, loss: 0.028880821366328746\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 283, loss: 0.028872817696537822\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 284, loss: 0.028864923515357077\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 285, loss: 0.02885705087101087\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 286, loss: 0.028849281079601496\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 287, loss: 0.02884161804104224\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 288, loss: 0.02883400209248066\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 289, loss: 0.028826480673160404\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 290, loss: 0.02881904604146257\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 291, loss: 0.028811652271542698\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 292, loss: 0.028804384171962738\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 293, loss: 0.028797145758289844\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 294, loss: 0.028790024283807725\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 295, loss: 0.028782969515305012\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 296, loss: 0.028775974235031754\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 297, loss: 0.02876906911842525\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 298, loss: 0.02876223373459652\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 299, loss: 0.028755491541232914\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 300, loss: 0.028748789569362998\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 301, loss: 0.028742158494424075\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 302, loss: 0.028735646046698093\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 303, loss: 0.02872915391344577\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 304, loss: 0.028722761722747236\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 305, loss: 0.028716430766507983\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 306, loss: 0.028710174199659377\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 307, loss: 0.028703995048999786\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 308, loss: 0.028697886678855866\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 309, loss: 0.028691827785223722\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 310, loss: 0.02868586528347805\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 311, loss: 0.02867992129176855\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 312, loss: 0.02867411560146138\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 313, loss: 0.028668277256656438\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 314, loss: 0.028662580822128803\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 315, loss: 0.02865692926570773\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 316, loss: 0.02865132241277024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 317, loss: 0.028645788959693164\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 318, loss: 0.028640303586144\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 319, loss: 0.02863487630384043\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 320, loss: 0.028629534237552434\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 321, loss: 0.028624211146961898\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 322, loss: 0.028618985845241696\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 323, loss: 0.028613795817364007\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 324, loss: 0.02860864991089329\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 325, loss: 0.02860358712496236\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 326, loss: 0.02859855449059978\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 327, loss: 0.02859356888802722\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 328, loss: 0.028588670305907726\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 329, loss: 0.028583804611116648\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 330, loss: 0.028579020232427865\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 331, loss: 0.02857422735542059\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 332, loss: 0.028569550020620227\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 333, loss: 0.028564866457600147\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 334, loss: 0.028560254664625973\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 335, loss: 0.02855569397797808\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 336, loss: 0.02855116216233\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 337, loss: 0.028546711604576558\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 338, loss: 0.02854229713557288\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 339, loss: 0.028537941921968013\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 340, loss: 0.028533629374578595\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 341, loss: 0.02852931182133034\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 342, loss: 0.028525110974442214\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 343, loss: 0.028520899883005768\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 344, loss: 0.0285167804104276\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 345, loss: 0.028512689983472228\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 346, loss: 0.028508625517133623\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 347, loss: 0.028504619898740202\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 348, loss: 0.028500670159701258\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 349, loss: 0.028496717859525234\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 350, loss: 0.028492849320173264\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 351, loss: 0.02848904562415555\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 352, loss: 0.028485239658039063\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 353, loss: 0.028481501329224557\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 354, loss: 0.0284778272616677\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 355, loss: 0.028474173042923212\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 356, loss: 0.028470550198107958\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 357, loss: 0.028467002790421247\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 358, loss: 0.028463504277169704\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 359, loss: 0.028460022702347487\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 360, loss: 0.028456612315494567\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 361, loss: 0.028453199192881584\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 362, loss: 0.0284498929977417\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 363, loss: 0.02844661148265004\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 364, loss: 0.02844334440305829\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 365, loss: 0.028440150781534612\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 366, loss: 0.02843701874371618\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 367, loss: 0.02843393210787326\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 368, loss: 0.028430868755094707\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 369, loss: nan\n",
      "Test_acc: 0.36666666666666664\n",
      "--------------------------\n",
      "Epoch 370, loss: nan\n",
      "Test_acc: 0.36666666666666664\n",
      "--------------------------\n",
      "Epoch 371, loss: nan\n",
      "Test_acc: 0.36666666666666664\n",
      "--------------------------\n",
      "Epoch 372, loss: nan\n",
      "Test_acc: 0.36666666666666664\n",
      "--------------------------\n",
      "Epoch 373, loss: nan\n",
      "Test_acc: 0.36666666666666664\n",
      "--------------------------\n",
      "Epoch 374, loss: nan\n",
      "Test_acc: 0.36666666666666664\n",
      "--------------------------\n",
      "Epoch 375, loss: nan\n",
      "Test_acc: 0.36666666666666664\n",
      "--------------------------\n",
      "Epoch 376, loss: nan\n",
      "Test_acc: 0.36666666666666664\n",
      "--------------------------\n",
      "Epoch 377, loss: nan\n",
      "Test_acc: 0.36666666666666664\n",
      "--------------------------\n",
      "Epoch 378, loss: nan\n",
      "Test_acc: 0.36666666666666664\n",
      "--------------------------\n",
      "Epoch 379, loss: nan\n",
      "Test_acc: 0.36666666666666664\n",
      "--------------------------\n",
      "Epoch 380, loss: nan\n",
      "Test_acc: 0.36666666666666664\n",
      "--------------------------\n",
      "Epoch 381, loss: nan\n",
      "Test_acc: 0.36666666666666664\n",
      "--------------------------\n",
      "Epoch 382, loss: nan\n",
      "Test_acc: 0.36666666666666664\n",
      "--------------------------\n",
      "Epoch 383, loss: nan\n",
      "Test_acc: 0.36666666666666664\n",
      "--------------------------\n",
      "Epoch 384, loss: nan\n",
      "Test_acc: 0.36666666666666664\n",
      "--------------------------\n",
      "Epoch 385, loss: nan\n",
      "Test_acc: 0.36666666666666664\n",
      "--------------------------\n",
      "Epoch 386, loss: nan\n",
      "Test_acc: 0.36666666666666664\n",
      "--------------------------\n",
      "Epoch 387, loss: nan\n",
      "Test_acc: 0.36666666666666664\n",
      "--------------------------\n",
      "Epoch 388, loss: nan\n",
      "Test_acc: 0.36666666666666664\n",
      "--------------------------\n",
      "Epoch 389, loss: nan\n",
      "Test_acc: 0.36666666666666664\n",
      "--------------------------\n",
      "Epoch 390, loss: nan\n",
      "Test_acc: 0.36666666666666664\n",
      "--------------------------\n",
      "Epoch 391, loss: nan\n",
      "Test_acc: 0.36666666666666664\n",
      "--------------------------\n",
      "Epoch 392, loss: nan\n",
      "Test_acc: 0.36666666666666664\n",
      "--------------------------\n",
      "Epoch 393, loss: nan\n",
      "Test_acc: 0.36666666666666664\n",
      "--------------------------\n",
      "Epoch 394, loss: nan\n",
      "Test_acc: 0.36666666666666664\n",
      "--------------------------\n",
      "Epoch 395, loss: nan\n",
      "Test_acc: 0.36666666666666664\n",
      "--------------------------\n",
      "Epoch 396, loss: nan\n",
      "Test_acc: 0.36666666666666664\n",
      "--------------------------\n",
      "Epoch 397, loss: nan\n",
      "Test_acc: 0.36666666666666664\n",
      "--------------------------\n",
      "Epoch 398, loss: nan\n",
      "Test_acc: 0.36666666666666664\n",
      "--------------------------\n",
      "Epoch 399, loss: nan\n",
      "Test_acc: 0.36666666666666664\n",
      "--------------------------\n",
      "Epoch 400, loss: nan\n",
      "Test_acc: 0.36666666666666664\n",
      "--------------------------\n",
      "Epoch 401, loss: nan\n",
      "Test_acc: 0.36666666666666664\n",
      "--------------------------\n",
      "Epoch 402, loss: nan\n",
      "Test_acc: 0.36666666666666664\n",
      "--------------------------\n",
      "Epoch 403, loss: nan\n",
      "Test_acc: 0.36666666666666664\n",
      "--------------------------\n",
      "Epoch 404, loss: nan\n",
      "Test_acc: 0.36666666666666664\n",
      "--------------------------\n",
      "Epoch 405, loss: nan\n",
      "Test_acc: 0.36666666666666664\n",
      "--------------------------\n",
      "Epoch 406, loss: nan\n",
      "Test_acc: 0.36666666666666664\n",
      "--------------------------\n",
      "Epoch 407, loss: nan\n",
      "Test_acc: 0.36666666666666664\n",
      "--------------------------\n",
      "Epoch 408, loss: nan\n",
      "Test_acc: 0.36666666666666664\n",
      "--------------------------\n",
      "Epoch 409, loss: nan\n",
      "Test_acc: 0.36666666666666664\n",
      "--------------------------\n",
      "Epoch 410, loss: nan\n",
      "Test_acc: 0.36666666666666664\n",
      "--------------------------\n",
      "Epoch 411, loss: nan\n",
      "Test_acc: 0.36666666666666664\n",
      "--------------------------\n",
      "Epoch 412, loss: nan\n",
      "Test_acc: 0.36666666666666664\n",
      "--------------------------\n",
      "Epoch 413, loss: nan\n",
      "Test_acc: 0.36666666666666664\n",
      "--------------------------\n",
      "Epoch 414, loss: nan\n",
      "Test_acc: 0.36666666666666664\n",
      "--------------------------\n",
      "Epoch 415, loss: nan\n",
      "Test_acc: 0.36666666666666664\n",
      "--------------------------\n",
      "Epoch 416, loss: nan\n",
      "Test_acc: 0.36666666666666664\n",
      "--------------------------\n",
      "Epoch 417, loss: nan\n",
      "Test_acc: 0.36666666666666664\n",
      "--------------------------\n",
      "Epoch 418, loss: nan\n",
      "Test_acc: 0.36666666666666664\n",
      "--------------------------\n",
      "Epoch 419, loss: nan\n",
      "Test_acc: 0.36666666666666664\n",
      "--------------------------\n",
      "Epoch 420, loss: nan\n",
      "Test_acc: 0.36666666666666664\n",
      "--------------------------\n",
      "Epoch 421, loss: nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test_acc: 0.36666666666666664\n",
      "--------------------------\n",
      "Epoch 422, loss: nan\n",
      "Test_acc: 0.36666666666666664\n",
      "--------------------------\n",
      "Epoch 423, loss: nan\n",
      "Test_acc: 0.36666666666666664\n",
      "--------------------------\n",
      "Epoch 424, loss: nan\n",
      "Test_acc: 0.36666666666666664\n",
      "--------------------------\n",
      "Epoch 425, loss: nan\n",
      "Test_acc: 0.36666666666666664\n",
      "--------------------------\n",
      "Epoch 426, loss: nan\n",
      "Test_acc: 0.36666666666666664\n",
      "--------------------------\n",
      "Epoch 427, loss: nan\n",
      "Test_acc: 0.36666666666666664\n",
      "--------------------------\n",
      "Epoch 428, loss: nan\n",
      "Test_acc: 0.36666666666666664\n",
      "--------------------------\n",
      "Epoch 429, loss: nan\n",
      "Test_acc: 0.36666666666666664\n",
      "--------------------------\n",
      "Epoch 430, loss: nan\n",
      "Test_acc: 0.36666666666666664\n",
      "--------------------------\n",
      "Epoch 431, loss: nan\n",
      "Test_acc: 0.36666666666666664\n",
      "--------------------------\n",
      "Epoch 432, loss: nan\n",
      "Test_acc: 0.36666666666666664\n",
      "--------------------------\n",
      "Epoch 433, loss: nan\n",
      "Test_acc: 0.36666666666666664\n",
      "--------------------------\n",
      "Epoch 434, loss: nan\n",
      "Test_acc: 0.36666666666666664\n",
      "--------------------------\n",
      "Epoch 435, loss: nan\n",
      "Test_acc: 0.36666666666666664\n",
      "--------------------------\n",
      "Epoch 436, loss: nan\n",
      "Test_acc: 0.36666666666666664\n",
      "--------------------------\n",
      "Epoch 437, loss: nan\n",
      "Test_acc: 0.36666666666666664\n",
      "--------------------------\n",
      "Epoch 438, loss: nan\n",
      "Test_acc: 0.36666666666666664\n",
      "--------------------------\n",
      "Epoch 439, loss: nan\n",
      "Test_acc: 0.36666666666666664\n",
      "--------------------------\n",
      "Epoch 440, loss: nan\n",
      "Test_acc: 0.36666666666666664\n",
      "--------------------------\n",
      "Epoch 441, loss: nan\n",
      "Test_acc: 0.36666666666666664\n",
      "--------------------------\n",
      "Epoch 442, loss: nan\n",
      "Test_acc: 0.36666666666666664\n",
      "--------------------------\n",
      "Epoch 443, loss: nan\n",
      "Test_acc: 0.36666666666666664\n",
      "--------------------------\n",
      "Epoch 444, loss: nan\n",
      "Test_acc: 0.36666666666666664\n",
      "--------------------------\n",
      "Epoch 445, loss: nan\n",
      "Test_acc: 0.36666666666666664\n",
      "--------------------------\n",
      "Epoch 446, loss: nan\n",
      "Test_acc: 0.36666666666666664\n",
      "--------------------------\n",
      "Epoch 447, loss: nan\n",
      "Test_acc: 0.36666666666666664\n",
      "--------------------------\n",
      "Epoch 448, loss: nan\n",
      "Test_acc: 0.36666666666666664\n",
      "--------------------------\n",
      "Epoch 449, loss: nan\n",
      "Test_acc: 0.36666666666666664\n",
      "--------------------------\n",
      "Epoch 450, loss: nan\n",
      "Test_acc: 0.36666666666666664\n",
      "--------------------------\n",
      "Epoch 451, loss: nan\n",
      "Test_acc: 0.36666666666666664\n",
      "--------------------------\n",
      "Epoch 452, loss: nan\n",
      "Test_acc: 0.36666666666666664\n",
      "--------------------------\n",
      "Epoch 453, loss: nan\n",
      "Test_acc: 0.36666666666666664\n",
      "--------------------------\n",
      "Epoch 454, loss: nan\n",
      "Test_acc: 0.36666666666666664\n",
      "--------------------------\n",
      "Epoch 455, loss: nan\n",
      "Test_acc: 0.36666666666666664\n",
      "--------------------------\n",
      "Epoch 456, loss: nan\n",
      "Test_acc: 0.36666666666666664\n",
      "--------------------------\n",
      "Epoch 457, loss: nan\n",
      "Test_acc: 0.36666666666666664\n",
      "--------------------------\n",
      "Epoch 458, loss: nan\n",
      "Test_acc: 0.36666666666666664\n",
      "--------------------------\n",
      "Epoch 459, loss: nan\n",
      "Test_acc: 0.36666666666666664\n",
      "--------------------------\n",
      "Epoch 460, loss: nan\n",
      "Test_acc: 0.36666666666666664\n",
      "--------------------------\n",
      "Epoch 461, loss: nan\n",
      "Test_acc: 0.36666666666666664\n",
      "--------------------------\n",
      "Epoch 462, loss: nan\n",
      "Test_acc: 0.36666666666666664\n",
      "--------------------------\n",
      "Epoch 463, loss: nan\n",
      "Test_acc: 0.36666666666666664\n",
      "--------------------------\n",
      "Epoch 464, loss: nan\n",
      "Test_acc: 0.36666666666666664\n",
      "--------------------------\n",
      "Epoch 465, loss: nan\n",
      "Test_acc: 0.36666666666666664\n",
      "--------------------------\n",
      "Epoch 466, loss: nan\n",
      "Test_acc: 0.36666666666666664\n",
      "--------------------------\n",
      "Epoch 467, loss: nan\n",
      "Test_acc: 0.36666666666666664\n",
      "--------------------------\n",
      "Epoch 468, loss: nan\n",
      "Test_acc: 0.36666666666666664\n",
      "--------------------------\n",
      "Epoch 469, loss: nan\n",
      "Test_acc: 0.36666666666666664\n",
      "--------------------------\n",
      "Epoch 470, loss: nan\n",
      "Test_acc: 0.36666666666666664\n",
      "--------------------------\n",
      "Epoch 471, loss: nan\n",
      "Test_acc: 0.36666666666666664\n",
      "--------------------------\n",
      "Epoch 472, loss: nan\n",
      "Test_acc: 0.36666666666666664\n",
      "--------------------------\n",
      "Epoch 473, loss: nan\n",
      "Test_acc: 0.36666666666666664\n",
      "--------------------------\n",
      "Epoch 474, loss: nan\n",
      "Test_acc: 0.36666666666666664\n",
      "--------------------------\n",
      "Epoch 475, loss: nan\n",
      "Test_acc: 0.36666666666666664\n",
      "--------------------------\n",
      "Epoch 476, loss: nan\n",
      "Test_acc: 0.36666666666666664\n",
      "--------------------------\n",
      "Epoch 477, loss: nan\n",
      "Test_acc: 0.36666666666666664\n",
      "--------------------------\n",
      "Epoch 478, loss: nan\n",
      "Test_acc: 0.36666666666666664\n",
      "--------------------------\n",
      "Epoch 479, loss: nan\n",
      "Test_acc: 0.36666666666666664\n",
      "--------------------------\n",
      "Epoch 480, loss: nan\n",
      "Test_acc: 0.36666666666666664\n",
      "--------------------------\n",
      "Epoch 481, loss: nan\n",
      "Test_acc: 0.36666666666666664\n",
      "--------------------------\n",
      "Epoch 482, loss: nan\n",
      "Test_acc: 0.36666666666666664\n",
      "--------------------------\n",
      "Epoch 483, loss: nan\n",
      "Test_acc: 0.36666666666666664\n",
      "--------------------------\n",
      "Epoch 484, loss: nan\n",
      "Test_acc: 0.36666666666666664\n",
      "--------------------------\n",
      "Epoch 485, loss: nan\n",
      "Test_acc: 0.36666666666666664\n",
      "--------------------------\n",
      "Epoch 486, loss: nan\n",
      "Test_acc: 0.36666666666666664\n",
      "--------------------------\n",
      "Epoch 487, loss: nan\n",
      "Test_acc: 0.36666666666666664\n",
      "--------------------------\n",
      "Epoch 488, loss: nan\n",
      "Test_acc: 0.36666666666666664\n",
      "--------------------------\n",
      "Epoch 489, loss: nan\n",
      "Test_acc: 0.36666666666666664\n",
      "--------------------------\n",
      "Epoch 490, loss: nan\n",
      "Test_acc: 0.36666666666666664\n",
      "--------------------------\n",
      "Epoch 491, loss: nan\n",
      "Test_acc: 0.36666666666666664\n",
      "--------------------------\n",
      "Epoch 492, loss: nan\n",
      "Test_acc: 0.36666666666666664\n",
      "--------------------------\n",
      "Epoch 493, loss: nan\n",
      "Test_acc: 0.36666666666666664\n",
      "--------------------------\n",
      "Epoch 494, loss: nan\n",
      "Test_acc: 0.36666666666666664\n",
      "--------------------------\n",
      "Epoch 495, loss: nan\n",
      "Test_acc: 0.36666666666666664\n",
      "--------------------------\n",
      "Epoch 496, loss: nan\n",
      "Test_acc: 0.36666666666666664\n",
      "--------------------------\n",
      "Epoch 497, loss: nan\n",
      "Test_acc: 0.36666666666666664\n",
      "--------------------------\n",
      "Epoch 498, loss: nan\n",
      "Test_acc: 0.36666666666666664\n",
      "--------------------------\n",
      "Epoch 499, loss: nan\n",
      "Test_acc: 0.36666666666666664\n",
      "--------------------------\n",
      "total_time 25.669678449630737\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 利用鸢尾花数据集，实现前向传播、反向传播，可视化loss曲线\n",
    "\n",
    "# 导入所需模块\n",
    "import tensorflow as tf\n",
    "from sklearn import datasets\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import time  ##1##\n",
    "\n",
    "# 导入数据，分别为输入特征和标签\n",
    "x_data = datasets.load_iris().data\n",
    "y_data = datasets.load_iris().target\n",
    "\n",
    "# 随机打乱数据（因为原始数据是顺序的，顺序不打乱会影响准确率）\n",
    "# seed: 随机数种子，是一个整数，当设置之后，每次生成的随机数都一样（为方便教学，以保每位同学结果一致）\n",
    "np.random.seed(116)  # 使用相同的seed，保证输入特征和标签一一对应\n",
    "np.random.shuffle(x_data)\n",
    "np.random.seed(116)\n",
    "np.random.shuffle(y_data)\n",
    "tf.random.set_seed(116)\n",
    "\n",
    "# 将打乱后的数据集分割为训练集和测试集，训练集为前120行，测试集为后30行\n",
    "x_train = x_data[:-30]\n",
    "y_train = y_data[:-30]\n",
    "x_test = x_data[-30:]\n",
    "y_test = y_data[-30:]\n",
    "\n",
    "# 转换x的数据类型，否则后面矩阵相乘时会因数据类型不一致报错\n",
    "x_train = tf.cast(x_train, tf.float32)\n",
    "x_test = tf.cast(x_test, tf.float32)\n",
    "\n",
    "# from_tensor_slices函数使输入特征和标签值一一对应。（把数据集分批次，每个批次batch组数据）\n",
    "train_db = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(32)\n",
    "test_db = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(32)\n",
    "\n",
    "# 生成神经网络的参数，4个输入特征故，输入层为4个输入节点；因为3分类，故输出层为3个神经元\n",
    "# 用tf.Variable()标记参数可训练\n",
    "# 使用seed使每次生成的随机数相同（方便教学，使大家结果都一致，在现实使用时不写seed）\n",
    "w1 = tf.Variable(tf.random.truncated_normal([4, 3], stddev=0.1, seed=1))\n",
    "b1 = tf.Variable(tf.random.truncated_normal([3], stddev=0.1, seed=1))\n",
    "\n",
    "lr = 0.1  # 学习率为0.1\n",
    "train_loss_results = []  # 将每轮的loss记录在此列表中，为后续画loss曲线提供数据\n",
    "test_acc = []  # 将每轮的acc记录在此列表中，为后续画acc曲线提供数据\n",
    "epoch = 500  # 循环500轮\n",
    "loss_all = 0  # 每轮分4个step，loss_all记录四个step生成的4个loss的和\n",
    "\n",
    "##########################################################################\n",
    "v_w, v_b = 0, 0\n",
    "beta = 0.9\n",
    "##########################################################################\n",
    "\n",
    "# 训练部分\n",
    "now_time = time.time()  ##2##\n",
    "for epoch in range(epoch):  # 数据集级别的循环，每个epoch循环一次数据集\n",
    "    for step, (x_train, y_train) in enumerate(train_db):  # batch级别的循环 ，每个step循环一个batch\n",
    "        with tf.GradientTape() as tape:  # with结构记录梯度信息\n",
    "            y = tf.matmul(x_train, w1) + b1  # 神经网络乘加运算\n",
    "            y = tf.nn.softmax(y)  # 使输出y符合概率分布（此操作后与独热码同量级，可相减求loss）\n",
    "            y_ = tf.one_hot(y_train, depth=3)  # 将标签值转换为独热码格式，方便计算loss和accuracy\n",
    "            loss = tf.reduce_mean(tf.square(y_ - y))  # 采用均方误差损失函数mse = mean(sum(y-out)^2)\n",
    "            loss_all += loss.numpy()  # 将每个step计算出的loss累加，为后续求loss平均值提供数据，这样计算的loss更准确\n",
    "        # 计算loss对各个参数的梯度\n",
    "        grads = tape.gradient(loss, [w1, b1])\n",
    "\n",
    "        ##########################################################################\n",
    "        # rmsprop\n",
    "        v_w = beta * v_w + (1 - beta) * tf.square(grads[0])\n",
    "        v_b = beta * v_b + (1 - beta) * tf.square(grads[1])\n",
    "        w1.assign_sub(lr * grads[0] / tf.sqrt(v_w))\n",
    "        b1.assign_sub(lr * grads[1] / tf.sqrt(v_b))\n",
    "    ##########################################################################\n",
    "\n",
    "    # 每个epoch，打印loss信息\n",
    "    print(\"Epoch {}, loss: {}\".format(epoch, loss_all / 4))\n",
    "    train_loss_results.append(loss_all / 4)  # 将4个step的loss求平均记录在此变量中\n",
    "    loss_all = 0  # loss_all归零，为记录下一个epoch的loss做准备\n",
    "\n",
    "    # 测试部分\n",
    "    # total_correct为预测对的样本个数, total_number为测试的总样本数，将这两个变量都初始化为0\n",
    "    total_correct, total_number = 0, 0\n",
    "    for x_test, y_test in test_db:\n",
    "        # 使用更新后的参数进行预测\n",
    "        y = tf.matmul(x_test, w1) + b1\n",
    "        y = tf.nn.softmax(y)\n",
    "        pred = tf.argmax(y, axis=1)  # 返回y中最大值的索引，即预测的分类\n",
    "        # 将pred转换为y_test的数据类型\n",
    "        pred = tf.cast(pred, dtype=y_test.dtype)\n",
    "        # 若分类正确，则correct=1，否则为0，将bool型的结果转换为int型\n",
    "        correct = tf.cast(tf.equal(pred, y_test), dtype=tf.int32)\n",
    "        # 将每个batch的correct数加起来\n",
    "        correct = tf.reduce_sum(correct)\n",
    "        # 将所有batch中的correct数加起来\n",
    "        total_correct += int(correct)\n",
    "        # total_number为测试的总样本数，也就是x_test的行数，shape[0]返回变量的行数\n",
    "        total_number += x_test.shape[0]\n",
    "    # 总的准确率等于total_correct/total_number\n",
    "    acc = total_correct / total_number\n",
    "    test_acc.append(acc)\n",
    "    print(\"Test_acc:\", acc)\n",
    "    print(\"--------------------------\")\n",
    "total_time = time.time() - now_time  ##3##\n",
    "print(\"total_time\", total_time)  ##4##\n",
    "\n",
    "# 绘制 loss 曲线\n",
    "plt.title('Loss Function Curve')  # 图片标题\n",
    "plt.xlabel('Epoch')  # x轴变量名称\n",
    "plt.ylabel('Loss')  # y轴变量名称\n",
    "plt.plot(train_loss_results, label=\"$Loss$\")  # 逐点画出trian_loss_results值并连线，连线图标是Loss\n",
    "plt.legend()  # 画出曲线图标\n",
    "plt.show()  # 画出图像\n",
    "\n",
    "# 绘制 Accuracy 曲线\n",
    "plt.title('Acc Curve')  # 图片标题\n",
    "plt.xlabel('Epoch')  # x轴变量名称\n",
    "plt.ylabel('Acc')  # y轴变量名称\n",
    "plt.plot(test_acc, label=\"$Accuracy$\")  # 逐点画出test_acc值并连线，连线图标是Accuracy\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 请将loss曲线、ACC曲线、total_time记录到 class2\\优化器对比.docx  对比各优化器收敛情况\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f772b78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
